{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "19FogMb1TnqHFO_HBxmm32KCsuCkrd0kp",
      "authorship_tag": "ABX9TyNmZ25RA5Qq/BgD7wIx4F4p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saeedmaktek/SSD-MODEL-Trained-/blob/main/saeed_SSD_YOUR_own_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nTXh7j6kZF8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faf0865c-7b37-406a-c191-0751cfaf98de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "pip  install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install imutils\n"
      ],
      "metadata": {
        "id": "wb4-XVHZZegS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6df85f85-3e0c-4eb7-9a7c-ba5021b9432b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imutils in /usr/local/lib/python3.8/dist-packages (0.5.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install matplotlib\n"
      ],
      "metadata": {
        "id": "ki7Rc8PjZu8t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97c41ae1-ff61-4022-c1fb-1b1c0d4c1b53"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.5.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (23.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.38.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchvision"
      ],
      "metadata": {
        "id": "3ZJigKjnZy1C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8545a4a2-bad3-4b49-a0b6-62ee6e750714"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision) (4.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.13.1+cu116)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.26.14)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch\n"
      ],
      "metadata": {
        "id": "tGNycJPPZ8U0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8d003c-86c6-42da-adcd-bf833269cb60"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install boto3\n"
      ],
      "metadata": {
        "id": "l_Qe4JppaE5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c48999f9-b59e-4c62-ae64-386cec78710f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.85-py3-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.85\n",
            "  Downloading botocore-1.29.85-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.85->boto3) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.8/dist-packages (from botocore<1.30.0,>=1.29.85->boto3) (1.26.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.85->boto3) (1.15.0)\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.26.85 botocore-1.29.85 jmespath-1.0.1 s3transfer-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "id": "pVmIhVBHaIzV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf62b32-fbe2-4912-9111-cb2c9d02ac00"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install urllib3"
      ],
      "metadata": {
        "id": "9-0zm8g7aQxy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2519989-dfa0-431a-c2c2-e07d9d949d76"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (1.26.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y git\n"
      ],
      "metadata": {
        "id": "-loOFqTqaVCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11c65283-531d-4848-b3a2-4d909a4a241e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.25.1-1ubuntu3.10).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mailrocketsystems/jetson-train.git"
      ],
      "metadata": {
        "id": "VqAPsg-vhSpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94441f60-2207-4f60-f452-3d91b6afe10b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'jetson-train'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
            "remote: Compressing objects: 100% (31/31), done.\u001b[K\n",
            "remote: Total 212 (delta 23), reused 54 (delta 22), pack-reused 157\u001b[K\n",
            "Receiving objects: 100% (212/212), 160.46 MiB | 22.75 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd jetson-train"
      ],
      "metadata": {
        "id": "8OGcfqpviOq-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9218682-ea1b-4375-bf83-6215be2e6940"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/jetson-train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1iajr73vFRmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f0f7240-98d9-436f-e4a5-c5a3314449f9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/model0110.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCeqN-cevQaI",
        "outputId": "5caf9e3e-62da-476a-ce45-ea4be2352088"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/model0110.zip\n",
            "replace __MACOSX/._model0110? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: __MACOSX/._model0110    \n",
            "  inflating: __MACOSX/model0110/._ImageSets  \n",
            "  inflating: model0110/.DS_Store     \n",
            "  inflating: __MACOSX/model0110/._.DS_Store  \n",
            "  inflating: __MACOSX/model0110/._Annotations  \n",
            "  inflating: model0110/labelmap.txt  \n",
            "  inflating: __MACOSX/model0110/._labelmap.txt  \n",
            "  inflating: __MACOSX/model0110/._JPEGImages  \n",
            "  inflating: model0110/ImageSets/.DS_Store  \n",
            "  inflating: __MACOSX/model0110/ImageSets/._.DS_Store  \n",
            "  inflating: __MACOSX/model0110/ImageSets/._Main  \n",
            "  inflating: model0110/Annotations/file46.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file46.xml  \n",
            "  inflating: model0110/Annotations/file52.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file52.xml  \n",
            "  inflating: model0110/Annotations/file53.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file53.xml  \n",
            "  inflating: model0110/Annotations/file47.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file47.xml  \n",
            "  inflating: model0110/Annotations/file84.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file84.xml  \n",
            "  inflating: model0110/Annotations/file79.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file79.xml  \n",
            "  inflating: model0110/Annotations/file51.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file51.xml  \n",
            "  inflating: model0110/Annotations/file45.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file45.xml  \n",
            "  inflating: model0110/Annotations/file44.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file44.xml  \n",
            "  inflating: model0110/Annotations/file50.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file50.xml  \n",
            "  inflating: model0110/Annotations/file78.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file78.xml  \n",
            "  inflating: model0110/Annotations/file83.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file83.xml  \n",
            "  inflating: model0110/Annotations/file54.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file54.xml  \n",
            "  inflating: model0110/Annotations/file40.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file40.xml  \n",
            "  inflating: model0110/Annotations/file68.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file68.xml  \n",
            "  inflating: model0110/Annotations/file69.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file69.xml  \n",
            "  inflating: model0110/Annotations/file41.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file41.xml  \n",
            "  inflating: model0110/Annotations/file55.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file55.xml  \n",
            "  inflating: model0110/Annotations/file82.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file82.xml  \n",
            "  inflating: model0110/Annotations/file80.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file80.xml  \n",
            "  inflating: model0110/Annotations/file43.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file43.xml  \n",
            "  inflating: model0110/Annotations/file57.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file57.xml  \n",
            "  inflating: model0110/Annotations/file56.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file56.xml  \n",
            "  inflating: model0110/Annotations/file42.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file42.xml  \n",
            "  inflating: model0110/Annotations/file81.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file81.xml  \n",
            "  inflating: model0110/Annotations/file19.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file19.xml  \n",
            "  inflating: model0110/Annotations/file25.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file25.xml  \n",
            "  inflating: model0110/Annotations/file31.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file31.xml  \n",
            "  inflating: model0110/Annotations/file3.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file3.xml  \n",
            "  inflating: model0110/Annotations/file2.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file2.xml  \n",
            "  inflating: model0110/Annotations/file30.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file30.xml  \n",
            "  inflating: model0110/Annotations/file24.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file24.xml  \n",
            "  inflating: model0110/Annotations/file18.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file18.xml  \n",
            "  inflating: model0110/Annotations/file32.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file32.xml  \n",
            "  inflating: model0110/Annotations/file26.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file26.xml  \n",
            "  inflating: model0110/Annotations/file1.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file1.xml  \n",
            "  inflating: model0110/Annotations/file27.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file27.xml  \n",
            "  inflating: model0110/Annotations/file33.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file33.xml  \n",
            "  inflating: model0110/Annotations/file37.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file37.xml  \n",
            "  inflating: model0110/Annotations/file23.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file23.xml  \n",
            "  inflating: model0110/Annotations/file5.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file5.xml  \n",
            "  inflating: model0110/Annotations/file4.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file4.xml  \n",
            "  inflating: model0110/Annotations/file22.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file22.xml  \n",
            "  inflating: model0110/Annotations/file36.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file36.xml  \n",
            "  inflating: model0110/Annotations/file20.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file20.xml  \n",
            "  inflating: model0110/Annotations/file34.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file34.xml  \n",
            "  inflating: model0110/Annotations/file6.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file6.xml  \n",
            "  inflating: model0110/Annotations/file7.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file7.xml  \n",
            "  inflating: model0110/Annotations/file35.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file35.xml  \n",
            "  inflating: model0110/Annotations/file21.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file21.xml  \n",
            "  inflating: model0110/Annotations/file38.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file38.xml  \n",
            "  inflating: model0110/Annotations/file10.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file10.xml  \n",
            "  inflating: model0110/Annotations/file11.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file11.xml  \n",
            "  inflating: model0110/Annotations/file39.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file39.xml  \n",
            "  inflating: model0110/Annotations/file13.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file13.xml  \n",
            "  inflating: model0110/Annotations/file9.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file9.xml  \n",
            "  inflating: model0110/Annotations/file8.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file8.xml  \n",
            "  inflating: model0110/Annotations/file12.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file12.xml  \n",
            "  inflating: model0110/Annotations/file16.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file16.xml  \n",
            "  inflating: model0110/Annotations/file17.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file17.xml  \n",
            "  inflating: model0110/Annotations/file15.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file15.xml  \n",
            "  inflating: model0110/Annotations/file29.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file29.xml  \n",
            "  inflating: model0110/Annotations/file28.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file28.xml  \n",
            "  inflating: model0110/Annotations/file14.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file14.xml  \n",
            "  inflating: model0110/Annotations/file67.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file67.xml  \n",
            "  inflating: model0110/Annotations/file73.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file73.xml  \n",
            "  inflating: model0110/Annotations/file72.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file72.xml  \n",
            "  inflating: model0110/Annotations/file66.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file66.xml  \n",
            "  inflating: model0110/Annotations/file58.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file58.xml  \n",
            "  inflating: model0110/Annotations/file70.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file70.xml  \n",
            "  inflating: model0110/Annotations/file64.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file64.xml  \n",
            "  inflating: model0110/Annotations/file65.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file65.xml  \n",
            "  inflating: model0110/Annotations/file71.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file71.xml  \n",
            "  inflating: model0110/Annotations/file59.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file59.xml  \n",
            "  inflating: model0110/Annotations/file75.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file75.xml  \n",
            "  inflating: model0110/Annotations/file61.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file61.xml  \n",
            "  inflating: model0110/Annotations/file49.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file49.xml  \n",
            "  inflating: model0110/Annotations/file48.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file48.xml  \n",
            "  inflating: model0110/Annotations/file60.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file60.xml  \n",
            "  inflating: model0110/Annotations/file74.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file74.xml  \n",
            "  inflating: model0110/Annotations/file62.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file62.xml  \n",
            "  inflating: model0110/Annotations/file76.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file76.xml  \n",
            "  inflating: model0110/Annotations/file77.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file77.xml  \n",
            "  inflating: model0110/Annotations/file63.xml  \n",
            "  inflating: __MACOSX/model0110/Annotations/._file63.xml  \n",
            "  inflating: model0110/JPEGImages/file52.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file52.png  \n",
            "  inflating: model0110/JPEGImages/file46.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file46.png  \n",
            "  inflating: model0110/JPEGImages/file47.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file47.png  \n",
            "  inflating: model0110/JPEGImages/file53.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file53.png  \n",
            "  inflating: model0110/JPEGImages/file84.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file84.png  \n",
            "  inflating: model0110/JPEGImages/file45.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file45.png  \n",
            "  inflating: model0110/JPEGImages/file51.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file51.png  \n",
            "  inflating: model0110/JPEGImages/file79.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file79.png  \n",
            "  inflating: model0110/JPEGImages/file78.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file78.png  \n",
            "  inflating: model0110/JPEGImages/file50.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file50.png  \n",
            "  inflating: model0110/JPEGImages/file44.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file44.png  \n",
            "  inflating: model0110/JPEGImages/file83.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file83.png  \n",
            "  inflating: model0110/JPEGImages/file68.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file68.png  \n",
            "  inflating: model0110/JPEGImages/file40.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file40.png  \n",
            "  inflating: model0110/JPEGImages/file54.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file54.png  \n",
            "  inflating: model0110/JPEGImages/.DS_Store  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._.DS_Store  \n",
            "  inflating: model0110/JPEGImages/file55.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file55.png  \n",
            "  inflating: model0110/JPEGImages/file41.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file41.png  \n",
            "  inflating: model0110/JPEGImages/file69.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file69.png  \n",
            "  inflating: model0110/JPEGImages/file82.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file82.png  \n",
            "  inflating: model0110/JPEGImages/file80.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file80.png  \n",
            "  inflating: model0110/JPEGImages/file57.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file57.png  \n",
            "  inflating: model0110/JPEGImages/file43.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file43.png  \n",
            "  inflating: model0110/JPEGImages/file42.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file42.png  \n",
            "  inflating: model0110/JPEGImages/file56.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file56.png  \n",
            "  inflating: model0110/JPEGImages/file81.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file81.png  \n",
            "  inflating: model0110/JPEGImages/file31.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file31.png  \n",
            "  inflating: model0110/JPEGImages/file25.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file25.png  \n",
            "  inflating: model0110/JPEGImages/file19.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file19.png  \n",
            "  inflating: model0110/JPEGImages/file3.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file3.png  \n",
            "  inflating: model0110/JPEGImages/file2.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file2.png  \n",
            "  inflating: model0110/JPEGImages/file18.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file18.png  \n",
            "  inflating: model0110/JPEGImages/file24.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file24.png  \n",
            "  inflating: model0110/JPEGImages/file30.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file30.png  \n",
            "  inflating: model0110/JPEGImages/file26.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file26.png  \n",
            "  inflating: model0110/JPEGImages/file32.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file32.png  \n",
            "  inflating: model0110/JPEGImages/file1.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file1.png  \n",
            "  inflating: model0110/JPEGImages/file33.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file33.png  \n",
            "  inflating: model0110/JPEGImages/file27.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file27.png  \n",
            "  inflating: model0110/JPEGImages/file23.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file23.png  \n",
            "  inflating: model0110/JPEGImages/file37.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file37.png  \n",
            "  inflating: model0110/JPEGImages/file5.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file5.png  \n",
            "  inflating: model0110/JPEGImages/file4.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file4.png  \n",
            "  inflating: model0110/JPEGImages/file36.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file36.png  \n",
            "  inflating: model0110/JPEGImages/file22.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file22.png  \n",
            "  inflating: model0110/JPEGImages/file34.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file34.png  \n",
            "  inflating: model0110/JPEGImages/file20.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file20.png  \n",
            "  inflating: model0110/JPEGImages/file6.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file6.png  \n",
            "  inflating: model0110/JPEGImages/file7.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file7.png  \n",
            "  inflating: model0110/JPEGImages/file21.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file21.png  \n",
            "  inflating: model0110/JPEGImages/file35.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file35.png  \n",
            "  inflating: model0110/JPEGImages/file10.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file10.png  \n",
            "  inflating: model0110/JPEGImages/file38.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file38.png  \n",
            "  inflating: model0110/JPEGImages/file39.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file39.png  \n",
            "  inflating: model0110/JPEGImages/file11.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file11.png  \n",
            "  inflating: model0110/JPEGImages/file13.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file13.png  \n",
            "  inflating: model0110/JPEGImages/file9.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file9.png  \n",
            "  inflating: model0110/JPEGImages/file8.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file8.png  \n",
            "  inflating: model0110/JPEGImages/file12.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file12.png  \n",
            "  inflating: model0110/JPEGImages/file16.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file16.png  \n",
            "  inflating: model0110/JPEGImages/file17.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file17.png  \n",
            "  inflating: model0110/JPEGImages/file29.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file29.png  \n",
            "  inflating: model0110/JPEGImages/file15.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file15.png  \n",
            "  inflating: model0110/JPEGImages/file14.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file14.png  \n",
            "  inflating: model0110/JPEGImages/file28.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file28.png  \n",
            "  inflating: model0110/JPEGImages/file73.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file73.png  \n",
            "  inflating: model0110/JPEGImages/file67.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file67.png  \n",
            "  inflating: model0110/JPEGImages/file66.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file66.png  \n",
            "  inflating: model0110/JPEGImages/file72.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file72.png  \n",
            "  inflating: model0110/JPEGImages/file64.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file64.png  \n",
            "  inflating: model0110/JPEGImages/file70.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file70.png  \n",
            "  inflating: model0110/JPEGImages/file58.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file58.png  \n",
            "  inflating: model0110/JPEGImages/file59.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file59.png  \n",
            "  inflating: model0110/JPEGImages/file71.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file71.png  \n",
            "  inflating: model0110/JPEGImages/file65.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file65.png  \n",
            "  inflating: model0110/JPEGImages/file49.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file49.png  \n",
            "  inflating: model0110/JPEGImages/file61.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file61.png  \n",
            "  inflating: model0110/JPEGImages/file75.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file75.png  \n",
            "  inflating: model0110/JPEGImages/file74.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file74.png  \n",
            "  inflating: model0110/JPEGImages/file60.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file60.png  \n",
            "  inflating: model0110/JPEGImages/file48.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file48.png  \n",
            "  inflating: model0110/JPEGImages/file76.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file76.png  \n",
            "  inflating: model0110/JPEGImages/file62.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file62.png  \n",
            "  inflating: model0110/JPEGImages/file63.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file63.png  \n",
            "  inflating: model0110/JPEGImages/file77.png  \n",
            "  inflating: __MACOSX/model0110/JPEGImages/._file77.png  \n",
            "  inflating: model0110/ImageSets/Main/.DS_Store  \n",
            "  inflating: __MACOSX/model0110/ImageSets/Main/._.DS_Store  \n",
            "  inflating: model0110/ImageSets/Main/train.txt  \n",
            "  inflating: model0110/ImageSets/Main/trainval.txt  \n",
            "  inflating: model0110/ImageSets/Main/test.txt  \n",
            "  inflating: model0110/ImageSets/Main/val.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train_ssd.py --dataset-type=voc --data=data/model0110/ --model-dir=models/model0110 --batch-size=2 --workers=5 --epochs=300"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eH5il-pcLl5u",
        "outputId": "391a8d28-7750-49d7-be86-040dd9b57272"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-07 01:47:52.769688: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-07 01:47:54.007439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-07 01:47:54.007539: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-07 01:47:54.007553: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 01:47:55 - Namespace(balance_data=False, base_net=None, base_net_lr=0.001, batch_size=2, checkpoint_folder='models/model0110', dataset_type='voc', datasets=['data/model0110/'], debug_steps=10, extra_layers_lr=None, freeze_base_net=False, freeze_net=False, gamma=0.1, log_level='info', lr=0.01, mb2_width_mult=1.0, milestones='80,100', momentum=0.9, net='mb1-ssd', num_epochs=300, num_workers=5, pretrained_ssd='models/mobilenet-v1-ssd-mp-0_675.pth', resolution=300, resume=None, scheduler='cosine', t_max=100, use_cuda=True, validation_epochs=1, validation_mean_ap=False, weight_decay=0.0005)\n",
            "2023-03-07 01:47:55 - model resolution 300x300\n",
            "2023-03-07 01:47:55 - SSDSpec(feature_map_size=19, shrinkage=16, box_sizes=SSDBoxSizes(min=60, max=105), aspect_ratios=[2, 3])\n",
            "2023-03-07 01:47:55 - SSDSpec(feature_map_size=10, shrinkage=32, box_sizes=SSDBoxSizes(min=105, max=150), aspect_ratios=[2, 3])\n",
            "2023-03-07 01:47:55 - SSDSpec(feature_map_size=5, shrinkage=64, box_sizes=SSDBoxSizes(min=150, max=195), aspect_ratios=[2, 3])\n",
            "2023-03-07 01:47:55 - SSDSpec(feature_map_size=3, shrinkage=100, box_sizes=SSDBoxSizes(min=195, max=240), aspect_ratios=[2, 3])\n",
            "2023-03-07 01:47:55 - SSDSpec(feature_map_size=2, shrinkage=150, box_sizes=SSDBoxSizes(min=240, max=285), aspect_ratios=[2, 3])\n",
            "2023-03-07 01:47:55 - SSDSpec(feature_map_size=1, shrinkage=300, box_sizes=SSDBoxSizes(min=285, max=330), aspect_ratios=[2, 3])\n",
            "2023-03-07 01:47:55 - Prepare training datasets.\n",
            "2023-03-07 01:47:55 - No labels file, using default VOC classes.\n",
            "2023-03-07 01:47:55 - Stored labels into file models/model0110/labels.txt.\n",
            "2023-03-07 01:47:55 - Train dataset size: 76\n",
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "2023-03-07 01:47:55 - Prepare Validation datasets.\n",
            "2023-03-07 01:47:55 - No labels file, using default VOC classes.\n",
            "2023-03-07 01:47:55 - Validation dataset size: 8\n",
            "2023-03-07 01:47:55 - Build network.\n",
            "2023-03-07 01:47:55 - Init from pretrained ssd models/mobilenet-v1-ssd-mp-0_675.pth\n",
            "2023-03-07 01:47:55 - Took 0.04 seconds to load the model.\n",
            "2023-03-07 01:47:55 - Learning rate: 0.01, Base net learning rate: 0.001, Extra Layers learning rate: 0.01.\n",
            "2023-03-07 01:47:55 - Uses CosineAnnealingLR scheduler.\n",
            "2023-03-07 01:47:55 - Start training from epoch 0.\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "2023-03-07 01:48:09 - Epoch: 0, Step: 10/38, Avg Loss: 16.0696, Avg Regression Loss 4.0335, Avg Classification Loss: 12.0360\n",
            "2023-03-07 01:48:20 - Epoch: 0, Step: 20/38, Avg Loss: 7.4062, Avg Regression Loss 3.4316, Avg Classification Loss: 3.9747\n",
            "2023-03-07 01:48:29 - Epoch: 0, Step: 30/38, Avg Loss: 6.8175, Avg Regression Loss 3.6935, Avg Classification Loss: 3.1240\n",
            "2023-03-07 01:48:36 - Epoch: 0, Training Loss: 8.9927, Training Regression Loss 3.3446, Training Classification Loss: 5.6481\n",
            "2023-03-07 01:48:37 - Epoch: 0, Validation Loss: 4.2516, Validation Regression Loss 1.8399, Validation Classification Loss: 2.4117\n",
            "2023-03-07 01:48:37 - Saved model models/model0110/mb1-ssd-Epoch-0-Loss-4.251550316810608.pth\n",
            "2023-03-07 01:48:51 - Epoch: 1, Step: 10/38, Avg Loss: 5.6117, Avg Regression Loss 2.1749, Avg Classification Loss: 3.4367\n",
            "2023-03-07 01:49:01 - Epoch: 1, Step: 20/38, Avg Loss: 4.4021, Avg Regression Loss 1.9974, Avg Classification Loss: 2.4047\n",
            "2023-03-07 01:49:11 - Epoch: 1, Step: 30/38, Avg Loss: 4.1355, Avg Regression Loss 1.7048, Avg Classification Loss: 2.4307\n",
            "2023-03-07 01:49:18 - Epoch: 1, Training Loss: 4.4918, Training Regression Loss 1.8816, Training Classification Loss: 2.6102\n",
            "2023-03-07 01:49:19 - Epoch: 1, Validation Loss: 3.0516, Validation Regression Loss 1.2336, Validation Classification Loss: 1.8180\n",
            "2023-03-07 01:49:19 - Saved model models/model0110/mb1-ssd-Epoch-1-Loss-3.0516268610954285.pth\n",
            "2023-03-07 01:49:34 - Epoch: 2, Step: 10/38, Avg Loss: 3.7199, Avg Regression Loss 1.5134, Avg Classification Loss: 2.2065\n",
            "2023-03-07 01:49:45 - Epoch: 2, Step: 20/38, Avg Loss: 3.8260, Avg Regression Loss 1.6368, Avg Classification Loss: 2.1892\n",
            "2023-03-07 01:49:55 - Epoch: 2, Step: 30/38, Avg Loss: 3.4027, Avg Regression Loss 1.2583, Avg Classification Loss: 2.1444\n",
            "2023-03-07 01:50:02 - Epoch: 2, Training Loss: 3.4310, Training Regression Loss 1.3768, Training Classification Loss: 2.0542\n",
            "2023-03-07 01:50:03 - Epoch: 2, Validation Loss: 2.8290, Validation Regression Loss 1.0212, Validation Classification Loss: 1.8078\n",
            "2023-03-07 01:50:03 - Saved model models/model0110/mb1-ssd-Epoch-2-Loss-2.829031527042389.pth\n",
            "2023-03-07 01:50:16 - Epoch: 3, Step: 10/38, Avg Loss: 3.3009, Avg Regression Loss 1.3295, Avg Classification Loss: 1.9714\n",
            "2023-03-07 01:50:27 - Epoch: 3, Step: 20/38, Avg Loss: 3.3943, Avg Regression Loss 1.2293, Avg Classification Loss: 2.1649\n",
            "2023-03-07 01:50:37 - Epoch: 3, Step: 30/38, Avg Loss: 3.6800, Avg Regression Loss 1.0882, Avg Classification Loss: 2.5918\n",
            "2023-03-07 01:50:44 - Epoch: 3, Training Loss: 3.2442, Training Regression Loss 1.1616, Training Classification Loss: 2.0826\n",
            "2023-03-07 01:50:45 - Epoch: 3, Validation Loss: 2.0890, Validation Regression Loss 0.6845, Validation Classification Loss: 1.4045\n",
            "2023-03-07 01:50:45 - Saved model models/model0110/mb1-ssd-Epoch-3-Loss-2.0890009105205536.pth\n",
            "2023-03-07 01:50:58 - Epoch: 4, Step: 10/38, Avg Loss: 4.4373, Avg Regression Loss 1.5044, Avg Classification Loss: 2.9328\n",
            "2023-03-07 01:51:09 - Epoch: 4, Step: 20/38, Avg Loss: 3.0628, Avg Regression Loss 1.3596, Avg Classification Loss: 1.7032\n",
            "2023-03-07 01:51:19 - Epoch: 4, Step: 30/38, Avg Loss: 3.1037, Avg Regression Loss 1.1959, Avg Classification Loss: 1.9079\n",
            "2023-03-07 01:51:26 - Epoch: 4, Training Loss: 3.3048, Training Regression Loss 1.2393, Training Classification Loss: 2.0655\n",
            "2023-03-07 01:51:27 - Epoch: 4, Validation Loss: 2.1777, Validation Regression Loss 0.8322, Validation Classification Loss: 1.3455\n",
            "2023-03-07 01:51:27 - Saved model models/model0110/mb1-ssd-Epoch-4-Loss-2.17766410112381.pth\n",
            "2023-03-07 01:51:40 - Epoch: 5, Step: 10/38, Avg Loss: 3.5039, Avg Regression Loss 1.5041, Avg Classification Loss: 1.9998\n",
            "2023-03-07 01:51:51 - Epoch: 5, Step: 20/38, Avg Loss: 2.9694, Avg Regression Loss 1.0993, Avg Classification Loss: 1.8702\n",
            "2023-03-07 01:52:01 - Epoch: 5, Step: 30/38, Avg Loss: 2.9970, Avg Regression Loss 1.0735, Avg Classification Loss: 1.9235\n",
            "2023-03-07 01:52:08 - Epoch: 5, Training Loss: 2.8506, Training Regression Loss 1.0808, Training Classification Loss: 1.7698\n",
            "2023-03-07 01:52:09 - Epoch: 5, Validation Loss: 1.7662, Validation Regression Loss 0.7053, Validation Classification Loss: 1.0609\n",
            "2023-03-07 01:52:09 - Saved model models/model0110/mb1-ssd-Epoch-5-Loss-1.766226440668106.pth\n",
            "2023-03-07 01:52:22 - Epoch: 6, Step: 10/38, Avg Loss: 2.5645, Avg Regression Loss 0.9537, Avg Classification Loss: 1.6108\n",
            "2023-03-07 01:52:32 - Epoch: 6, Step: 20/38, Avg Loss: 2.3367, Avg Regression Loss 0.9036, Avg Classification Loss: 1.4331\n",
            "2023-03-07 01:52:42 - Epoch: 6, Step: 30/38, Avg Loss: 2.2120, Avg Regression Loss 0.8379, Avg Classification Loss: 1.3741\n",
            "2023-03-07 01:52:48 - Epoch: 6, Training Loss: 2.4020, Training Regression Loss 0.8891, Training Classification Loss: 1.5129\n",
            "2023-03-07 01:52:50 - Epoch: 6, Validation Loss: 2.1418, Validation Regression Loss 0.6500, Validation Classification Loss: 1.4918\n",
            "2023-03-07 01:52:50 - Saved model models/model0110/mb1-ssd-Epoch-6-Loss-2.141753226518631.pth\n",
            "2023-03-07 01:53:05 - Epoch: 7, Step: 10/38, Avg Loss: 2.3282, Avg Regression Loss 0.8235, Avg Classification Loss: 1.5047\n",
            "2023-03-07 01:53:15 - Epoch: 7, Step: 20/38, Avg Loss: 3.1582, Avg Regression Loss 1.0006, Avg Classification Loss: 2.1576\n",
            "2023-03-07 01:53:26 - Epoch: 7, Step: 30/38, Avg Loss: 2.2402, Avg Regression Loss 0.7690, Avg Classification Loss: 1.4711\n",
            "2023-03-07 01:53:33 - Epoch: 7, Training Loss: 2.6220, Training Regression Loss 0.8937, Training Classification Loss: 1.7283\n",
            "2023-03-07 01:53:35 - Epoch: 7, Validation Loss: 1.8083, Validation Regression Loss 0.6734, Validation Classification Loss: 1.1348\n",
            "2023-03-07 01:53:35 - Saved model models/model0110/mb1-ssd-Epoch-7-Loss-1.8082684576511383.pth\n",
            "2023-03-07 01:53:48 - Epoch: 8, Step: 10/38, Avg Loss: 2.6248, Avg Regression Loss 0.8782, Avg Classification Loss: 1.7466\n",
            "2023-03-07 01:54:00 - Epoch: 8, Step: 20/38, Avg Loss: 2.3765, Avg Regression Loss 0.8095, Avg Classification Loss: 1.5670\n",
            "2023-03-07 01:54:11 - Epoch: 8, Step: 30/38, Avg Loss: 2.6685, Avg Regression Loss 0.7201, Avg Classification Loss: 1.9484\n",
            "2023-03-07 01:54:18 - Epoch: 8, Training Loss: 2.5794, Training Regression Loss 0.8417, Training Classification Loss: 1.7377\n",
            "2023-03-07 01:54:20 - Epoch: 8, Validation Loss: 2.4668, Validation Regression Loss 0.5842, Validation Classification Loss: 1.8826\n",
            "2023-03-07 01:54:20 - Saved model models/model0110/mb1-ssd-Epoch-8-Loss-2.466758966445923.pth\n",
            "2023-03-07 01:54:34 - Epoch: 9, Step: 10/38, Avg Loss: 3.4634, Avg Regression Loss 1.0063, Avg Classification Loss: 2.4572\n",
            "2023-03-07 01:54:43 - Epoch: 9, Step: 20/38, Avg Loss: 2.4835, Avg Regression Loss 0.8660, Avg Classification Loss: 1.6174\n",
            "2023-03-07 01:54:55 - Epoch: 9, Step: 30/38, Avg Loss: 2.9198, Avg Regression Loss 1.0308, Avg Classification Loss: 1.8890\n",
            "2023-03-07 01:55:02 - Epoch: 9, Training Loss: 2.8903, Training Regression Loss 0.9968, Training Classification Loss: 1.8935\n",
            "2023-03-07 01:55:03 - Epoch: 9, Validation Loss: 1.5307, Validation Regression Loss 0.4809, Validation Classification Loss: 1.0499\n",
            "2023-03-07 01:55:03 - Saved model models/model0110/mb1-ssd-Epoch-9-Loss-1.5307139158248901.pth\n",
            "2023-03-07 01:55:17 - Epoch: 10, Step: 10/38, Avg Loss: 2.5415, Avg Regression Loss 0.8912, Avg Classification Loss: 1.6503\n",
            "2023-03-07 01:55:28 - Epoch: 10, Step: 20/38, Avg Loss: 2.9118, Avg Regression Loss 1.1212, Avg Classification Loss: 1.7907\n",
            "2023-03-07 01:55:37 - Epoch: 10, Step: 30/38, Avg Loss: 2.6011, Avg Regression Loss 0.8096, Avg Classification Loss: 1.7915\n",
            "2023-03-07 01:55:45 - Epoch: 10, Training Loss: 2.5970, Training Regression Loss 0.9071, Training Classification Loss: 1.6898\n",
            "2023-03-07 01:55:46 - Epoch: 10, Validation Loss: 1.4419, Validation Regression Loss 0.3956, Validation Classification Loss: 1.0463\n",
            "2023-03-07 01:55:46 - Saved model models/model0110/mb1-ssd-Epoch-10-Loss-1.4419183433055878.pth\n",
            "2023-03-07 01:55:59 - Epoch: 11, Step: 10/38, Avg Loss: 2.5895, Avg Regression Loss 0.9679, Avg Classification Loss: 1.6216\n",
            "2023-03-07 01:56:10 - Epoch: 11, Step: 20/38, Avg Loss: 2.3365, Avg Regression Loss 0.7110, Avg Classification Loss: 1.6256\n",
            "2023-03-07 01:56:20 - Epoch: 11, Step: 30/38, Avg Loss: 2.2862, Avg Regression Loss 0.7516, Avg Classification Loss: 1.5346\n",
            "2023-03-07 01:56:29 - Epoch: 11, Training Loss: 2.3340, Training Regression Loss 0.7790, Training Classification Loss: 1.5550\n",
            "2023-03-07 01:56:30 - Epoch: 11, Validation Loss: 1.6231, Validation Regression Loss 0.4935, Validation Classification Loss: 1.1296\n",
            "2023-03-07 01:56:30 - Saved model models/model0110/mb1-ssd-Epoch-11-Loss-1.623109132051468.pth\n",
            "2023-03-07 01:56:44 - Epoch: 12, Step: 10/38, Avg Loss: 2.3252, Avg Regression Loss 0.8167, Avg Classification Loss: 1.5085\n",
            "2023-03-07 01:56:54 - Epoch: 12, Step: 20/38, Avg Loss: 3.4541, Avg Regression Loss 1.5247, Avg Classification Loss: 1.9294\n",
            "2023-03-07 01:57:04 - Epoch: 12, Step: 30/38, Avg Loss: 2.0409, Avg Regression Loss 0.6742, Avg Classification Loss: 1.3667\n",
            "2023-03-07 01:57:11 - Epoch: 12, Training Loss: 2.5608, Training Regression Loss 0.9614, Training Classification Loss: 1.5994\n",
            "2023-03-07 01:57:13 - Epoch: 12, Validation Loss: 1.4342, Validation Regression Loss 0.4059, Validation Classification Loss: 1.0283\n",
            "2023-03-07 01:57:13 - Saved model models/model0110/mb1-ssd-Epoch-12-Loss-1.4341871738433838.pth\n",
            "2023-03-07 01:57:26 - Epoch: 13, Step: 10/38, Avg Loss: 2.1055, Avg Regression Loss 0.7274, Avg Classification Loss: 1.3781\n",
            "2023-03-07 01:57:37 - Epoch: 13, Step: 20/38, Avg Loss: 2.0693, Avg Regression Loss 0.7450, Avg Classification Loss: 1.3244\n",
            "2023-03-07 01:57:47 - Epoch: 13, Step: 30/38, Avg Loss: 1.9229, Avg Regression Loss 0.6603, Avg Classification Loss: 1.2627\n",
            "2023-03-07 01:57:54 - Epoch: 13, Training Loss: 1.9762, Training Regression Loss 0.6617, Training Classification Loss: 1.3145\n",
            "2023-03-07 01:57:55 - Epoch: 13, Validation Loss: 1.4681, Validation Regression Loss 0.4396, Validation Classification Loss: 1.0285\n",
            "2023-03-07 01:57:55 - Saved model models/model0110/mb1-ssd-Epoch-13-Loss-1.4680517315864563.pth\n",
            "2023-03-07 01:58:08 - Epoch: 14, Step: 10/38, Avg Loss: 2.1890, Avg Regression Loss 0.8073, Avg Classification Loss: 1.3816\n",
            "2023-03-07 01:58:19 - Epoch: 14, Step: 20/38, Avg Loss: 1.9645, Avg Regression Loss 0.6585, Avg Classification Loss: 1.3061\n",
            "2023-03-07 01:58:30 - Epoch: 14, Step: 30/38, Avg Loss: 2.0713, Avg Regression Loss 0.7184, Avg Classification Loss: 1.3529\n",
            "2023-03-07 01:58:36 - Epoch: 14, Training Loss: 1.9904, Training Regression Loss 0.6929, Training Classification Loss: 1.2975\n",
            "2023-03-07 01:58:37 - Epoch: 14, Validation Loss: 1.3645, Validation Regression Loss 0.3838, Validation Classification Loss: 0.9807\n",
            "2023-03-07 01:58:37 - Saved model models/model0110/mb1-ssd-Epoch-14-Loss-1.3644961416721344.pth\n",
            "2023-03-07 01:58:51 - Epoch: 15, Step: 10/38, Avg Loss: 2.4713, Avg Regression Loss 0.8130, Avg Classification Loss: 1.6583\n",
            "2023-03-07 01:59:02 - Epoch: 15, Step: 20/38, Avg Loss: 2.2501, Avg Regression Loss 0.7241, Avg Classification Loss: 1.5260\n",
            "2023-03-07 01:59:12 - Epoch: 15, Step: 30/38, Avg Loss: 2.0936, Avg Regression Loss 0.7345, Avg Classification Loss: 1.3591\n",
            "2023-03-07 01:59:18 - Epoch: 15, Training Loss: 2.0773, Training Regression Loss 0.7050, Training Classification Loss: 1.3724\n",
            "2023-03-07 01:59:20 - Epoch: 15, Validation Loss: 1.4223, Validation Regression Loss 0.3914, Validation Classification Loss: 1.0309\n",
            "2023-03-07 01:59:20 - Saved model models/model0110/mb1-ssd-Epoch-15-Loss-1.42231684923172.pth\n",
            "2023-03-07 01:59:33 - Epoch: 16, Step: 10/38, Avg Loss: 2.2414, Avg Regression Loss 0.7195, Avg Classification Loss: 1.5219\n",
            "2023-03-07 01:59:44 - Epoch: 16, Step: 20/38, Avg Loss: 2.2385, Avg Regression Loss 0.6967, Avg Classification Loss: 1.5418\n",
            "2023-03-07 01:59:56 - Epoch: 16, Step: 30/38, Avg Loss: 2.6689, Avg Regression Loss 0.8179, Avg Classification Loss: 1.8510\n",
            "2023-03-07 02:00:03 - Epoch: 16, Training Loss: 2.2464, Training Regression Loss 0.7189, Training Classification Loss: 1.5275\n",
            "2023-03-07 02:00:04 - Epoch: 16, Validation Loss: 1.5316, Validation Regression Loss 0.5468, Validation Classification Loss: 0.9848\n",
            "2023-03-07 02:00:04 - Saved model models/model0110/mb1-ssd-Epoch-16-Loss-1.531584620475769.pth\n",
            "2023-03-07 02:00:17 - Epoch: 17, Step: 10/38, Avg Loss: 2.4551, Avg Regression Loss 0.8008, Avg Classification Loss: 1.6544\n",
            "2023-03-07 02:00:28 - Epoch: 17, Step: 20/38, Avg Loss: 2.4378, Avg Regression Loss 0.8242, Avg Classification Loss: 1.6136\n",
            "2023-03-07 02:00:39 - Epoch: 17, Step: 30/38, Avg Loss: 1.8212, Avg Regression Loss 0.5802, Avg Classification Loss: 1.2409\n",
            "2023-03-07 02:00:45 - Epoch: 17, Training Loss: 2.1848, Training Regression Loss 0.6979, Training Classification Loss: 1.4869\n",
            "2023-03-07 02:00:47 - Epoch: 17, Validation Loss: 1.3626, Validation Regression Loss 0.3697, Validation Classification Loss: 0.9929\n",
            "2023-03-07 02:00:47 - Saved model models/model0110/mb1-ssd-Epoch-17-Loss-1.3626216650009155.pth\n",
            "2023-03-07 02:01:00 - Epoch: 18, Step: 10/38, Avg Loss: 2.3783, Avg Regression Loss 0.7474, Avg Classification Loss: 1.6310\n",
            "2023-03-07 02:01:11 - Epoch: 18, Step: 20/38, Avg Loss: 2.1954, Avg Regression Loss 0.7700, Avg Classification Loss: 1.4254\n",
            "2023-03-07 02:01:22 - Epoch: 18, Step: 30/38, Avg Loss: 2.3243, Avg Regression Loss 0.7745, Avg Classification Loss: 1.5497\n",
            "2023-03-07 02:01:28 - Epoch: 18, Training Loss: 2.3226, Training Regression Loss 0.7789, Training Classification Loss: 1.5438\n",
            "2023-03-07 02:01:30 - Epoch: 18, Validation Loss: 1.2877, Validation Regression Loss 0.4281, Validation Classification Loss: 0.8595\n",
            "2023-03-07 02:01:31 - Saved model models/model0110/mb1-ssd-Epoch-18-Loss-1.287690594792366.pth\n",
            "2023-03-07 02:01:44 - Epoch: 19, Step: 10/38, Avg Loss: 2.0954, Avg Regression Loss 0.6428, Avg Classification Loss: 1.4526\n",
            "2023-03-07 02:01:54 - Epoch: 19, Step: 20/38, Avg Loss: 1.8436, Avg Regression Loss 0.5922, Avg Classification Loss: 1.2514\n",
            "2023-03-07 02:02:05 - Epoch: 19, Step: 30/38, Avg Loss: 1.8574, Avg Regression Loss 0.6527, Avg Classification Loss: 1.2047\n",
            "2023-03-07 02:02:12 - Epoch: 19, Training Loss: 1.8302, Training Regression Loss 0.5854, Training Classification Loss: 1.2448\n",
            "2023-03-07 02:02:14 - Epoch: 19, Validation Loss: 1.4950, Validation Regression Loss 0.2978, Validation Classification Loss: 1.1972\n",
            "2023-03-07 02:02:14 - Saved model models/model0110/mb1-ssd-Epoch-19-Loss-1.494995802640915.pth\n",
            "2023-03-07 02:02:27 - Epoch: 20, Step: 10/38, Avg Loss: 1.7197, Avg Regression Loss 0.5175, Avg Classification Loss: 1.2022\n",
            "2023-03-07 02:02:37 - Epoch: 20, Step: 20/38, Avg Loss: 1.4316, Avg Regression Loss 0.4074, Avg Classification Loss: 1.0242\n",
            "2023-03-07 02:02:47 - Epoch: 20, Step: 30/38, Avg Loss: 1.7651, Avg Regression Loss 0.5170, Avg Classification Loss: 1.2481\n",
            "2023-03-07 02:02:55 - Epoch: 20, Training Loss: 1.6619, Training Regression Loss 0.4731, Training Classification Loss: 1.1888\n",
            "2023-03-07 02:02:56 - Epoch: 20, Validation Loss: 1.2503, Validation Regression Loss 0.3135, Validation Classification Loss: 0.9369\n",
            "2023-03-07 02:02:56 - Saved model models/model0110/mb1-ssd-Epoch-20-Loss-1.2503497898578644.pth\n",
            "2023-03-07 02:03:09 - Epoch: 21, Step: 10/38, Avg Loss: 2.0146, Avg Regression Loss 0.5959, Avg Classification Loss: 1.4187\n",
            "2023-03-07 02:03:19 - Epoch: 21, Step: 20/38, Avg Loss: 1.5280, Avg Regression Loss 0.5456, Avg Classification Loss: 0.9825\n",
            "2023-03-07 02:03:31 - Epoch: 21, Step: 30/38, Avg Loss: 1.5347, Avg Regression Loss 0.5059, Avg Classification Loss: 1.0288\n",
            "2023-03-07 02:03:39 - Epoch: 21, Training Loss: 1.6361, Training Regression Loss 0.5213, Training Classification Loss: 1.1148\n",
            "2023-03-07 02:03:41 - Epoch: 21, Validation Loss: 1.2426, Validation Regression Loss 0.3598, Validation Classification Loss: 0.8827\n",
            "2023-03-07 02:03:41 - Saved model models/model0110/mb1-ssd-Epoch-21-Loss-1.2425782084465027.pth\n",
            "2023-03-07 02:03:56 - Epoch: 22, Step: 10/38, Avg Loss: 1.8256, Avg Regression Loss 0.6186, Avg Classification Loss: 1.2070\n",
            "2023-03-07 02:04:08 - Epoch: 22, Step: 20/38, Avg Loss: 2.0515, Avg Regression Loss 0.6916, Avg Classification Loss: 1.3599\n",
            "2023-03-07 02:04:17 - Epoch: 22, Step: 30/38, Avg Loss: 2.3050, Avg Regression Loss 0.6353, Avg Classification Loss: 1.6696\n",
            "2023-03-07 02:04:25 - Epoch: 22, Training Loss: 2.0653, Training Regression Loss 0.5979, Training Classification Loss: 1.4674\n",
            "2023-03-07 02:04:26 - Epoch: 22, Validation Loss: 1.3451, Validation Regression Loss 0.5168, Validation Classification Loss: 0.8283\n",
            "2023-03-07 02:04:26 - Saved model models/model0110/mb1-ssd-Epoch-22-Loss-1.3450967669487.pth\n",
            "2023-03-07 02:04:40 - Epoch: 23, Step: 10/38, Avg Loss: 2.7978, Avg Regression Loss 1.0005, Avg Classification Loss: 1.7973\n",
            "2023-03-07 02:04:51 - Epoch: 23, Step: 20/38, Avg Loss: 1.9994, Avg Regression Loss 0.6059, Avg Classification Loss: 1.3935\n",
            "2023-03-07 02:05:01 - Epoch: 23, Step: 30/38, Avg Loss: 1.7913, Avg Regression Loss 0.5393, Avg Classification Loss: 1.2520\n",
            "2023-03-07 02:05:08 - Epoch: 23, Training Loss: 2.1906, Training Regression Loss 0.7132, Training Classification Loss: 1.4775\n",
            "2023-03-07 02:05:09 - Epoch: 23, Validation Loss: 1.2873, Validation Regression Loss 0.3565, Validation Classification Loss: 0.9307\n",
            "2023-03-07 02:05:09 - Saved model models/model0110/mb1-ssd-Epoch-23-Loss-1.2872511148452759.pth\n",
            "2023-03-07 02:05:23 - Epoch: 24, Step: 10/38, Avg Loss: 2.1423, Avg Regression Loss 0.7140, Avg Classification Loss: 1.4283\n",
            "2023-03-07 02:05:34 - Epoch: 24, Step: 20/38, Avg Loss: 2.0626, Avg Regression Loss 0.5735, Avg Classification Loss: 1.4891\n",
            "2023-03-07 02:05:45 - Epoch: 24, Step: 30/38, Avg Loss: 2.3710, Avg Regression Loss 0.5286, Avg Classification Loss: 1.8424\n",
            "2023-03-07 02:05:51 - Epoch: 24, Training Loss: 2.0773, Training Regression Loss 0.5760, Training Classification Loss: 1.5013\n",
            "2023-03-07 02:05:52 - Epoch: 24, Validation Loss: 1.3669, Validation Regression Loss 0.3468, Validation Classification Loss: 1.0201\n",
            "2023-03-07 02:05:52 - Saved model models/model0110/mb1-ssd-Epoch-24-Loss-1.3669283092021942.pth\n",
            "2023-03-07 02:06:06 - Epoch: 25, Step: 10/38, Avg Loss: 2.2086, Avg Regression Loss 0.5668, Avg Classification Loss: 1.6419\n",
            "2023-03-07 02:06:17 - Epoch: 25, Step: 20/38, Avg Loss: 2.1668, Avg Regression Loss 0.6077, Avg Classification Loss: 1.5592\n",
            "2023-03-07 02:06:28 - Epoch: 25, Step: 30/38, Avg Loss: 2.2135, Avg Regression Loss 0.5761, Avg Classification Loss: 1.6374\n",
            "2023-03-07 02:06:34 - Epoch: 25, Training Loss: 2.2010, Training Regression Loss 0.5886, Training Classification Loss: 1.6125\n",
            "2023-03-07 02:06:36 - Epoch: 25, Validation Loss: 1.3597, Validation Regression Loss 0.4119, Validation Classification Loss: 0.9478\n",
            "2023-03-07 02:06:36 - Saved model models/model0110/mb1-ssd-Epoch-25-Loss-1.3597324788570404.pth\n",
            "2023-03-07 02:06:51 - Epoch: 26, Step: 10/38, Avg Loss: 1.8650, Avg Regression Loss 0.4510, Avg Classification Loss: 1.4140\n",
            "2023-03-07 02:07:02 - Epoch: 26, Step: 20/38, Avg Loss: 2.1935, Avg Regression Loss 0.7295, Avg Classification Loss: 1.4640\n",
            "2023-03-07 02:07:12 - Epoch: 26, Step: 30/38, Avg Loss: 1.8744, Avg Regression Loss 0.5418, Avg Classification Loss: 1.3326\n",
            "2023-03-07 02:07:19 - Epoch: 26, Training Loss: 1.8676, Training Regression Loss 0.5547, Training Classification Loss: 1.3130\n",
            "2023-03-07 02:07:21 - Epoch: 26, Validation Loss: 1.2012, Validation Regression Loss 0.2946, Validation Classification Loss: 0.9066\n",
            "2023-03-07 02:07:21 - Saved model models/model0110/mb1-ssd-Epoch-26-Loss-1.201164796948433.pth\n",
            "2023-03-07 02:07:34 - Epoch: 27, Step: 10/38, Avg Loss: 1.8283, Avg Regression Loss 0.4510, Avg Classification Loss: 1.3772\n",
            "2023-03-07 02:07:43 - Epoch: 27, Step: 20/38, Avg Loss: 1.7540, Avg Regression Loss 0.4665, Avg Classification Loss: 1.2875\n",
            "2023-03-07 02:07:54 - Epoch: 27, Step: 30/38, Avg Loss: 1.2636, Avg Regression Loss 0.2966, Avg Classification Loss: 0.9670\n",
            "2023-03-07 02:08:01 - Epoch: 27, Training Loss: 1.5769, Training Regression Loss 0.4142, Training Classification Loss: 1.1627\n",
            "2023-03-07 02:08:03 - Epoch: 27, Validation Loss: 1.0755, Validation Regression Loss 0.2199, Validation Classification Loss: 0.8556\n",
            "2023-03-07 02:08:03 - Saved model models/model0110/mb1-ssd-Epoch-27-Loss-1.0754704475402832.pth\n",
            "2023-03-07 02:08:16 - Epoch: 28, Step: 10/38, Avg Loss: 1.9770, Avg Regression Loss 0.5038, Avg Classification Loss: 1.4732\n",
            "2023-03-07 02:08:26 - Epoch: 28, Step: 20/38, Avg Loss: 1.5970, Avg Regression Loss 0.4564, Avg Classification Loss: 1.1407\n",
            "2023-03-07 02:08:36 - Epoch: 28, Step: 30/38, Avg Loss: 1.5469, Avg Regression Loss 0.4581, Avg Classification Loss: 1.0888\n",
            "2023-03-07 02:08:44 - Epoch: 28, Training Loss: 1.6943, Training Regression Loss 0.4742, Training Classification Loss: 1.2201\n",
            "2023-03-07 02:08:45 - Epoch: 28, Validation Loss: 1.1042, Validation Regression Loss 0.2781, Validation Classification Loss: 0.8261\n",
            "2023-03-07 02:08:45 - Saved model models/model0110/mb1-ssd-Epoch-28-Loss-1.1041830331087112.pth\n",
            "2023-03-07 02:08:59 - Epoch: 29, Step: 10/38, Avg Loss: 1.9138, Avg Regression Loss 0.6029, Avg Classification Loss: 1.3109\n",
            "2023-03-07 02:09:09 - Epoch: 29, Step: 20/38, Avg Loss: 1.7699, Avg Regression Loss 0.5213, Avg Classification Loss: 1.2486\n",
            "2023-03-07 02:09:20 - Epoch: 29, Step: 30/38, Avg Loss: 1.6271, Avg Regression Loss 0.5781, Avg Classification Loss: 1.0490\n",
            "2023-03-07 02:09:28 - Epoch: 29, Training Loss: 1.7263, Training Regression Loss 0.5297, Training Classification Loss: 1.1966\n",
            "2023-03-07 02:09:29 - Epoch: 29, Validation Loss: 1.2567, Validation Regression Loss 0.3055, Validation Classification Loss: 0.9512\n",
            "2023-03-07 02:09:29 - Saved model models/model0110/mb1-ssd-Epoch-29-Loss-1.2567008584737778.pth\n",
            "2023-03-07 02:09:42 - Epoch: 30, Step: 10/38, Avg Loss: 1.4914, Avg Regression Loss 0.3643, Avg Classification Loss: 1.1271\n",
            "2023-03-07 02:09:53 - Epoch: 30, Step: 20/38, Avg Loss: 1.8136, Avg Regression Loss 0.5389, Avg Classification Loss: 1.2747\n",
            "2023-03-07 02:10:02 - Epoch: 30, Step: 30/38, Avg Loss: 1.5155, Avg Regression Loss 0.4846, Avg Classification Loss: 1.0309\n",
            "2023-03-07 02:10:10 - Epoch: 30, Training Loss: 1.6304, Training Regression Loss 0.4673, Training Classification Loss: 1.1631\n",
            "2023-03-07 02:10:11 - Epoch: 30, Validation Loss: 1.1161, Validation Regression Loss 0.2672, Validation Classification Loss: 0.8489\n",
            "2023-03-07 02:10:12 - Saved model models/model0110/mb1-ssd-Epoch-30-Loss-1.1160995811223984.pth\n",
            "2023-03-07 02:10:27 - Epoch: 31, Step: 10/38, Avg Loss: 1.5978, Avg Regression Loss 0.4560, Avg Classification Loss: 1.1418\n",
            "2023-03-07 02:10:38 - Epoch: 31, Step: 20/38, Avg Loss: 1.9459, Avg Regression Loss 0.5773, Avg Classification Loss: 1.3685\n",
            "2023-03-07 02:10:48 - Epoch: 31, Step: 30/38, Avg Loss: 1.6809, Avg Regression Loss 0.4657, Avg Classification Loss: 1.2152\n",
            "2023-03-07 02:10:55 - Epoch: 31, Training Loss: 1.6392, Training Regression Loss 0.4562, Training Classification Loss: 1.1830\n",
            "2023-03-07 02:10:56 - Epoch: 31, Validation Loss: 0.9365, Validation Regression Loss 0.2160, Validation Classification Loss: 0.7205\n",
            "2023-03-07 02:10:56 - Saved model models/model0110/mb1-ssd-Epoch-31-Loss-0.936544731259346.pth\n",
            "2023-03-07 02:11:10 - Epoch: 32, Step: 10/38, Avg Loss: 1.6510, Avg Regression Loss 0.4635, Avg Classification Loss: 1.1875\n",
            "2023-03-07 02:11:21 - Epoch: 32, Step: 20/38, Avg Loss: 1.5508, Avg Regression Loss 0.4104, Avg Classification Loss: 1.1403\n",
            "2023-03-07 02:11:32 - Epoch: 32, Step: 30/38, Avg Loss: 1.8647, Avg Regression Loss 0.6032, Avg Classification Loss: 1.2615\n",
            "2023-03-07 02:11:38 - Epoch: 32, Training Loss: 1.6166, Training Regression Loss 0.4847, Training Classification Loss: 1.1319\n",
            "2023-03-07 02:11:39 - Epoch: 32, Validation Loss: 1.1322, Validation Regression Loss 0.2162, Validation Classification Loss: 0.9160\n",
            "2023-03-07 02:11:39 - Saved model models/model0110/mb1-ssd-Epoch-32-Loss-1.13216033577919.pth\n",
            "2023-03-07 02:11:52 - Epoch: 33, Step: 10/38, Avg Loss: 1.8261, Avg Regression Loss 0.6038, Avg Classification Loss: 1.2223\n",
            "2023-03-07 02:12:04 - Epoch: 33, Step: 20/38, Avg Loss: 1.6799, Avg Regression Loss 0.5436, Avg Classification Loss: 1.1363\n",
            "2023-03-07 02:12:14 - Epoch: 33, Step: 30/38, Avg Loss: 1.7050, Avg Regression Loss 0.3406, Avg Classification Loss: 1.3644\n",
            "2023-03-07 02:12:20 - Epoch: 33, Training Loss: 1.7103, Training Regression Loss 0.4719, Training Classification Loss: 1.2385\n",
            "2023-03-07 02:12:22 - Epoch: 33, Validation Loss: 1.1744, Validation Regression Loss 0.2997, Validation Classification Loss: 0.8747\n",
            "2023-03-07 02:12:22 - Saved model models/model0110/mb1-ssd-Epoch-33-Loss-1.174371600151062.pth\n",
            "2023-03-07 02:12:35 - Epoch: 34, Step: 10/38, Avg Loss: 1.7324, Avg Regression Loss 0.4559, Avg Classification Loss: 1.2765\n",
            "2023-03-07 02:12:46 - Epoch: 34, Step: 20/38, Avg Loss: 1.2864, Avg Regression Loss 0.3560, Avg Classification Loss: 0.9304\n",
            "2023-03-07 02:12:57 - Epoch: 34, Step: 30/38, Avg Loss: 2.2427, Avg Regression Loss 0.5618, Avg Classification Loss: 1.6808\n",
            "2023-03-07 02:13:03 - Epoch: 34, Training Loss: 1.6272, Training Regression Loss 0.4224, Training Classification Loss: 1.2048\n",
            "2023-03-07 02:13:05 - Epoch: 34, Validation Loss: 1.2336, Validation Regression Loss 0.3617, Validation Classification Loss: 0.8719\n",
            "2023-03-07 02:13:05 - Saved model models/model0110/mb1-ssd-Epoch-34-Loss-1.2336001098155975.pth\n",
            "2023-03-07 02:13:18 - Epoch: 35, Step: 10/38, Avg Loss: 2.1391, Avg Regression Loss 0.6524, Avg Classification Loss: 1.4867\n",
            "2023-03-07 02:13:29 - Epoch: 35, Step: 20/38, Avg Loss: 1.9614, Avg Regression Loss 0.6250, Avg Classification Loss: 1.3364\n",
            "2023-03-07 02:13:40 - Epoch: 35, Step: 30/38, Avg Loss: 2.1708, Avg Regression Loss 0.5985, Avg Classification Loss: 1.5724\n",
            "2023-03-07 02:13:46 - Epoch: 35, Training Loss: 1.9306, Training Regression Loss 0.5514, Training Classification Loss: 1.3791\n",
            "2023-03-07 02:13:50 - Epoch: 35, Validation Loss: 1.1222, Validation Regression Loss 0.2687, Validation Classification Loss: 0.8535\n",
            "2023-03-07 02:13:50 - Saved model models/model0110/mb1-ssd-Epoch-35-Loss-1.1221961975097656.pth\n",
            "2023-03-07 02:14:07 - Epoch: 36, Step: 10/38, Avg Loss: 2.0785, Avg Regression Loss 0.5831, Avg Classification Loss: 1.4954\n",
            "2023-03-07 02:14:17 - Epoch: 36, Step: 20/38, Avg Loss: 1.9596, Avg Regression Loss 0.7152, Avg Classification Loss: 1.2443\n",
            "2023-03-07 02:14:27 - Epoch: 36, Step: 30/38, Avg Loss: 1.3130, Avg Regression Loss 0.3109, Avg Classification Loss: 1.0021\n",
            "2023-03-07 02:14:35 - Epoch: 36, Training Loss: 1.6828, Training Regression Loss 0.5012, Training Classification Loss: 1.1816\n",
            "2023-03-07 02:14:36 - Epoch: 36, Validation Loss: 1.3854, Validation Regression Loss 0.3892, Validation Classification Loss: 0.9963\n",
            "2023-03-07 02:14:36 - Saved model models/model0110/mb1-ssd-Epoch-36-Loss-1.3854394555091858.pth\n",
            "2023-03-07 02:14:50 - Epoch: 37, Step: 10/38, Avg Loss: 1.6313, Avg Regression Loss 0.4306, Avg Classification Loss: 1.2007\n",
            "2023-03-07 02:15:00 - Epoch: 37, Step: 20/38, Avg Loss: 2.0706, Avg Regression Loss 0.5084, Avg Classification Loss: 1.5622\n",
            "2023-03-07 02:15:10 - Epoch: 37, Step: 30/38, Avg Loss: 1.3212, Avg Regression Loss 0.3220, Avg Classification Loss: 0.9992\n",
            "2023-03-07 02:15:18 - Epoch: 37, Training Loss: 1.5947, Training Regression Loss 0.4101, Training Classification Loss: 1.1846\n",
            "2023-03-07 02:15:19 - Epoch: 37, Validation Loss: 1.1124, Validation Regression Loss 0.2080, Validation Classification Loss: 0.9043\n",
            "2023-03-07 02:15:19 - Saved model models/model0110/mb1-ssd-Epoch-37-Loss-1.112367182970047.pth\n",
            "2023-03-07 02:15:33 - Epoch: 38, Step: 10/38, Avg Loss: 1.3921, Avg Regression Loss 0.3503, Avg Classification Loss: 1.0418\n",
            "2023-03-07 02:15:43 - Epoch: 38, Step: 20/38, Avg Loss: 1.4187, Avg Regression Loss 0.2940, Avg Classification Loss: 1.1247\n",
            "2023-03-07 02:15:53 - Epoch: 38, Step: 30/38, Avg Loss: 2.1420, Avg Regression Loss 0.5521, Avg Classification Loss: 1.5899\n",
            "2023-03-07 02:16:01 - Epoch: 38, Training Loss: 1.6095, Training Regression Loss 0.3936, Training Classification Loss: 1.2159\n",
            "2023-03-07 02:16:02 - Epoch: 38, Validation Loss: 1.0169, Validation Regression Loss 0.2108, Validation Classification Loss: 0.8061\n",
            "2023-03-07 02:16:02 - Saved model models/model0110/mb1-ssd-Epoch-38-Loss-1.0168652832508087.pth\n",
            "2023-03-07 02:16:15 - Epoch: 39, Step: 10/38, Avg Loss: 2.1822, Avg Regression Loss 0.7684, Avg Classification Loss: 1.4137\n",
            "2023-03-07 02:16:26 - Epoch: 39, Step: 20/38, Avg Loss: 1.2451, Avg Regression Loss 0.3762, Avg Classification Loss: 0.8690\n",
            "2023-03-07 02:16:36 - Epoch: 39, Step: 30/38, Avg Loss: 1.7347, Avg Regression Loss 0.3527, Avg Classification Loss: 1.3819\n",
            "2023-03-07 02:16:43 - Epoch: 39, Training Loss: 1.6944, Training Regression Loss 0.4733, Training Classification Loss: 1.2211\n",
            "2023-03-07 02:16:44 - Epoch: 39, Validation Loss: 1.0081, Validation Regression Loss 0.2267, Validation Classification Loss: 0.7814\n",
            "2023-03-07 02:16:44 - Saved model models/model0110/mb1-ssd-Epoch-39-Loss-1.008106142282486.pth\n",
            "2023-03-07 02:16:58 - Epoch: 40, Step: 10/38, Avg Loss: 1.7112, Avg Regression Loss 0.3285, Avg Classification Loss: 1.3827\n",
            "2023-03-07 02:17:09 - Epoch: 40, Step: 20/38, Avg Loss: 1.4010, Avg Regression Loss 0.3334, Avg Classification Loss: 1.0676\n",
            "2023-03-07 02:17:19 - Epoch: 40, Step: 30/38, Avg Loss: 1.4469, Avg Regression Loss 0.3717, Avg Classification Loss: 1.0752\n",
            "2023-03-07 02:17:27 - Epoch: 40, Training Loss: 1.4925, Training Regression Loss 0.3416, Training Classification Loss: 1.1510\n",
            "2023-03-07 02:17:28 - Epoch: 40, Validation Loss: 1.0722, Validation Regression Loss 0.2495, Validation Classification Loss: 0.8227\n",
            "2023-03-07 02:17:28 - Saved model models/model0110/mb1-ssd-Epoch-40-Loss-1.0721925050020218.pth\n",
            "2023-03-07 02:17:42 - Epoch: 41, Step: 10/38, Avg Loss: 1.9072, Avg Regression Loss 0.5685, Avg Classification Loss: 1.3387\n",
            "2023-03-07 02:17:53 - Epoch: 41, Step: 20/38, Avg Loss: 1.4592, Avg Regression Loss 0.3597, Avg Classification Loss: 1.0995\n",
            "2023-03-07 02:18:04 - Epoch: 41, Step: 30/38, Avg Loss: 1.4038, Avg Regression Loss 0.3516, Avg Classification Loss: 1.0522\n",
            "2023-03-07 02:18:10 - Epoch: 41, Training Loss: 1.5355, Training Regression Loss 0.4178, Training Classification Loss: 1.1176\n",
            "2023-03-07 02:18:11 - Epoch: 41, Validation Loss: 1.0380, Validation Regression Loss 0.2059, Validation Classification Loss: 0.8321\n",
            "2023-03-07 02:18:11 - Saved model models/model0110/mb1-ssd-Epoch-41-Loss-1.0380002409219742.pth\n",
            "2023-03-07 02:18:25 - Epoch: 42, Step: 10/38, Avg Loss: 1.5978, Avg Regression Loss 0.4343, Avg Classification Loss: 1.1635\n",
            "2023-03-07 02:18:36 - Epoch: 42, Step: 20/38, Avg Loss: 1.5476, Avg Regression Loss 0.4386, Avg Classification Loss: 1.1090\n",
            "2023-03-07 02:18:47 - Epoch: 42, Step: 30/38, Avg Loss: 1.8175, Avg Regression Loss 0.3544, Avg Classification Loss: 1.4631\n",
            "2023-03-07 02:18:53 - Epoch: 42, Training Loss: 1.6082, Training Regression Loss 0.3885, Training Classification Loss: 1.2197\n",
            "2023-03-07 02:18:54 - Epoch: 42, Validation Loss: 1.1841, Validation Regression Loss 0.2434, Validation Classification Loss: 0.9407\n",
            "2023-03-07 02:18:54 - Saved model models/model0110/mb1-ssd-Epoch-42-Loss-1.184124544262886.pth\n",
            "2023-03-07 02:19:08 - Epoch: 43, Step: 10/38, Avg Loss: 2.0599, Avg Regression Loss 0.4972, Avg Classification Loss: 1.5627\n",
            "2023-03-07 02:19:19 - Epoch: 43, Step: 20/38, Avg Loss: 1.2850, Avg Regression Loss 0.3927, Avg Classification Loss: 0.8923\n",
            "2023-03-07 02:19:30 - Epoch: 43, Step: 30/38, Avg Loss: 1.4785, Avg Regression Loss 0.3687, Avg Classification Loss: 1.1098\n",
            "2023-03-07 02:19:36 - Epoch: 43, Training Loss: 1.6019, Training Regression Loss 0.4382, Training Classification Loss: 1.1637\n",
            "2023-03-07 02:19:38 - Epoch: 43, Validation Loss: 0.9754, Validation Regression Loss 0.2320, Validation Classification Loss: 0.7434\n",
            "2023-03-07 02:19:38 - Saved model models/model0110/mb1-ssd-Epoch-43-Loss-0.9753546565771103.pth\n",
            "2023-03-07 02:19:51 - Epoch: 44, Step: 10/38, Avg Loss: 1.8645, Avg Regression Loss 0.6361, Avg Classification Loss: 1.2284\n",
            "2023-03-07 02:20:01 - Epoch: 44, Step: 20/38, Avg Loss: 1.7071, Avg Regression Loss 0.4268, Avg Classification Loss: 1.2803\n",
            "2023-03-07 02:20:12 - Epoch: 44, Step: 30/38, Avg Loss: 1.3499, Avg Regression Loss 0.3207, Avg Classification Loss: 1.0292\n",
            "2023-03-07 02:20:18 - Epoch: 44, Training Loss: 1.5402, Training Regression Loss 0.4221, Training Classification Loss: 1.1181\n",
            "2023-03-07 02:20:20 - Epoch: 44, Validation Loss: 1.1344, Validation Regression Loss 0.2020, Validation Classification Loss: 0.9324\n",
            "2023-03-07 02:20:20 - Saved model models/model0110/mb1-ssd-Epoch-44-Loss-1.1344405114650726.pth\n",
            "2023-03-07 02:20:34 - Epoch: 45, Step: 10/38, Avg Loss: 1.4026, Avg Regression Loss 0.3276, Avg Classification Loss: 1.0750\n",
            "2023-03-07 02:20:43 - Epoch: 45, Step: 20/38, Avg Loss: 1.3973, Avg Regression Loss 0.3835, Avg Classification Loss: 1.0138\n",
            "2023-03-07 02:20:56 - Epoch: 45, Step: 30/38, Avg Loss: 1.4323, Avg Regression Loss 0.3592, Avg Classification Loss: 1.0731\n",
            "2023-03-07 02:21:03 - Epoch: 45, Training Loss: 1.3402, Training Regression Loss 0.3490, Training Classification Loss: 0.9912\n",
            "2023-03-07 02:21:05 - Epoch: 45, Validation Loss: 1.0799, Validation Regression Loss 0.2635, Validation Classification Loss: 0.8164\n",
            "2023-03-07 02:21:05 - Saved model models/model0110/mb1-ssd-Epoch-45-Loss-1.0798840075731277.pth\n",
            "2023-03-07 02:21:18 - Epoch: 46, Step: 10/38, Avg Loss: 1.8453, Avg Regression Loss 0.3603, Avg Classification Loss: 1.4850\n",
            "2023-03-07 02:21:28 - Epoch: 46, Step: 20/38, Avg Loss: 1.3496, Avg Regression Loss 0.3298, Avg Classification Loss: 1.0198\n",
            "2023-03-07 02:21:38 - Epoch: 46, Step: 30/38, Avg Loss: 2.0427, Avg Regression Loss 0.5238, Avg Classification Loss: 1.5188\n",
            "2023-03-07 02:21:46 - Epoch: 46, Training Loss: 1.6383, Training Regression Loss 0.3834, Training Classification Loss: 1.2549\n",
            "2023-03-07 02:21:47 - Epoch: 46, Validation Loss: 1.0401, Validation Regression Loss 0.2409, Validation Classification Loss: 0.7992\n",
            "2023-03-07 02:21:47 - Saved model models/model0110/mb1-ssd-Epoch-46-Loss-1.0401161015033722.pth\n",
            "2023-03-07 02:22:01 - Epoch: 47, Step: 10/38, Avg Loss: 1.4635, Avg Regression Loss 0.2953, Avg Classification Loss: 1.1682\n",
            "2023-03-07 02:22:12 - Epoch: 47, Step: 20/38, Avg Loss: 2.2064, Avg Regression Loss 0.7331, Avg Classification Loss: 1.4733\n",
            "2023-03-07 02:22:21 - Epoch: 47, Step: 30/38, Avg Loss: 1.7287, Avg Regression Loss 0.4910, Avg Classification Loss: 1.2377\n",
            "2023-03-07 02:22:28 - Epoch: 47, Training Loss: 1.6701, Training Regression Loss 0.4716, Training Classification Loss: 1.1986\n",
            "2023-03-07 02:22:30 - Epoch: 47, Validation Loss: 1.1340, Validation Regression Loss 0.3061, Validation Classification Loss: 0.8278\n",
            "2023-03-07 02:22:30 - Saved model models/model0110/mb1-ssd-Epoch-47-Loss-1.1339618563652039.pth\n",
            "2023-03-07 02:22:43 - Epoch: 48, Step: 10/38, Avg Loss: 1.9752, Avg Regression Loss 0.5080, Avg Classification Loss: 1.4672\n",
            "2023-03-07 02:22:54 - Epoch: 48, Step: 20/38, Avg Loss: 1.3663, Avg Regression Loss 0.2726, Avg Classification Loss: 1.0936\n",
            "2023-03-07 02:23:03 - Epoch: 48, Step: 30/38, Avg Loss: 1.2164, Avg Regression Loss 0.2797, Avg Classification Loss: 0.9368\n",
            "2023-03-07 02:23:10 - Epoch: 48, Training Loss: 1.4380, Training Regression Loss 0.3317, Training Classification Loss: 1.1064\n",
            "2023-03-07 02:23:12 - Epoch: 48, Validation Loss: 1.0527, Validation Regression Loss 0.2244, Validation Classification Loss: 0.8283\n",
            "2023-03-07 02:23:12 - Saved model models/model0110/mb1-ssd-Epoch-48-Loss-1.0527486205101013.pth\n",
            "2023-03-07 02:23:25 - Epoch: 49, Step: 10/38, Avg Loss: 1.6699, Avg Regression Loss 0.3954, Avg Classification Loss: 1.2745\n",
            "2023-03-07 02:23:36 - Epoch: 49, Step: 20/38, Avg Loss: 1.3367, Avg Regression Loss 0.2962, Avg Classification Loss: 1.0405\n",
            "2023-03-07 02:23:46 - Epoch: 49, Step: 30/38, Avg Loss: 1.4330, Avg Regression Loss 0.3839, Avg Classification Loss: 1.0491\n",
            "2023-03-07 02:23:53 - Epoch: 49, Training Loss: 1.4493, Training Regression Loss 0.3657, Training Classification Loss: 1.0836\n",
            "2023-03-07 02:23:54 - Epoch: 49, Validation Loss: 1.0769, Validation Regression Loss 0.2120, Validation Classification Loss: 0.8650\n",
            "2023-03-07 02:23:54 - Saved model models/model0110/mb1-ssd-Epoch-49-Loss-1.0769242197275162.pth\n",
            "2023-03-07 02:24:11 - Epoch: 50, Step: 10/38, Avg Loss: 1.7329, Avg Regression Loss 0.4042, Avg Classification Loss: 1.3287\n",
            "2023-03-07 02:24:23 - Epoch: 50, Step: 20/38, Avg Loss: 1.7333, Avg Regression Loss 0.4892, Avg Classification Loss: 1.2441\n",
            "2023-03-07 02:24:34 - Epoch: 50, Step: 30/38, Avg Loss: 1.3405, Avg Regression Loss 0.3071, Avg Classification Loss: 1.0334\n",
            "2023-03-07 02:24:40 - Epoch: 50, Training Loss: 1.4889, Training Regression Loss 0.3719, Training Classification Loss: 1.1170\n",
            "2023-03-07 02:24:42 - Epoch: 50, Validation Loss: 0.9913, Validation Regression Loss 0.1955, Validation Classification Loss: 0.7958\n",
            "2023-03-07 02:24:42 - Saved model models/model0110/mb1-ssd-Epoch-50-Loss-0.9913188964128494.pth\n",
            "2023-03-07 02:24:55 - Epoch: 51, Step: 10/38, Avg Loss: 1.4192, Avg Regression Loss 0.2790, Avg Classification Loss: 1.1402\n",
            "2023-03-07 02:25:06 - Epoch: 51, Step: 20/38, Avg Loss: 1.4345, Avg Regression Loss 0.3659, Avg Classification Loss: 1.0687\n",
            "2023-03-07 02:25:17 - Epoch: 51, Step: 30/38, Avg Loss: 1.4298, Avg Regression Loss 0.3113, Avg Classification Loss: 1.1185\n",
            "2023-03-07 02:25:23 - Epoch: 51, Training Loss: 1.4719, Training Regression Loss 0.3280, Training Classification Loss: 1.1439\n",
            "2023-03-07 02:25:25 - Epoch: 51, Validation Loss: 0.9506, Validation Regression Loss 0.2318, Validation Classification Loss: 0.7188\n",
            "2023-03-07 02:25:25 - Saved model models/model0110/mb1-ssd-Epoch-51-Loss-0.950552687048912.pth\n",
            "2023-03-07 02:25:38 - Epoch: 52, Step: 10/38, Avg Loss: 1.3583, Avg Regression Loss 0.3163, Avg Classification Loss: 1.0421\n",
            "2023-03-07 02:25:47 - Epoch: 52, Step: 20/38, Avg Loss: 1.2947, Avg Regression Loss 0.3611, Avg Classification Loss: 0.9335\n",
            "2023-03-07 02:25:58 - Epoch: 52, Step: 30/38, Avg Loss: 1.5842, Avg Regression Loss 0.3210, Avg Classification Loss: 1.2632\n",
            "2023-03-07 02:26:06 - Epoch: 52, Training Loss: 1.3717, Training Regression Loss 0.3174, Training Classification Loss: 1.0544\n",
            "2023-03-07 02:26:07 - Epoch: 52, Validation Loss: 0.8843, Validation Regression Loss 0.1664, Validation Classification Loss: 0.7180\n",
            "2023-03-07 02:26:07 - Saved model models/model0110/mb1-ssd-Epoch-52-Loss-0.884321466088295.pth\n",
            "2023-03-07 02:26:20 - Epoch: 53, Step: 10/38, Avg Loss: 1.6407, Avg Regression Loss 0.4235, Avg Classification Loss: 1.2172\n",
            "2023-03-07 02:26:30 - Epoch: 53, Step: 20/38, Avg Loss: 1.3078, Avg Regression Loss 0.3491, Avg Classification Loss: 0.9586\n",
            "2023-03-07 02:26:40 - Epoch: 53, Step: 30/38, Avg Loss: 1.1928, Avg Regression Loss 0.2868, Avg Classification Loss: 0.9059\n",
            "2023-03-07 02:26:48 - Epoch: 53, Training Loss: 1.2908, Training Regression Loss 0.3238, Training Classification Loss: 0.9670\n",
            "2023-03-07 02:26:49 - Epoch: 53, Validation Loss: 0.9541, Validation Regression Loss 0.2250, Validation Classification Loss: 0.7291\n",
            "2023-03-07 02:26:49 - Saved model models/model0110/mb1-ssd-Epoch-53-Loss-0.954091340303421.pth\n",
            "2023-03-07 02:27:03 - Epoch: 54, Step: 10/38, Avg Loss: 1.3807, Avg Regression Loss 0.3668, Avg Classification Loss: 1.0139\n",
            "2023-03-07 02:27:13 - Epoch: 54, Step: 20/38, Avg Loss: 1.0672, Avg Regression Loss 0.2389, Avg Classification Loss: 0.8283\n",
            "2023-03-07 02:27:23 - Epoch: 54, Step: 30/38, Avg Loss: 1.5453, Avg Regression Loss 0.4228, Avg Classification Loss: 1.1226\n",
            "2023-03-07 02:27:30 - Epoch: 54, Training Loss: 1.2359, Training Regression Loss 0.3154, Training Classification Loss: 0.9204\n",
            "2023-03-07 02:27:32 - Epoch: 54, Validation Loss: 0.8856, Validation Regression Loss 0.1748, Validation Classification Loss: 0.7107\n",
            "2023-03-07 02:27:32 - Saved model models/model0110/mb1-ssd-Epoch-54-Loss-0.8855506628751755.pth\n",
            "2023-03-07 02:27:45 - Epoch: 55, Step: 10/38, Avg Loss: 1.4813, Avg Regression Loss 0.3189, Avg Classification Loss: 1.1624\n",
            "2023-03-07 02:27:56 - Epoch: 55, Step: 20/38, Avg Loss: 1.2488, Avg Regression Loss 0.2782, Avg Classification Loss: 0.9706\n",
            "2023-03-07 02:28:07 - Epoch: 55, Step: 30/38, Avg Loss: 1.3142, Avg Regression Loss 0.3364, Avg Classification Loss: 0.9778\n",
            "2023-03-07 02:28:15 - Epoch: 55, Training Loss: 1.3982, Training Regression Loss 0.3265, Training Classification Loss: 1.0717\n",
            "2023-03-07 02:28:16 - Epoch: 55, Validation Loss: 0.8977, Validation Regression Loss 0.1719, Validation Classification Loss: 0.7258\n",
            "2023-03-07 02:28:16 - Saved model models/model0110/mb1-ssd-Epoch-55-Loss-0.8976932018995285.pth\n",
            "2023-03-07 02:28:29 - Epoch: 56, Step: 10/38, Avg Loss: 0.9921, Avg Regression Loss 0.3048, Avg Classification Loss: 0.6873\n",
            "2023-03-07 02:28:40 - Epoch: 56, Step: 20/38, Avg Loss: 1.2045, Avg Regression Loss 0.2511, Avg Classification Loss: 0.9534\n",
            "2023-03-07 02:28:49 - Epoch: 56, Step: 30/38, Avg Loss: 1.1884, Avg Regression Loss 0.2255, Avg Classification Loss: 0.9629\n",
            "2023-03-07 02:28:56 - Epoch: 56, Training Loss: 1.1534, Training Regression Loss 0.2738, Training Classification Loss: 0.8796\n",
            "2023-03-07 02:28:58 - Epoch: 56, Validation Loss: 0.8953, Validation Regression Loss 0.1729, Validation Classification Loss: 0.7223\n",
            "2023-03-07 02:28:58 - Saved model models/model0110/mb1-ssd-Epoch-56-Loss-0.8952662199735641.pth\n",
            "2023-03-07 02:29:11 - Epoch: 57, Step: 10/38, Avg Loss: 1.6501, Avg Regression Loss 0.3621, Avg Classification Loss: 1.2880\n",
            "2023-03-07 02:29:22 - Epoch: 57, Step: 20/38, Avg Loss: 1.4345, Avg Regression Loss 0.3713, Avg Classification Loss: 1.0632\n",
            "2023-03-07 02:29:32 - Epoch: 57, Step: 30/38, Avg Loss: 1.2668, Avg Regression Loss 0.3046, Avg Classification Loss: 0.9622\n",
            "2023-03-07 02:29:39 - Epoch: 57, Training Loss: 1.3951, Training Regression Loss 0.3380, Training Classification Loss: 1.0571\n",
            "2023-03-07 02:29:41 - Epoch: 57, Validation Loss: 0.9158, Validation Regression Loss 0.1921, Validation Classification Loss: 0.7237\n",
            "2023-03-07 02:29:41 - Saved model models/model0110/mb1-ssd-Epoch-57-Loss-0.9157735109329224.pth\n",
            "2023-03-07 02:29:54 - Epoch: 58, Step: 10/38, Avg Loss: 1.2115, Avg Regression Loss 0.3053, Avg Classification Loss: 0.9062\n",
            "2023-03-07 02:30:05 - Epoch: 58, Step: 20/38, Avg Loss: 1.6540, Avg Regression Loss 0.3798, Avg Classification Loss: 1.2742\n",
            "2023-03-07 02:30:16 - Epoch: 58, Step: 30/38, Avg Loss: 1.3061, Avg Regression Loss 0.2769, Avg Classification Loss: 1.0292\n",
            "2023-03-07 02:30:22 - Epoch: 58, Training Loss: 1.3342, Training Regression Loss 0.3129, Training Classification Loss: 1.0213\n",
            "2023-03-07 02:30:23 - Epoch: 58, Validation Loss: 0.9156, Validation Regression Loss 0.1945, Validation Classification Loss: 0.7211\n",
            "2023-03-07 02:30:23 - Saved model models/model0110/mb1-ssd-Epoch-58-Loss-0.9155910015106201.pth\n",
            "2023-03-07 02:30:37 - Epoch: 59, Step: 10/38, Avg Loss: 1.4243, Avg Regression Loss 0.3705, Avg Classification Loss: 1.0539\n",
            "2023-03-07 02:30:48 - Epoch: 59, Step: 20/38, Avg Loss: 1.0292, Avg Regression Loss 0.2942, Avg Classification Loss: 0.7350\n",
            "2023-03-07 02:30:59 - Epoch: 59, Step: 30/38, Avg Loss: 1.2180, Avg Regression Loss 0.2534, Avg Classification Loss: 0.9647\n",
            "2023-03-07 02:31:05 - Epoch: 59, Training Loss: 1.1884, Training Regression Loss 0.2922, Training Classification Loss: 0.8962\n",
            "2023-03-07 02:31:07 - Epoch: 59, Validation Loss: 0.8879, Validation Regression Loss 0.1797, Validation Classification Loss: 0.7082\n",
            "2023-03-07 02:31:07 - Saved model models/model0110/mb1-ssd-Epoch-59-Loss-0.8878888338804245.pth\n",
            "2023-03-07 02:31:20 - Epoch: 60, Step: 10/38, Avg Loss: 1.3674, Avg Regression Loss 0.3108, Avg Classification Loss: 1.0566\n",
            "2023-03-07 02:31:32 - Epoch: 60, Step: 20/38, Avg Loss: 0.8864, Avg Regression Loss 0.1912, Avg Classification Loss: 0.6952\n",
            "2023-03-07 02:31:43 - Epoch: 60, Step: 30/38, Avg Loss: 1.5409, Avg Regression Loss 0.3632, Avg Classification Loss: 1.1776\n",
            "2023-03-07 02:31:49 - Epoch: 60, Training Loss: 1.1842, Training Regression Loss 0.2706, Training Classification Loss: 0.9136\n",
            "2023-03-07 02:31:52 - Epoch: 60, Validation Loss: 0.8348, Validation Regression Loss 0.1556, Validation Classification Loss: 0.6792\n",
            "2023-03-07 02:31:52 - Saved model models/model0110/mb1-ssd-Epoch-60-Loss-0.8347687125205994.pth\n",
            "2023-03-07 02:32:06 - Epoch: 61, Step: 10/38, Avg Loss: 1.0889, Avg Regression Loss 0.2602, Avg Classification Loss: 0.8288\n",
            "2023-03-07 02:32:16 - Epoch: 61, Step: 20/38, Avg Loss: 1.3328, Avg Regression Loss 0.3369, Avg Classification Loss: 0.9959\n",
            "2023-03-07 02:32:27 - Epoch: 61, Step: 30/38, Avg Loss: 1.3863, Avg Regression Loss 0.3978, Avg Classification Loss: 0.9885\n",
            "2023-03-07 02:32:34 - Epoch: 61, Training Loss: 1.2371, Training Regression Loss 0.3219, Training Classification Loss: 0.9152\n",
            "2023-03-07 02:32:36 - Epoch: 61, Validation Loss: 0.9614, Validation Regression Loss 0.1925, Validation Classification Loss: 0.7689\n",
            "2023-03-07 02:32:36 - Saved model models/model0110/mb1-ssd-Epoch-61-Loss-0.9613829702138901.pth\n",
            "2023-03-07 02:32:49 - Epoch: 62, Step: 10/38, Avg Loss: 1.4480, Avg Regression Loss 0.3327, Avg Classification Loss: 1.1154\n",
            "2023-03-07 02:32:59 - Epoch: 62, Step: 20/38, Avg Loss: 1.6083, Avg Regression Loss 0.3942, Avg Classification Loss: 1.2141\n",
            "2023-03-07 02:33:09 - Epoch: 62, Step: 30/38, Avg Loss: 0.9591, Avg Regression Loss 0.1953, Avg Classification Loss: 0.7638\n",
            "2023-03-07 02:33:17 - Epoch: 62, Training Loss: 1.2647, Training Regression Loss 0.2898, Training Classification Loss: 0.9749\n",
            "2023-03-07 02:33:18 - Epoch: 62, Validation Loss: 0.8415, Validation Regression Loss 0.1593, Validation Classification Loss: 0.6822\n",
            "2023-03-07 02:33:18 - Saved model models/model0110/mb1-ssd-Epoch-62-Loss-0.841469943523407.pth\n",
            "2023-03-07 02:33:32 - Epoch: 63, Step: 10/38, Avg Loss: 1.3015, Avg Regression Loss 0.2901, Avg Classification Loss: 1.0114\n",
            "2023-03-07 02:33:42 - Epoch: 63, Step: 20/38, Avg Loss: 1.4505, Avg Regression Loss 0.3186, Avg Classification Loss: 1.1319\n",
            "2023-03-07 02:33:51 - Epoch: 63, Step: 30/38, Avg Loss: 1.1174, Avg Regression Loss 0.2557, Avg Classification Loss: 0.8618\n",
            "2023-03-07 02:33:59 - Epoch: 63, Training Loss: 1.2929, Training Regression Loss 0.3036, Training Classification Loss: 0.9893\n",
            "2023-03-07 02:34:00 - Epoch: 63, Validation Loss: 0.9080, Validation Regression Loss 0.1839, Validation Classification Loss: 0.7241\n",
            "2023-03-07 02:34:00 - Saved model models/model0110/mb1-ssd-Epoch-63-Loss-0.9079746454954147.pth\n",
            "2023-03-07 02:34:18 - Epoch: 64, Step: 10/38, Avg Loss: 1.3605, Avg Regression Loss 0.2836, Avg Classification Loss: 1.0768\n",
            "2023-03-07 02:34:30 - Epoch: 64, Step: 20/38, Avg Loss: 1.3164, Avg Regression Loss 0.2784, Avg Classification Loss: 1.0380\n",
            "2023-03-07 02:34:40 - Epoch: 64, Step: 30/38, Avg Loss: 1.3155, Avg Regression Loss 0.2829, Avg Classification Loss: 1.0326\n",
            "2023-03-07 02:34:46 - Epoch: 64, Training Loss: 1.2363, Training Regression Loss 0.2683, Training Classification Loss: 0.9679\n",
            "2023-03-07 02:34:48 - Epoch: 64, Validation Loss: 0.7908, Validation Regression Loss 0.1339, Validation Classification Loss: 0.6569\n",
            "2023-03-07 02:34:48 - Saved model models/model0110/mb1-ssd-Epoch-64-Loss-0.7907895147800446.pth\n",
            "2023-03-07 02:35:04 - Epoch: 65, Step: 10/38, Avg Loss: 1.1756, Avg Regression Loss 0.3034, Avg Classification Loss: 0.8722\n",
            "2023-03-07 02:35:15 - Epoch: 65, Step: 20/38, Avg Loss: 1.1016, Avg Regression Loss 0.2086, Avg Classification Loss: 0.8930\n",
            "2023-03-07 02:35:26 - Epoch: 65, Step: 30/38, Avg Loss: 1.4604, Avg Regression Loss 0.3455, Avg Classification Loss: 1.1149\n",
            "2023-03-07 02:35:32 - Epoch: 65, Training Loss: 1.1652, Training Regression Loss 0.2653, Training Classification Loss: 0.8999\n",
            "2023-03-07 02:35:34 - Epoch: 65, Validation Loss: 0.9069, Validation Regression Loss 0.1422, Validation Classification Loss: 0.7646\n",
            "2023-03-07 02:35:35 - Saved model models/model0110/mb1-ssd-Epoch-65-Loss-0.9068653434514999.pth\n",
            "2023-03-07 02:35:49 - Epoch: 66, Step: 10/38, Avg Loss: 1.6566, Avg Regression Loss 0.3627, Avg Classification Loss: 1.2938\n",
            "2023-03-07 02:35:58 - Epoch: 66, Step: 20/38, Avg Loss: 1.2130, Avg Regression Loss 0.2023, Avg Classification Loss: 1.0107\n",
            "2023-03-07 02:36:09 - Epoch: 66, Step: 30/38, Avg Loss: 1.0595, Avg Regression Loss 0.2099, Avg Classification Loss: 0.8496\n",
            "2023-03-07 02:36:16 - Epoch: 66, Training Loss: 1.4306, Training Regression Loss 0.2777, Training Classification Loss: 1.1530\n",
            "2023-03-07 02:36:18 - Epoch: 66, Validation Loss: 0.8426, Validation Regression Loss 0.1404, Validation Classification Loss: 0.7023\n",
            "2023-03-07 02:36:18 - Saved model models/model0110/mb1-ssd-Epoch-66-Loss-0.8426427096128464.pth\n",
            "2023-03-07 02:36:31 - Epoch: 67, Step: 10/38, Avg Loss: 1.2960, Avg Regression Loss 0.2952, Avg Classification Loss: 1.0008\n",
            "2023-03-07 02:36:41 - Epoch: 67, Step: 20/38, Avg Loss: 1.4250, Avg Regression Loss 0.3148, Avg Classification Loss: 1.1102\n",
            "2023-03-07 02:36:51 - Epoch: 67, Step: 30/38, Avg Loss: 1.6636, Avg Regression Loss 0.3113, Avg Classification Loss: 1.3524\n",
            "2023-03-07 02:36:59 - Epoch: 67, Training Loss: 1.3560, Training Regression Loss 0.2946, Training Classification Loss: 1.0614\n",
            "2023-03-07 02:37:00 - Epoch: 67, Validation Loss: 0.8621, Validation Regression Loss 0.1607, Validation Classification Loss: 0.7014\n",
            "2023-03-07 02:37:00 - Saved model models/model0110/mb1-ssd-Epoch-67-Loss-0.862060934305191.pth\n",
            "2023-03-07 02:37:13 - Epoch: 68, Step: 10/38, Avg Loss: 1.6279, Avg Regression Loss 0.3787, Avg Classification Loss: 1.2493\n",
            "2023-03-07 02:37:25 - Epoch: 68, Step: 20/38, Avg Loss: 1.2830, Avg Regression Loss 0.2898, Avg Classification Loss: 0.9933\n",
            "2023-03-07 02:37:34 - Epoch: 68, Step: 30/38, Avg Loss: 1.0456, Avg Regression Loss 0.2424, Avg Classification Loss: 0.8032\n",
            "2023-03-07 02:37:42 - Epoch: 68, Training Loss: 1.2482, Training Regression Loss 0.2810, Training Classification Loss: 0.9672\n",
            "2023-03-07 02:37:43 - Epoch: 68, Validation Loss: 0.9060, Validation Regression Loss 0.1782, Validation Classification Loss: 0.7277\n",
            "2023-03-07 02:37:43 - Saved model models/model0110/mb1-ssd-Epoch-68-Loss-0.9059709906578064.pth\n",
            "2023-03-07 02:37:57 - Epoch: 69, Step: 10/38, Avg Loss: 1.3779, Avg Regression Loss 0.2856, Avg Classification Loss: 1.0923\n",
            "2023-03-07 02:38:08 - Epoch: 69, Step: 20/38, Avg Loss: 1.1184, Avg Regression Loss 0.2296, Avg Classification Loss: 0.8888\n",
            "2023-03-07 02:38:18 - Epoch: 69, Step: 30/38, Avg Loss: 1.0078, Avg Regression Loss 0.2209, Avg Classification Loss: 0.7869\n",
            "2023-03-07 02:38:25 - Epoch: 69, Training Loss: 1.1412, Training Regression Loss 0.2546, Training Classification Loss: 0.8866\n",
            "2023-03-07 02:38:26 - Epoch: 69, Validation Loss: 0.8754, Validation Regression Loss 0.1631, Validation Classification Loss: 0.7123\n",
            "2023-03-07 02:38:26 - Saved model models/model0110/mb1-ssd-Epoch-69-Loss-0.875378429889679.pth\n",
            "2023-03-07 02:38:41 - Epoch: 70, Step: 10/38, Avg Loss: 1.5744, Avg Regression Loss 0.3421, Avg Classification Loss: 1.2323\n",
            "2023-03-07 02:38:52 - Epoch: 70, Step: 20/38, Avg Loss: 1.0199, Avg Regression Loss 0.2199, Avg Classification Loss: 0.8000\n",
            "2023-03-07 02:39:03 - Epoch: 70, Step: 30/38, Avg Loss: 1.3132, Avg Regression Loss 0.3854, Avg Classification Loss: 0.9278\n",
            "2023-03-07 02:39:09 - Epoch: 70, Training Loss: 1.2563, Training Regression Loss 0.2880, Training Classification Loss: 0.9682\n",
            "2023-03-07 02:39:10 - Epoch: 70, Validation Loss: 0.9084, Validation Regression Loss 0.1587, Validation Classification Loss: 0.7498\n",
            "2023-03-07 02:39:11 - Saved model models/model0110/mb1-ssd-Epoch-70-Loss-0.9084496200084686.pth\n",
            "2023-03-07 02:39:23 - Epoch: 71, Step: 10/38, Avg Loss: 1.0026, Avg Regression Loss 0.1753, Avg Classification Loss: 0.8272\n",
            "2023-03-07 02:39:34 - Epoch: 71, Step: 20/38, Avg Loss: 1.1967, Avg Regression Loss 0.3132, Avg Classification Loss: 0.8835\n",
            "2023-03-07 02:39:45 - Epoch: 71, Step: 30/38, Avg Loss: 1.2265, Avg Regression Loss 0.2530, Avg Classification Loss: 0.9735\n",
            "2023-03-07 02:39:52 - Epoch: 71, Training Loss: 1.0886, Training Regression Loss 0.2250, Training Classification Loss: 0.8636\n",
            "2023-03-07 02:39:53 - Epoch: 71, Validation Loss: 0.8576, Validation Regression Loss 0.1669, Validation Classification Loss: 0.6907\n",
            "2023-03-07 02:39:53 - Saved model models/model0110/mb1-ssd-Epoch-71-Loss-0.8576316833496094.pth\n",
            "2023-03-07 02:40:07 - Epoch: 72, Step: 10/38, Avg Loss: 1.7262, Avg Regression Loss 0.3795, Avg Classification Loss: 1.3468\n",
            "2023-03-07 02:40:17 - Epoch: 72, Step: 20/38, Avg Loss: 1.2449, Avg Regression Loss 0.2511, Avg Classification Loss: 0.9938\n",
            "2023-03-07 02:40:28 - Epoch: 72, Step: 30/38, Avg Loss: 1.2897, Avg Regression Loss 0.2690, Avg Classification Loss: 1.0207\n",
            "2023-03-07 02:40:35 - Epoch: 72, Training Loss: 1.3201, Training Regression Loss 0.2810, Training Classification Loss: 1.0391\n",
            "2023-03-07 02:40:37 - Epoch: 72, Validation Loss: 0.7905, Validation Regression Loss 0.1308, Validation Classification Loss: 0.6598\n",
            "2023-03-07 02:40:37 - Saved model models/model0110/mb1-ssd-Epoch-72-Loss-0.7905288934707642.pth\n",
            "2023-03-07 02:40:50 - Epoch: 73, Step: 10/38, Avg Loss: 1.6878, Avg Regression Loss 0.3799, Avg Classification Loss: 1.3078\n",
            "2023-03-07 02:41:00 - Epoch: 73, Step: 20/38, Avg Loss: 1.0783, Avg Regression Loss 0.2207, Avg Classification Loss: 0.8577\n",
            "2023-03-07 02:41:11 - Epoch: 73, Step: 30/38, Avg Loss: 1.1644, Avg Regression Loss 0.2049, Avg Classification Loss: 0.9596\n",
            "2023-03-07 02:41:19 - Epoch: 73, Training Loss: 1.2876, Training Regression Loss 0.2663, Training Classification Loss: 1.0214\n",
            "2023-03-07 02:41:20 - Epoch: 73, Validation Loss: 0.8045, Validation Regression Loss 0.1501, Validation Classification Loss: 0.6544\n",
            "2023-03-07 02:41:20 - Saved model models/model0110/mb1-ssd-Epoch-73-Loss-0.8045186102390289.pth\n",
            "2023-03-07 02:41:33 - Epoch: 74, Step: 10/38, Avg Loss: 1.0257, Avg Regression Loss 0.2150, Avg Classification Loss: 0.8107\n",
            "2023-03-07 02:41:44 - Epoch: 74, Step: 20/38, Avg Loss: 1.0141, Avg Regression Loss 0.2363, Avg Classification Loss: 0.7778\n",
            "2023-03-07 02:41:54 - Epoch: 74, Step: 30/38, Avg Loss: 1.2287, Avg Regression Loss 0.3527, Avg Classification Loss: 0.8760\n",
            "2023-03-07 02:42:02 - Epoch: 74, Training Loss: 1.1039, Training Regression Loss 0.2593, Training Classification Loss: 0.8446\n",
            "2023-03-07 02:42:03 - Epoch: 74, Validation Loss: 0.8227, Validation Regression Loss 0.1371, Validation Classification Loss: 0.6857\n",
            "2023-03-07 02:42:03 - Saved model models/model0110/mb1-ssd-Epoch-74-Loss-0.8227449506521225.pth\n",
            "2023-03-07 02:42:18 - Epoch: 75, Step: 10/38, Avg Loss: 1.2211, Avg Regression Loss 0.2363, Avg Classification Loss: 0.9848\n",
            "2023-03-07 02:42:29 - Epoch: 75, Step: 20/38, Avg Loss: 1.1224, Avg Regression Loss 0.2347, Avg Classification Loss: 0.8877\n",
            "2023-03-07 02:42:38 - Epoch: 75, Step: 30/38, Avg Loss: 1.0019, Avg Regression Loss 0.1751, Avg Classification Loss: 0.8268\n",
            "2023-03-07 02:42:46 - Epoch: 75, Training Loss: 1.0624, Training Regression Loss 0.2041, Training Classification Loss: 0.8582\n",
            "2023-03-07 02:42:47 - Epoch: 75, Validation Loss: 0.7791, Validation Regression Loss 0.1300, Validation Classification Loss: 0.6490\n",
            "2023-03-07 02:42:47 - Saved model models/model0110/mb1-ssd-Epoch-75-Loss-0.7790711522102356.pth\n",
            "2023-03-07 02:43:00 - Epoch: 76, Step: 10/38, Avg Loss: 1.3076, Avg Regression Loss 0.2303, Avg Classification Loss: 1.0773\n",
            "2023-03-07 02:43:11 - Epoch: 76, Step: 20/38, Avg Loss: 1.3014, Avg Regression Loss 0.2769, Avg Classification Loss: 1.0245\n",
            "2023-03-07 02:43:21 - Epoch: 76, Step: 30/38, Avg Loss: 1.1778, Avg Regression Loss 0.2478, Avg Classification Loss: 0.9300\n",
            "2023-03-07 02:43:28 - Epoch: 76, Training Loss: 1.2253, Training Regression Loss 0.2457, Training Classification Loss: 0.9796\n",
            "2023-03-07 02:43:29 - Epoch: 76, Validation Loss: 0.8032, Validation Regression Loss 0.1419, Validation Classification Loss: 0.6613\n",
            "2023-03-07 02:43:30 - Saved model models/model0110/mb1-ssd-Epoch-76-Loss-0.8031578660011292.pth\n",
            "2023-03-07 02:43:43 - Epoch: 77, Step: 10/38, Avg Loss: 1.2636, Avg Regression Loss 0.1974, Avg Classification Loss: 1.0661\n",
            "2023-03-07 02:43:54 - Epoch: 77, Step: 20/38, Avg Loss: 1.3231, Avg Regression Loss 0.1964, Avg Classification Loss: 1.1267\n",
            "2023-03-07 02:44:05 - Epoch: 77, Step: 30/38, Avg Loss: 1.2520, Avg Regression Loss 0.3591, Avg Classification Loss: 0.8929\n",
            "2023-03-07 02:44:11 - Epoch: 77, Training Loss: 1.1737, Training Regression Loss 0.2379, Training Classification Loss: 0.9358\n",
            "2023-03-07 02:44:12 - Epoch: 77, Validation Loss: 0.8884, Validation Regression Loss 0.1505, Validation Classification Loss: 0.7379\n",
            "2023-03-07 02:44:12 - Saved model models/model0110/mb1-ssd-Epoch-77-Loss-0.8884177505970001.pth\n",
            "2023-03-07 02:44:30 - Epoch: 78, Step: 10/38, Avg Loss: 1.1991, Avg Regression Loss 0.3270, Avg Classification Loss: 0.8721\n",
            "2023-03-07 02:44:41 - Epoch: 78, Step: 20/38, Avg Loss: 0.9889, Avg Regression Loss 0.1935, Avg Classification Loss: 0.7955\n",
            "2023-03-07 02:44:52 - Epoch: 78, Step: 30/38, Avg Loss: 1.8425, Avg Regression Loss 0.4980, Avg Classification Loss: 1.3445\n",
            "2023-03-07 02:44:59 - Epoch: 78, Training Loss: 1.2385, Training Regression Loss 0.3000, Training Classification Loss: 0.9385\n",
            "2023-03-07 02:45:01 - Epoch: 78, Validation Loss: 0.8686, Validation Regression Loss 0.1577, Validation Classification Loss: 0.7109\n",
            "2023-03-07 02:45:01 - Saved model models/model0110/mb1-ssd-Epoch-78-Loss-0.8686342686414719.pth\n",
            "2023-03-07 02:45:15 - Epoch: 79, Step: 10/38, Avg Loss: 1.5639, Avg Regression Loss 0.3428, Avg Classification Loss: 1.2211\n",
            "2023-03-07 02:45:25 - Epoch: 79, Step: 20/38, Avg Loss: 1.6176, Avg Regression Loss 0.2034, Avg Classification Loss: 1.4141\n",
            "2023-03-07 02:45:35 - Epoch: 79, Step: 30/38, Avg Loss: 1.0347, Avg Regression Loss 0.2319, Avg Classification Loss: 0.8029\n",
            "2023-03-07 02:45:43 - Epoch: 79, Training Loss: 1.3374, Training Regression Loss 0.2393, Training Classification Loss: 1.0981\n",
            "2023-03-07 02:45:44 - Epoch: 79, Validation Loss: 0.8412, Validation Regression Loss 0.1472, Validation Classification Loss: 0.6941\n",
            "2023-03-07 02:45:45 - Saved model models/model0110/mb1-ssd-Epoch-79-Loss-0.8412298858165741.pth\n",
            "2023-03-07 02:46:00 - Epoch: 80, Step: 10/38, Avg Loss: 1.0614, Avg Regression Loss 0.1939, Avg Classification Loss: 0.8675\n",
            "2023-03-07 02:46:11 - Epoch: 80, Step: 20/38, Avg Loss: 1.0761, Avg Regression Loss 0.1761, Avg Classification Loss: 0.9000\n",
            "2023-03-07 02:46:20 - Epoch: 80, Step: 30/38, Avg Loss: 0.9664, Avg Regression Loss 0.1833, Avg Classification Loss: 0.7831\n",
            "2023-03-07 02:46:28 - Epoch: 80, Training Loss: 1.0683, Training Regression Loss 0.2001, Training Classification Loss: 0.8681\n",
            "2023-03-07 02:46:29 - Epoch: 80, Validation Loss: 0.8391, Validation Regression Loss 0.1426, Validation Classification Loss: 0.6965\n",
            "2023-03-07 02:46:29 - Saved model models/model0110/mb1-ssd-Epoch-80-Loss-0.8390528559684753.pth\n",
            "2023-03-07 02:46:43 - Epoch: 81, Step: 10/38, Avg Loss: 1.1300, Avg Regression Loss 0.1975, Avg Classification Loss: 0.9325\n",
            "2023-03-07 02:46:53 - Epoch: 81, Step: 20/38, Avg Loss: 1.0262, Avg Regression Loss 0.1890, Avg Classification Loss: 0.8372\n",
            "2023-03-07 02:47:04 - Epoch: 81, Step: 30/38, Avg Loss: 0.9902, Avg Regression Loss 0.2277, Avg Classification Loss: 0.7625\n",
            "2023-03-07 02:47:11 - Epoch: 81, Training Loss: 0.9971, Training Regression Loss 0.1997, Training Classification Loss: 0.7974\n",
            "2023-03-07 02:47:12 - Epoch: 81, Validation Loss: 0.8225, Validation Regression Loss 0.1446, Validation Classification Loss: 0.6779\n",
            "2023-03-07 02:47:12 - Saved model models/model0110/mb1-ssd-Epoch-81-Loss-0.8224947601556778.pth\n",
            "2023-03-07 02:47:26 - Epoch: 82, Step: 10/38, Avg Loss: 1.2566, Avg Regression Loss 0.2643, Avg Classification Loss: 0.9923\n",
            "2023-03-07 02:47:37 - Epoch: 82, Step: 20/38, Avg Loss: 1.2437, Avg Regression Loss 0.2473, Avg Classification Loss: 0.9965\n",
            "2023-03-07 02:47:48 - Epoch: 82, Step: 30/38, Avg Loss: 1.4535, Avg Regression Loss 0.2915, Avg Classification Loss: 1.1620\n",
            "2023-03-07 02:47:54 - Epoch: 82, Training Loss: 1.2474, Training Regression Loss 0.2597, Training Classification Loss: 0.9876\n",
            "2023-03-07 02:47:55 - Epoch: 82, Validation Loss: 0.8164, Validation Regression Loss 0.1398, Validation Classification Loss: 0.6766\n",
            "2023-03-07 02:47:55 - Saved model models/model0110/mb1-ssd-Epoch-82-Loss-0.8163613080978394.pth\n",
            "2023-03-07 02:48:09 - Epoch: 83, Step: 10/38, Avg Loss: 1.2320, Avg Regression Loss 0.2377, Avg Classification Loss: 0.9944\n",
            "2023-03-07 02:48:20 - Epoch: 83, Step: 20/38, Avg Loss: 1.3975, Avg Regression Loss 0.3026, Avg Classification Loss: 1.0950\n",
            "2023-03-07 02:48:31 - Epoch: 83, Step: 30/38, Avg Loss: 0.8948, Avg Regression Loss 0.1786, Avg Classification Loss: 0.7163\n",
            "2023-03-07 02:48:37 - Epoch: 83, Training Loss: 1.1199, Training Regression Loss 0.2313, Training Classification Loss: 0.8886\n",
            "2023-03-07 02:48:39 - Epoch: 83, Validation Loss: 0.7960, Validation Regression Loss 0.1381, Validation Classification Loss: 0.6579\n",
            "2023-03-07 02:48:39 - Saved model models/model0110/mb1-ssd-Epoch-83-Loss-0.7959865778684616.pth\n",
            "2023-03-07 02:48:52 - Epoch: 84, Step: 10/38, Avg Loss: 1.3174, Avg Regression Loss 0.2254, Avg Classification Loss: 1.0921\n",
            "2023-03-07 02:49:03 - Epoch: 84, Step: 20/38, Avg Loss: 0.8109, Avg Regression Loss 0.1793, Avg Classification Loss: 0.6317\n",
            "2023-03-07 02:49:14 - Epoch: 84, Step: 30/38, Avg Loss: 1.4643, Avg Regression Loss 0.3896, Avg Classification Loss: 1.0748\n",
            "2023-03-07 02:49:20 - Epoch: 84, Training Loss: 1.1984, Training Regression Loss 0.2608, Training Classification Loss: 0.9375\n",
            "2023-03-07 02:49:23 - Epoch: 84, Validation Loss: 0.8116, Validation Regression Loss 0.1473, Validation Classification Loss: 0.6642\n",
            "2023-03-07 02:49:23 - Saved model models/model0110/mb1-ssd-Epoch-84-Loss-0.8115704208612442.pth\n",
            "2023-03-07 02:49:38 - Epoch: 85, Step: 10/38, Avg Loss: 1.3213, Avg Regression Loss 0.2791, Avg Classification Loss: 1.0422\n",
            "2023-03-07 02:49:49 - Epoch: 85, Step: 20/38, Avg Loss: 0.9441, Avg Regression Loss 0.1831, Avg Classification Loss: 0.7611\n",
            "2023-03-07 02:49:59 - Epoch: 85, Step: 30/38, Avg Loss: 1.1213, Avg Regression Loss 0.2033, Avg Classification Loss: 0.9180\n",
            "2023-03-07 02:50:06 - Epoch: 85, Training Loss: 1.1226, Training Regression Loss 0.2285, Training Classification Loss: 0.8941\n",
            "2023-03-07 02:50:08 - Epoch: 85, Validation Loss: 0.8476, Validation Regression Loss 0.1530, Validation Classification Loss: 0.6946\n",
            "2023-03-07 02:50:08 - Saved model models/model0110/mb1-ssd-Epoch-85-Loss-0.84757399559021.pth\n",
            "2023-03-07 02:50:22 - Epoch: 86, Step: 10/38, Avg Loss: 1.5066, Avg Regression Loss 0.2643, Avg Classification Loss: 1.2424\n",
            "2023-03-07 02:50:33 - Epoch: 86, Step: 20/38, Avg Loss: 1.2775, Avg Regression Loss 0.2646, Avg Classification Loss: 1.0128\n",
            "2023-03-07 02:50:42 - Epoch: 86, Step: 30/38, Avg Loss: 1.1661, Avg Regression Loss 0.2695, Avg Classification Loss: 0.8966\n",
            "2023-03-07 02:50:50 - Epoch: 86, Training Loss: 1.2497, Training Regression Loss 0.2548, Training Classification Loss: 0.9949\n",
            "2023-03-07 02:50:51 - Epoch: 86, Validation Loss: 0.7967, Validation Regression Loss 0.1310, Validation Classification Loss: 0.6657\n",
            "2023-03-07 02:50:51 - Saved model models/model0110/mb1-ssd-Epoch-86-Loss-0.7967215478420258.pth\n",
            "2023-03-07 02:51:04 - Epoch: 87, Step: 10/38, Avg Loss: 1.1075, Avg Regression Loss 0.1981, Avg Classification Loss: 0.9095\n",
            "2023-03-07 02:51:15 - Epoch: 87, Step: 20/38, Avg Loss: 1.0607, Avg Regression Loss 0.1760, Avg Classification Loss: 0.8848\n",
            "2023-03-07 02:51:26 - Epoch: 87, Step: 30/38, Avg Loss: 1.5155, Avg Regression Loss 0.2828, Avg Classification Loss: 1.2328\n",
            "2023-03-07 02:51:32 - Epoch: 87, Training Loss: 1.2128, Training Regression Loss 0.2228, Training Classification Loss: 0.9900\n",
            "2023-03-07 02:51:34 - Epoch: 87, Validation Loss: 0.8322, Validation Regression Loss 0.1389, Validation Classification Loss: 0.6933\n",
            "2023-03-07 02:51:34 - Saved model models/model0110/mb1-ssd-Epoch-87-Loss-0.8322479277849197.pth\n",
            "2023-03-07 02:51:47 - Epoch: 88, Step: 10/38, Avg Loss: 1.5149, Avg Regression Loss 0.3070, Avg Classification Loss: 1.2079\n",
            "2023-03-07 02:51:59 - Epoch: 88, Step: 20/38, Avg Loss: 0.8587, Avg Regression Loss 0.1641, Avg Classification Loss: 0.6946\n",
            "2023-03-07 02:52:10 - Epoch: 88, Step: 30/38, Avg Loss: 0.8184, Avg Regression Loss 0.1813, Avg Classification Loss: 0.6371\n",
            "2023-03-07 02:52:16 - Epoch: 88, Training Loss: 1.0344, Training Regression Loss 0.2066, Training Classification Loss: 0.8279\n",
            "2023-03-07 02:52:17 - Epoch: 88, Validation Loss: 0.8194, Validation Regression Loss 0.1360, Validation Classification Loss: 0.6834\n",
            "2023-03-07 02:52:17 - Saved model models/model0110/mb1-ssd-Epoch-88-Loss-0.8194122165441513.pth\n",
            "2023-03-07 02:52:31 - Epoch: 89, Step: 10/38, Avg Loss: 1.3421, Avg Regression Loss 0.2223, Avg Classification Loss: 1.1198\n",
            "2023-03-07 02:52:42 - Epoch: 89, Step: 20/38, Avg Loss: 1.1203, Avg Regression Loss 0.2119, Avg Classification Loss: 0.9084\n",
            "2023-03-07 02:52:53 - Epoch: 89, Step: 30/38, Avg Loss: 1.1619, Avg Regression Loss 0.2154, Avg Classification Loss: 0.9464\n",
            "2023-03-07 02:52:59 - Epoch: 89, Training Loss: 1.1563, Training Regression Loss 0.1964, Training Classification Loss: 0.9599\n",
            "2023-03-07 02:53:01 - Epoch: 89, Validation Loss: 0.7838, Validation Regression Loss 0.1273, Validation Classification Loss: 0.6565\n",
            "2023-03-07 02:53:01 - Saved model models/model0110/mb1-ssd-Epoch-89-Loss-0.7837850004434586.pth\n",
            "2023-03-07 02:53:17 - Epoch: 90, Step: 10/38, Avg Loss: 1.1533, Avg Regression Loss 0.2361, Avg Classification Loss: 0.9172\n",
            "2023-03-07 02:53:26 - Epoch: 90, Step: 20/38, Avg Loss: 0.8752, Avg Regression Loss 0.1958, Avg Classification Loss: 0.6794\n",
            "2023-03-07 02:53:37 - Epoch: 90, Step: 30/38, Avg Loss: 1.4494, Avg Regression Loss 0.2793, Avg Classification Loss: 1.1700\n",
            "2023-03-07 02:53:45 - Epoch: 90, Training Loss: 1.1590, Training Regression Loss 0.2325, Training Classification Loss: 0.9266\n",
            "2023-03-07 02:53:46 - Epoch: 90, Validation Loss: 0.7976, Validation Regression Loss 0.1297, Validation Classification Loss: 0.6679\n",
            "2023-03-07 02:53:46 - Saved model models/model0110/mb1-ssd-Epoch-90-Loss-0.7976222336292267.pth\n",
            "2023-03-07 02:54:00 - Epoch: 91, Step: 10/38, Avg Loss: 1.6333, Avg Regression Loss 0.3025, Avg Classification Loss: 1.3308\n",
            "2023-03-07 02:54:12 - Epoch: 91, Step: 20/38, Avg Loss: 1.1505, Avg Regression Loss 0.2543, Avg Classification Loss: 0.8962\n",
            "2023-03-07 02:54:21 - Epoch: 91, Step: 30/38, Avg Loss: 0.9531, Avg Regression Loss 0.2107, Avg Classification Loss: 0.7424\n",
            "2023-03-07 02:54:28 - Epoch: 91, Training Loss: 1.1657, Training Regression Loss 0.2465, Training Classification Loss: 0.9192\n",
            "2023-03-07 02:54:30 - Epoch: 91, Validation Loss: 0.7944, Validation Regression Loss 0.1295, Validation Classification Loss: 0.6649\n",
            "2023-03-07 02:54:30 - Saved model models/model0110/mb1-ssd-Epoch-91-Loss-0.7943659126758575.pth\n",
            "2023-03-07 02:54:49 - Epoch: 92, Step: 10/38, Avg Loss: 1.2390, Avg Regression Loss 0.2124, Avg Classification Loss: 1.0267\n",
            "2023-03-07 02:55:00 - Epoch: 92, Step: 20/38, Avg Loss: 1.0381, Avg Regression Loss 0.2272, Avg Classification Loss: 0.8108\n",
            "2023-03-07 02:55:11 - Epoch: 92, Step: 30/38, Avg Loss: 0.9425, Avg Regression Loss 0.1786, Avg Classification Loss: 0.7639\n",
            "2023-03-07 02:55:17 - Epoch: 92, Training Loss: 1.0225, Training Regression Loss 0.2052, Training Classification Loss: 0.8173\n",
            "2023-03-07 02:55:18 - Epoch: 92, Validation Loss: 0.7958, Validation Regression Loss 0.1353, Validation Classification Loss: 0.6605\n",
            "2023-03-07 02:55:18 - Saved model models/model0110/mb1-ssd-Epoch-92-Loss-0.7958329170942307.pth\n",
            "2023-03-07 02:55:33 - Epoch: 93, Step: 10/38, Avg Loss: 1.4653, Avg Regression Loss 0.2348, Avg Classification Loss: 1.2305\n",
            "2023-03-07 02:55:44 - Epoch: 93, Step: 20/38, Avg Loss: 1.4615, Avg Regression Loss 0.2997, Avg Classification Loss: 1.1618\n",
            "2023-03-07 02:55:55 - Epoch: 93, Step: 30/38, Avg Loss: 0.9343, Avg Regression Loss 0.1574, Avg Classification Loss: 0.7769\n",
            "2023-03-07 02:56:01 - Epoch: 93, Training Loss: 1.1735, Training Regression Loss 0.2139, Training Classification Loss: 0.9596\n",
            "2023-03-07 02:56:04 - Epoch: 93, Validation Loss: 0.8173, Validation Regression Loss 0.1321, Validation Classification Loss: 0.6852\n",
            "2023-03-07 02:56:04 - Saved model models/model0110/mb1-ssd-Epoch-93-Loss-0.8172503709793091.pth\n",
            "2023-03-07 02:56:18 - Epoch: 94, Step: 10/38, Avg Loss: 1.1681, Avg Regression Loss 0.1757, Avg Classification Loss: 0.9924\n",
            "2023-03-07 02:56:28 - Epoch: 94, Step: 20/38, Avg Loss: 1.1787, Avg Regression Loss 0.2385, Avg Classification Loss: 0.9401\n",
            "2023-03-07 02:56:38 - Epoch: 94, Step: 30/38, Avg Loss: 0.9437, Avg Regression Loss 0.1802, Avg Classification Loss: 0.7635\n",
            "2023-03-07 02:56:46 - Epoch: 94, Training Loss: 1.1788, Training Regression Loss 0.2168, Training Classification Loss: 0.9620\n",
            "2023-03-07 02:56:49 - Epoch: 94, Validation Loss: 0.8173, Validation Regression Loss 0.1335, Validation Classification Loss: 0.6838\n",
            "2023-03-07 02:56:49 - Saved model models/model0110/mb1-ssd-Epoch-94-Loss-0.8172632902860641.pth\n",
            "2023-03-07 02:57:02 - Epoch: 95, Step: 10/38, Avg Loss: 1.2406, Avg Regression Loss 0.3237, Avg Classification Loss: 0.9169\n",
            "2023-03-07 02:57:12 - Epoch: 95, Step: 20/38, Avg Loss: 1.0592, Avg Regression Loss 0.1781, Avg Classification Loss: 0.8811\n",
            "2023-03-07 02:57:23 - Epoch: 95, Step: 30/38, Avg Loss: 1.1261, Avg Regression Loss 0.1968, Avg Classification Loss: 0.9293\n",
            "2023-03-07 02:57:31 - Epoch: 95, Training Loss: 1.1680, Training Regression Loss 0.2382, Training Classification Loss: 0.9299\n",
            "2023-03-07 02:57:32 - Epoch: 95, Validation Loss: 0.8129, Validation Regression Loss 0.1337, Validation Classification Loss: 0.6791\n",
            "2023-03-07 02:57:32 - Saved model models/model0110/mb1-ssd-Epoch-95-Loss-0.812865674495697.pth\n",
            "2023-03-07 02:57:45 - Epoch: 96, Step: 10/38, Avg Loss: 0.9820, Avg Regression Loss 0.1378, Avg Classification Loss: 0.8442\n",
            "2023-03-07 02:57:56 - Epoch: 96, Step: 20/38, Avg Loss: 1.0258, Avg Regression Loss 0.2519, Avg Classification Loss: 0.7739\n",
            "2023-03-07 02:58:06 - Epoch: 96, Step: 30/38, Avg Loss: 1.1654, Avg Regression Loss 0.2822, Avg Classification Loss: 0.8832\n",
            "2023-03-07 02:58:13 - Epoch: 96, Training Loss: 1.0253, Training Regression Loss 0.2150, Training Classification Loss: 0.8103\n",
            "2023-03-07 02:58:15 - Epoch: 96, Validation Loss: 0.7964, Validation Regression Loss 0.1271, Validation Classification Loss: 0.6692\n",
            "2023-03-07 02:58:15 - Saved model models/model0110/mb1-ssd-Epoch-96-Loss-0.7963592261075974.pth\n",
            "2023-03-07 02:58:28 - Epoch: 97, Step: 10/38, Avg Loss: 0.9960, Avg Regression Loss 0.1998, Avg Classification Loss: 0.7961\n",
            "2023-03-07 02:58:39 - Epoch: 97, Step: 20/38, Avg Loss: 1.2720, Avg Regression Loss 0.2421, Avg Classification Loss: 1.0298\n",
            "2023-03-07 02:58:49 - Epoch: 97, Step: 30/38, Avg Loss: 1.0421, Avg Regression Loss 0.1838, Avg Classification Loss: 0.8583\n",
            "2023-03-07 02:58:56 - Epoch: 97, Training Loss: 1.1759, Training Regression Loss 0.2284, Training Classification Loss: 0.9475\n",
            "2023-03-07 02:58:58 - Epoch: 97, Validation Loss: 0.8101, Validation Regression Loss 0.1334, Validation Classification Loss: 0.6767\n",
            "2023-03-07 02:58:58 - Saved model models/model0110/mb1-ssd-Epoch-97-Loss-0.8100710958242416.pth\n",
            "2023-03-07 02:59:11 - Epoch: 98, Step: 10/38, Avg Loss: 0.9711, Avg Regression Loss 0.1895, Avg Classification Loss: 0.7816\n",
            "2023-03-07 02:59:22 - Epoch: 98, Step: 20/38, Avg Loss: 1.0779, Avg Regression Loss 0.2331, Avg Classification Loss: 0.8448\n",
            "2023-03-07 02:59:33 - Epoch: 98, Step: 30/38, Avg Loss: 1.2366, Avg Regression Loss 0.2701, Avg Classification Loss: 0.9664\n",
            "2023-03-07 02:59:39 - Epoch: 98, Training Loss: 1.0710, Training Regression Loss 0.2154, Training Classification Loss: 0.8556\n",
            "2023-03-07 02:59:41 - Epoch: 98, Validation Loss: 0.8077, Validation Regression Loss 0.1284, Validation Classification Loss: 0.6793\n",
            "2023-03-07 02:59:41 - Saved model models/model0110/mb1-ssd-Epoch-98-Loss-0.8077038377523422.pth\n",
            "2023-03-07 02:59:54 - Epoch: 99, Step: 10/38, Avg Loss: 1.5201, Avg Regression Loss 0.2977, Avg Classification Loss: 1.2224\n",
            "2023-03-07 03:00:06 - Epoch: 99, Step: 20/38, Avg Loss: 1.3923, Avg Regression Loss 0.3039, Avg Classification Loss: 1.0885\n",
            "2023-03-07 03:00:17 - Epoch: 99, Step: 30/38, Avg Loss: 1.3081, Avg Regression Loss 0.2696, Avg Classification Loss: 1.0385\n",
            "2023-03-07 03:00:23 - Epoch: 99, Training Loss: 1.3344, Training Regression Loss 0.2627, Training Classification Loss: 1.0717\n",
            "2023-03-07 03:00:24 - Epoch: 99, Validation Loss: 0.8110, Validation Regression Loss 0.1315, Validation Classification Loss: 0.6795\n",
            "2023-03-07 03:00:24 - Saved model models/model0110/mb1-ssd-Epoch-99-Loss-0.8110257536172867.pth\n",
            "2023-03-07 03:00:39 - Epoch: 100, Step: 10/38, Avg Loss: 1.2441, Avg Regression Loss 0.3147, Avg Classification Loss: 0.9294\n",
            "2023-03-07 03:00:50 - Epoch: 100, Step: 20/38, Avg Loss: 1.0564, Avg Regression Loss 0.1797, Avg Classification Loss: 0.8768\n",
            "2023-03-07 03:01:01 - Epoch: 100, Step: 30/38, Avg Loss: 0.8856, Avg Regression Loss 0.1631, Avg Classification Loss: 0.7224\n",
            "2023-03-07 03:01:07 - Epoch: 100, Training Loss: 0.9849, Training Regression Loss 0.2004, Training Classification Loss: 0.7846\n",
            "2023-03-07 03:01:08 - Epoch: 100, Validation Loss: 0.8076, Validation Regression Loss 0.1262, Validation Classification Loss: 0.6814\n",
            "2023-03-07 03:01:08 - Saved model models/model0110/mb1-ssd-Epoch-100-Loss-0.807611420750618.pth\n",
            "2023-03-07 03:01:24 - Epoch: 101, Step: 10/38, Avg Loss: 1.1235, Avg Regression Loss 0.3099, Avg Classification Loss: 0.8136\n",
            "2023-03-07 03:01:34 - Epoch: 101, Step: 20/38, Avg Loss: 1.1154, Avg Regression Loss 0.2251, Avg Classification Loss: 0.8902\n",
            "2023-03-07 03:01:45 - Epoch: 101, Step: 30/38, Avg Loss: 1.1837, Avg Regression Loss 0.2603, Avg Classification Loss: 0.9234\n",
            "2023-03-07 03:01:53 - Epoch: 101, Training Loss: 1.1001, Training Regression Loss 0.2556, Training Classification Loss: 0.8444\n",
            "2023-03-07 03:01:54 - Epoch: 101, Validation Loss: 0.8153, Validation Regression Loss 0.1366, Validation Classification Loss: 0.6787\n",
            "2023-03-07 03:01:54 - Saved model models/model0110/mb1-ssd-Epoch-101-Loss-0.8153496831655502.pth\n",
            "2023-03-07 03:02:07 - Epoch: 102, Step: 10/38, Avg Loss: 1.0051, Avg Regression Loss 0.2165, Avg Classification Loss: 0.7885\n",
            "2023-03-07 03:02:17 - Epoch: 102, Step: 20/38, Avg Loss: 0.9474, Avg Regression Loss 0.2172, Avg Classification Loss: 0.7302\n",
            "2023-03-07 03:02:28 - Epoch: 102, Step: 30/38, Avg Loss: 1.3937, Avg Regression Loss 0.2516, Avg Classification Loss: 1.1422\n",
            "2023-03-07 03:02:36 - Epoch: 102, Training Loss: 1.1211, Training Regression Loss 0.2283, Training Classification Loss: 0.8928\n",
            "2023-03-07 03:02:37 - Epoch: 102, Validation Loss: 0.7965, Validation Regression Loss 0.1281, Validation Classification Loss: 0.6685\n",
            "2023-03-07 03:02:37 - Saved model models/model0110/mb1-ssd-Epoch-102-Loss-0.7965441644191742.pth\n",
            "2023-03-07 03:02:51 - Epoch: 103, Step: 10/38, Avg Loss: 1.3675, Avg Regression Loss 0.2307, Avg Classification Loss: 1.1368\n",
            "2023-03-07 03:03:01 - Epoch: 103, Step: 20/38, Avg Loss: 1.1036, Avg Regression Loss 0.1951, Avg Classification Loss: 0.9085\n",
            "2023-03-07 03:03:11 - Epoch: 103, Step: 30/38, Avg Loss: 1.4722, Avg Regression Loss 0.3493, Avg Classification Loss: 1.1229\n",
            "2023-03-07 03:03:18 - Epoch: 103, Training Loss: 1.2153, Training Regression Loss 0.2369, Training Classification Loss: 0.9784\n",
            "2023-03-07 03:03:19 - Epoch: 103, Validation Loss: 0.8347, Validation Regression Loss 0.1377, Validation Classification Loss: 0.6970\n",
            "2023-03-07 03:03:19 - Saved model models/model0110/mb1-ssd-Epoch-103-Loss-0.8346803039312363.pth\n",
            "2023-03-07 03:03:34 - Epoch: 104, Step: 10/38, Avg Loss: 1.0343, Avg Regression Loss 0.2125, Avg Classification Loss: 0.8218\n",
            "2023-03-07 03:03:45 - Epoch: 104, Step: 20/38, Avg Loss: 1.0030, Avg Regression Loss 0.1759, Avg Classification Loss: 0.8271\n",
            "2023-03-07 03:03:54 - Epoch: 104, Step: 30/38, Avg Loss: 1.1878, Avg Regression Loss 0.2019, Avg Classification Loss: 0.9859\n",
            "2023-03-07 03:04:01 - Epoch: 104, Training Loss: 1.1001, Training Regression Loss 0.1966, Training Classification Loss: 0.9034\n",
            "2023-03-07 03:04:03 - Epoch: 104, Validation Loss: 0.7845, Validation Regression Loss 0.1230, Validation Classification Loss: 0.6615\n",
            "2023-03-07 03:04:03 - Saved model models/model0110/mb1-ssd-Epoch-104-Loss-0.7845493108034134.pth\n",
            "2023-03-07 03:04:18 - Epoch: 105, Step: 10/38, Avg Loss: 1.3729, Avg Regression Loss 0.2931, Avg Classification Loss: 1.0798\n",
            "2023-03-07 03:04:29 - Epoch: 105, Step: 20/38, Avg Loss: 1.0436, Avg Regression Loss 0.1759, Avg Classification Loss: 0.8677\n",
            "2023-03-07 03:04:39 - Epoch: 105, Step: 30/38, Avg Loss: 1.2391, Avg Regression Loss 0.2583, Avg Classification Loss: 0.9808\n",
            "2023-03-07 03:04:47 - Epoch: 105, Training Loss: 1.1396, Training Regression Loss 0.2227, Training Classification Loss: 0.9168\n",
            "2023-03-07 03:04:50 - Epoch: 105, Validation Loss: 0.7746, Validation Regression Loss 0.1213, Validation Classification Loss: 0.6532\n",
            "2023-03-07 03:04:50 - Saved model models/model0110/mb1-ssd-Epoch-105-Loss-0.774585634469986.pth\n",
            "2023-03-07 03:05:07 - Epoch: 106, Step: 10/38, Avg Loss: 1.0247, Avg Regression Loss 0.1781, Avg Classification Loss: 0.8466\n",
            "2023-03-07 03:05:17 - Epoch: 106, Step: 20/38, Avg Loss: 0.9603, Avg Regression Loss 0.1853, Avg Classification Loss: 0.7750\n",
            "2023-03-07 03:05:27 - Epoch: 106, Step: 30/38, Avg Loss: 0.9186, Avg Regression Loss 0.1644, Avg Classification Loss: 0.7542\n",
            "2023-03-07 03:05:35 - Epoch: 106, Training Loss: 1.0639, Training Regression Loss 0.2117, Training Classification Loss: 0.8522\n",
            "2023-03-07 03:05:36 - Epoch: 106, Validation Loss: 0.8027, Validation Regression Loss 0.1276, Validation Classification Loss: 0.6751\n",
            "2023-03-07 03:05:37 - Saved model models/model0110/mb1-ssd-Epoch-106-Loss-0.8026926517486572.pth\n",
            "2023-03-07 03:05:50 - Epoch: 107, Step: 10/38, Avg Loss: 0.9291, Avg Regression Loss 0.1625, Avg Classification Loss: 0.7666\n",
            "2023-03-07 03:06:02 - Epoch: 107, Step: 20/38, Avg Loss: 1.4364, Avg Regression Loss 0.3114, Avg Classification Loss: 1.1250\n",
            "2023-03-07 03:06:11 - Epoch: 107, Step: 30/38, Avg Loss: 1.1341, Avg Regression Loss 0.2409, Avg Classification Loss: 0.8933\n",
            "2023-03-07 03:06:19 - Epoch: 107, Training Loss: 1.1133, Training Regression Loss 0.2297, Training Classification Loss: 0.8836\n",
            "2023-03-07 03:06:20 - Epoch: 107, Validation Loss: 0.8217, Validation Regression Loss 0.1368, Validation Classification Loss: 0.6849\n",
            "2023-03-07 03:06:20 - Saved model models/model0110/mb1-ssd-Epoch-107-Loss-0.8216843903064728.pth\n",
            "2023-03-07 03:06:33 - Epoch: 108, Step: 10/38, Avg Loss: 1.3346, Avg Regression Loss 0.2148, Avg Classification Loss: 1.1197\n",
            "2023-03-07 03:06:45 - Epoch: 108, Step: 20/38, Avg Loss: 1.2647, Avg Regression Loss 0.2643, Avg Classification Loss: 1.0005\n",
            "2023-03-07 03:06:55 - Epoch: 108, Step: 30/38, Avg Loss: 1.0179, Avg Regression Loss 0.2289, Avg Classification Loss: 0.7889\n",
            "2023-03-07 03:07:02 - Epoch: 108, Training Loss: 1.1134, Training Regression Loss 0.2156, Training Classification Loss: 0.8978\n",
            "2023-03-07 03:07:03 - Epoch: 108, Validation Loss: 0.7961, Validation Regression Loss 0.1288, Validation Classification Loss: 0.6674\n",
            "2023-03-07 03:07:03 - Saved model models/model0110/mb1-ssd-Epoch-108-Loss-0.7961270958185196.pth\n",
            "2023-03-07 03:07:17 - Epoch: 109, Step: 10/38, Avg Loss: 1.2969, Avg Regression Loss 0.3013, Avg Classification Loss: 0.9956\n",
            "2023-03-07 03:07:28 - Epoch: 109, Step: 20/38, Avg Loss: 1.0924, Avg Regression Loss 0.2408, Avg Classification Loss: 0.8516\n",
            "2023-03-07 03:07:39 - Epoch: 109, Step: 30/38, Avg Loss: 1.0294, Avg Regression Loss 0.2326, Avg Classification Loss: 0.7969\n",
            "2023-03-07 03:07:47 - Epoch: 109, Training Loss: 1.1543, Training Regression Loss 0.2574, Training Classification Loss: 0.8970\n",
            "2023-03-07 03:07:49 - Epoch: 109, Validation Loss: 0.8046, Validation Regression Loss 0.1316, Validation Classification Loss: 0.6730\n",
            "2023-03-07 03:07:49 - Saved model models/model0110/mb1-ssd-Epoch-109-Loss-0.804590567946434.pth\n",
            "2023-03-07 03:08:03 - Epoch: 110, Step: 10/38, Avg Loss: 1.6810, Avg Regression Loss 0.3390, Avg Classification Loss: 1.3420\n",
            "2023-03-07 03:08:14 - Epoch: 110, Step: 20/38, Avg Loss: 1.1915, Avg Regression Loss 0.2288, Avg Classification Loss: 0.9626\n",
            "2023-03-07 03:08:24 - Epoch: 110, Step: 30/38, Avg Loss: 0.9642, Avg Regression Loss 0.1554, Avg Classification Loss: 0.8088\n",
            "2023-03-07 03:08:32 - Epoch: 110, Training Loss: 1.1985, Training Regression Loss 0.2254, Training Classification Loss: 0.9731\n",
            "2023-03-07 03:08:34 - Epoch: 110, Validation Loss: 0.7938, Validation Regression Loss 0.1274, Validation Classification Loss: 0.6664\n",
            "2023-03-07 03:08:34 - Saved model models/model0110/mb1-ssd-Epoch-110-Loss-0.7938168942928314.pth\n",
            "2023-03-07 03:08:48 - Epoch: 111, Step: 10/38, Avg Loss: 1.3977, Avg Regression Loss 0.3493, Avg Classification Loss: 1.0483\n",
            "2023-03-07 03:08:57 - Epoch: 111, Step: 20/38, Avg Loss: 1.0852, Avg Regression Loss 0.2391, Avg Classification Loss: 0.8461\n",
            "2023-03-07 03:09:08 - Epoch: 111, Step: 30/38, Avg Loss: 0.7562, Avg Regression Loss 0.1688, Avg Classification Loss: 0.5874\n",
            "2023-03-07 03:09:16 - Epoch: 111, Training Loss: 1.0368, Training Regression Loss 0.2333, Training Classification Loss: 0.8035\n",
            "2023-03-07 03:09:17 - Epoch: 111, Validation Loss: 0.8054, Validation Regression Loss 0.1313, Validation Classification Loss: 0.6741\n",
            "2023-03-07 03:09:17 - Saved model models/model0110/mb1-ssd-Epoch-111-Loss-0.805399551987648.pth\n",
            "2023-03-07 03:09:31 - Epoch: 112, Step: 10/38, Avg Loss: 0.8379, Avg Regression Loss 0.1713, Avg Classification Loss: 0.6666\n",
            "2023-03-07 03:09:42 - Epoch: 112, Step: 20/38, Avg Loss: 1.2984, Avg Regression Loss 0.2505, Avg Classification Loss: 1.0479\n",
            "2023-03-07 03:09:51 - Epoch: 112, Step: 30/38, Avg Loss: 1.2739, Avg Regression Loss 0.2849, Avg Classification Loss: 0.9890\n",
            "2023-03-07 03:09:59 - Epoch: 112, Training Loss: 1.0698, Training Regression Loss 0.2231, Training Classification Loss: 0.8467\n",
            "2023-03-07 03:10:00 - Epoch: 112, Validation Loss: 0.8142, Validation Regression Loss 0.1398, Validation Classification Loss: 0.6744\n",
            "2023-03-07 03:10:00 - Saved model models/model0110/mb1-ssd-Epoch-112-Loss-0.8142338991165161.pth\n",
            "2023-03-07 03:10:14 - Epoch: 113, Step: 10/38, Avg Loss: 1.5669, Avg Regression Loss 0.3402, Avg Classification Loss: 1.2266\n",
            "2023-03-07 03:10:26 - Epoch: 113, Step: 20/38, Avg Loss: 1.0852, Avg Regression Loss 0.2626, Avg Classification Loss: 0.8226\n",
            "2023-03-07 03:10:36 - Epoch: 113, Step: 30/38, Avg Loss: 0.8601, Avg Regression Loss 0.2074, Avg Classification Loss: 0.6527\n",
            "2023-03-07 03:10:43 - Epoch: 113, Training Loss: 1.1983, Training Regression Loss 0.2619, Training Classification Loss: 0.9363\n",
            "2023-03-07 03:10:44 - Epoch: 113, Validation Loss: 0.8275, Validation Regression Loss 0.1387, Validation Classification Loss: 0.6888\n",
            "2023-03-07 03:10:44 - Saved model models/model0110/mb1-ssd-Epoch-113-Loss-0.8275165557861328.pth\n",
            "2023-03-07 03:10:58 - Epoch: 114, Step: 10/38, Avg Loss: 1.1985, Avg Regression Loss 0.2896, Avg Classification Loss: 0.9089\n",
            "2023-03-07 03:11:10 - Epoch: 114, Step: 20/38, Avg Loss: 1.0321, Avg Regression Loss 0.1944, Avg Classification Loss: 0.8376\n",
            "2023-03-07 03:11:22 - Epoch: 114, Step: 30/38, Avg Loss: 1.1843, Avg Regression Loss 0.2059, Avg Classification Loss: 0.9783\n",
            "2023-03-07 03:11:29 - Epoch: 114, Training Loss: 1.1370, Training Regression Loss 0.2233, Training Classification Loss: 0.9137\n",
            "2023-03-07 03:11:31 - Epoch: 114, Validation Loss: 0.8026, Validation Regression Loss 0.1304, Validation Classification Loss: 0.6722\n",
            "2023-03-07 03:11:31 - Saved model models/model0110/mb1-ssd-Epoch-114-Loss-0.8026031404733658.pth\n",
            "2023-03-07 03:11:45 - Epoch: 115, Step: 10/38, Avg Loss: 0.9824, Avg Regression Loss 0.1863, Avg Classification Loss: 0.7961\n",
            "2023-03-07 03:11:55 - Epoch: 115, Step: 20/38, Avg Loss: 1.5937, Avg Regression Loss 0.5179, Avg Classification Loss: 1.0758\n",
            "2023-03-07 03:12:06 - Epoch: 115, Step: 30/38, Avg Loss: 1.1329, Avg Regression Loss 0.2113, Avg Classification Loss: 0.9216\n",
            "2023-03-07 03:12:14 - Epoch: 115, Training Loss: 1.2764, Training Regression Loss 0.2995, Training Classification Loss: 0.9769\n",
            "2023-03-07 03:12:15 - Epoch: 115, Validation Loss: 0.8146, Validation Regression Loss 0.1307, Validation Classification Loss: 0.6839\n",
            "2023-03-07 03:12:15 - Saved model models/model0110/mb1-ssd-Epoch-115-Loss-0.8145635426044464.pth\n",
            "2023-03-07 03:12:29 - Epoch: 116, Step: 10/38, Avg Loss: 1.4732, Avg Regression Loss 0.4035, Avg Classification Loss: 1.0697\n",
            "2023-03-07 03:12:40 - Epoch: 116, Step: 20/38, Avg Loss: 0.9335, Avg Regression Loss 0.1991, Avg Classification Loss: 0.7345\n",
            "2023-03-07 03:12:50 - Epoch: 116, Step: 30/38, Avg Loss: 1.2087, Avg Regression Loss 0.2458, Avg Classification Loss: 0.9629\n",
            "2023-03-07 03:12:57 - Epoch: 116, Training Loss: 1.1282, Training Regression Loss 0.2534, Training Classification Loss: 0.8749\n",
            "2023-03-07 03:12:59 - Epoch: 116, Validation Loss: 0.7960, Validation Regression Loss 0.1216, Validation Classification Loss: 0.6744\n",
            "2023-03-07 03:12:59 - Saved model models/model0110/mb1-ssd-Epoch-116-Loss-0.7959504872560501.pth\n",
            "2023-03-07 03:13:12 - Epoch: 117, Step: 10/38, Avg Loss: 1.3218, Avg Regression Loss 0.3216, Avg Classification Loss: 1.0003\n",
            "2023-03-07 03:13:23 - Epoch: 117, Step: 20/38, Avg Loss: 0.9706, Avg Regression Loss 0.1834, Avg Classification Loss: 0.7871\n",
            "2023-03-07 03:13:33 - Epoch: 117, Step: 30/38, Avg Loss: 1.1195, Avg Regression Loss 0.2410, Avg Classification Loss: 0.8785\n",
            "2023-03-07 03:13:40 - Epoch: 117, Training Loss: 1.0993, Training Regression Loss 0.2349, Training Classification Loss: 0.8644\n",
            "2023-03-07 03:13:42 - Epoch: 117, Validation Loss: 0.7762, Validation Regression Loss 0.1192, Validation Classification Loss: 0.6570\n",
            "2023-03-07 03:13:42 - Saved model models/model0110/mb1-ssd-Epoch-117-Loss-0.7762163132429123.pth\n",
            "2023-03-07 03:13:56 - Epoch: 118, Step: 10/38, Avg Loss: 1.0400, Avg Regression Loss 0.2113, Avg Classification Loss: 0.8287\n",
            "2023-03-07 03:14:07 - Epoch: 118, Step: 20/38, Avg Loss: 1.2112, Avg Regression Loss 0.2786, Avg Classification Loss: 0.9326\n",
            "2023-03-07 03:14:17 - Epoch: 118, Step: 30/38, Avg Loss: 1.0551, Avg Regression Loss 0.2041, Avg Classification Loss: 0.8510\n",
            "2023-03-07 03:14:24 - Epoch: 118, Training Loss: 1.1549, Training Regression Loss 0.2395, Training Classification Loss: 0.9153\n",
            "2023-03-07 03:14:25 - Epoch: 118, Validation Loss: 0.8155, Validation Regression Loss 0.1393, Validation Classification Loss: 0.6762\n",
            "2023-03-07 03:14:25 - Saved model models/model0110/mb1-ssd-Epoch-118-Loss-0.8154668360948563.pth\n",
            "2023-03-07 03:14:39 - Epoch: 119, Step: 10/38, Avg Loss: 1.1144, Avg Regression Loss 0.1840, Avg Classification Loss: 0.9304\n",
            "2023-03-07 03:14:50 - Epoch: 119, Step: 20/38, Avg Loss: 1.0701, Avg Regression Loss 0.2332, Avg Classification Loss: 0.8368\n",
            "2023-03-07 03:15:07 - Epoch: 119, Step: 30/38, Avg Loss: 1.2436, Avg Regression Loss 0.2503, Avg Classification Loss: 0.9933\n",
            "2023-03-07 03:15:13 - Epoch: 119, Training Loss: 1.2024, Training Regression Loss 0.2332, Training Classification Loss: 0.9692\n",
            "2023-03-07 03:15:15 - Epoch: 119, Validation Loss: 0.8143, Validation Regression Loss 0.1428, Validation Classification Loss: 0.6715\n",
            "2023-03-07 03:15:15 - Saved model models/model0110/mb1-ssd-Epoch-119-Loss-0.8143237233161926.pth\n",
            "2023-03-07 03:15:29 - Epoch: 120, Step: 10/38, Avg Loss: 1.5916, Avg Regression Loss 0.3240, Avg Classification Loss: 1.2675\n",
            "2023-03-07 03:15:41 - Epoch: 120, Step: 20/38, Avg Loss: 1.2255, Avg Regression Loss 0.2711, Avg Classification Loss: 0.9544\n",
            "2023-03-07 03:15:52 - Epoch: 120, Step: 30/38, Avg Loss: 1.2149, Avg Regression Loss 0.1901, Avg Classification Loss: 1.0248\n",
            "2023-03-07 03:15:59 - Epoch: 120, Training Loss: 1.2441, Training Regression Loss 0.2504, Training Classification Loss: 0.9937\n",
            "2023-03-07 03:16:01 - Epoch: 120, Validation Loss: 0.8956, Validation Regression Loss 0.1431, Validation Classification Loss: 0.7525\n",
            "2023-03-07 03:16:01 - Saved model models/model0110/mb1-ssd-Epoch-120-Loss-0.8955678194761276.pth\n",
            "2023-03-07 03:16:14 - Epoch: 121, Step: 10/38, Avg Loss: 0.9360, Avg Regression Loss 0.1449, Avg Classification Loss: 0.7911\n",
            "2023-03-07 03:16:24 - Epoch: 121, Step: 20/38, Avg Loss: 1.0414, Avg Regression Loss 0.2402, Avg Classification Loss: 0.8012\n",
            "2023-03-07 03:16:35 - Epoch: 121, Step: 30/38, Avg Loss: 1.1463, Avg Regression Loss 0.2726, Avg Classification Loss: 0.8737\n",
            "2023-03-07 03:16:42 - Epoch: 121, Training Loss: 1.0206, Training Regression Loss 0.2073, Training Classification Loss: 0.8134\n",
            "2023-03-07 03:16:44 - Epoch: 121, Validation Loss: 0.8596, Validation Regression Loss 0.1379, Validation Classification Loss: 0.7217\n",
            "2023-03-07 03:16:44 - Saved model models/model0110/mb1-ssd-Epoch-121-Loss-0.859649270772934.pth\n",
            "2023-03-07 03:16:58 - Epoch: 122, Step: 10/38, Avg Loss: 1.1412, Avg Regression Loss 0.1633, Avg Classification Loss: 0.9779\n",
            "2023-03-07 03:17:09 - Epoch: 122, Step: 20/38, Avg Loss: 1.4052, Avg Regression Loss 0.3957, Avg Classification Loss: 1.0095\n",
            "2023-03-07 03:17:18 - Epoch: 122, Step: 30/38, Avg Loss: 1.3467, Avg Regression Loss 0.2498, Avg Classification Loss: 1.0968\n",
            "2023-03-07 03:17:26 - Epoch: 122, Training Loss: 1.2123, Training Regression Loss 0.2542, Training Classification Loss: 0.9582\n",
            "2023-03-07 03:17:27 - Epoch: 122, Validation Loss: 0.8972, Validation Regression Loss 0.1515, Validation Classification Loss: 0.7457\n",
            "2023-03-07 03:17:27 - Saved model models/model0110/mb1-ssd-Epoch-122-Loss-0.8971695005893707.pth\n",
            "2023-03-07 03:17:41 - Epoch: 123, Step: 10/38, Avg Loss: 1.1163, Avg Regression Loss 0.2403, Avg Classification Loss: 0.8760\n",
            "2023-03-07 03:17:52 - Epoch: 123, Step: 20/38, Avg Loss: 1.7825, Avg Regression Loss 0.4059, Avg Classification Loss: 1.3766\n",
            "2023-03-07 03:18:03 - Epoch: 123, Step: 30/38, Avg Loss: 1.0789, Avg Regression Loss 0.2492, Avg Classification Loss: 0.8297\n",
            "2023-03-07 03:18:09 - Epoch: 123, Training Loss: 1.2234, Training Regression Loss 0.2790, Training Classification Loss: 0.9444\n",
            "2023-03-07 03:18:11 - Epoch: 123, Validation Loss: 0.8007, Validation Regression Loss 0.1365, Validation Classification Loss: 0.6642\n",
            "2023-03-07 03:18:11 - Saved model models/model0110/mb1-ssd-Epoch-123-Loss-0.8007398396730423.pth\n",
            "2023-03-07 03:18:24 - Epoch: 124, Step: 10/38, Avg Loss: 1.3827, Avg Regression Loss 0.3097, Avg Classification Loss: 1.0730\n",
            "2023-03-07 03:18:35 - Epoch: 124, Step: 20/38, Avg Loss: 0.8595, Avg Regression Loss 0.1958, Avg Classification Loss: 0.6637\n",
            "2023-03-07 03:18:48 - Epoch: 124, Step: 30/38, Avg Loss: 1.4043, Avg Regression Loss 0.2685, Avg Classification Loss: 1.1358\n",
            "2023-03-07 03:18:54 - Epoch: 124, Training Loss: 1.1597, Training Regression Loss 0.2381, Training Classification Loss: 0.9217\n",
            "2023-03-07 03:18:56 - Epoch: 124, Validation Loss: 0.8831, Validation Regression Loss 0.1473, Validation Classification Loss: 0.7358\n",
            "2023-03-07 03:18:56 - Saved model models/model0110/mb1-ssd-Epoch-124-Loss-0.8831086903810501.pth\n",
            "2023-03-07 03:19:09 - Epoch: 125, Step: 10/38, Avg Loss: 1.3332, Avg Regression Loss 0.2327, Avg Classification Loss: 1.1005\n",
            "2023-03-07 03:19:20 - Epoch: 125, Step: 20/38, Avg Loss: 1.1130, Avg Regression Loss 0.2258, Avg Classification Loss: 0.8872\n",
            "2023-03-07 03:19:31 - Epoch: 125, Step: 30/38, Avg Loss: 1.1137, Avg Regression Loss 0.2954, Avg Classification Loss: 0.8182\n",
            "2023-03-07 03:19:38 - Epoch: 125, Training Loss: 1.1275, Training Regression Loss 0.2399, Training Classification Loss: 0.8877\n",
            "2023-03-07 03:19:40 - Epoch: 125, Validation Loss: 0.8101, Validation Regression Loss 0.1425, Validation Classification Loss: 0.6675\n",
            "2023-03-07 03:19:40 - Saved model models/model0110/mb1-ssd-Epoch-125-Loss-0.8100665062665939.pth\n",
            "2023-03-07 03:19:53 - Epoch: 126, Step: 10/38, Avg Loss: 0.8892, Avg Regression Loss 0.1874, Avg Classification Loss: 0.7017\n",
            "2023-03-07 03:20:03 - Epoch: 126, Step: 20/38, Avg Loss: 0.9955, Avg Regression Loss 0.1944, Avg Classification Loss: 0.8011\n",
            "2023-03-07 03:20:14 - Epoch: 126, Step: 30/38, Avg Loss: 1.3167, Avg Regression Loss 0.2417, Avg Classification Loss: 1.0750\n",
            "2023-03-07 03:20:21 - Epoch: 126, Training Loss: 1.0771, Training Regression Loss 0.2129, Training Classification Loss: 0.8642\n",
            "2023-03-07 03:20:23 - Epoch: 126, Validation Loss: 0.8538, Validation Regression Loss 0.1478, Validation Classification Loss: 0.7060\n",
            "2023-03-07 03:20:23 - Saved model models/model0110/mb1-ssd-Epoch-126-Loss-0.8537972718477249.pth\n",
            "2023-03-07 03:20:36 - Epoch: 127, Step: 10/38, Avg Loss: 1.0436, Avg Regression Loss 0.1756, Avg Classification Loss: 0.8681\n",
            "2023-03-07 03:20:46 - Epoch: 127, Step: 20/38, Avg Loss: 1.2923, Avg Regression Loss 0.2555, Avg Classification Loss: 1.0368\n",
            "2023-03-07 03:20:56 - Epoch: 127, Step: 30/38, Avg Loss: 1.1360, Avg Regression Loss 0.2501, Avg Classification Loss: 0.8859\n",
            "2023-03-07 03:21:04 - Epoch: 127, Training Loss: 1.0979, Training Regression Loss 0.2181, Training Classification Loss: 0.8798\n",
            "2023-03-07 03:21:05 - Epoch: 127, Validation Loss: 0.8550, Validation Regression Loss 0.1501, Validation Classification Loss: 0.7049\n",
            "2023-03-07 03:21:05 - Saved model models/model0110/mb1-ssd-Epoch-127-Loss-0.8550441265106201.pth\n",
            "2023-03-07 03:21:19 - Epoch: 128, Step: 10/38, Avg Loss: 1.0553, Avg Regression Loss 0.2089, Avg Classification Loss: 0.8464\n",
            "2023-03-07 03:21:31 - Epoch: 128, Step: 20/38, Avg Loss: 1.4149, Avg Regression Loss 0.3097, Avg Classification Loss: 1.1052\n",
            "2023-03-07 03:21:41 - Epoch: 128, Step: 30/38, Avg Loss: 1.2196, Avg Regression Loss 0.2903, Avg Classification Loss: 0.9293\n",
            "2023-03-07 03:21:48 - Epoch: 128, Training Loss: 1.2435, Training Regression Loss 0.2806, Training Classification Loss: 0.9629\n",
            "2023-03-07 03:21:49 - Epoch: 128, Validation Loss: 0.8797, Validation Regression Loss 0.1616, Validation Classification Loss: 0.7181\n",
            "2023-03-07 03:21:49 - Saved model models/model0110/mb1-ssd-Epoch-128-Loss-0.8797353506088257.pth\n",
            "2023-03-07 03:22:03 - Epoch: 129, Step: 10/38, Avg Loss: 1.0822, Avg Regression Loss 0.2389, Avg Classification Loss: 0.8433\n",
            "2023-03-07 03:22:16 - Epoch: 129, Step: 20/38, Avg Loss: 1.2030, Avg Regression Loss 0.2783, Avg Classification Loss: 0.9247\n",
            "2023-03-07 03:22:26 - Epoch: 129, Step: 30/38, Avg Loss: 1.0262, Avg Regression Loss 0.2204, Avg Classification Loss: 0.8057\n",
            "2023-03-07 03:22:33 - Epoch: 129, Training Loss: 1.0577, Training Regression Loss 0.2358, Training Classification Loss: 0.8219\n",
            "2023-03-07 03:22:34 - Epoch: 129, Validation Loss: 0.8320, Validation Regression Loss 0.1711, Validation Classification Loss: 0.6609\n",
            "2023-03-07 03:22:34 - Saved model models/model0110/mb1-ssd-Epoch-129-Loss-0.8320105075836182.pth\n",
            "2023-03-07 03:22:48 - Epoch: 130, Step: 10/38, Avg Loss: 1.1566, Avg Regression Loss 0.2107, Avg Classification Loss: 0.9459\n",
            "2023-03-07 03:22:59 - Epoch: 130, Step: 20/38, Avg Loss: 1.0713, Avg Regression Loss 0.2287, Avg Classification Loss: 0.8426\n",
            "2023-03-07 03:23:10 - Epoch: 130, Step: 30/38, Avg Loss: 1.4369, Avg Regression Loss 0.3630, Avg Classification Loss: 1.0739\n",
            "2023-03-07 03:23:16 - Epoch: 130, Training Loss: 1.2750, Training Regression Loss 0.2596, Training Classification Loss: 1.0154\n",
            "2023-03-07 03:23:17 - Epoch: 130, Validation Loss: 0.7994, Validation Regression Loss 0.1361, Validation Classification Loss: 0.6633\n",
            "2023-03-07 03:23:17 - Saved model models/model0110/mb1-ssd-Epoch-130-Loss-0.7994465529918671.pth\n",
            "2023-03-07 03:23:31 - Epoch: 131, Step: 10/38, Avg Loss: 1.0867, Avg Regression Loss 0.2125, Avg Classification Loss: 0.8742\n",
            "2023-03-07 03:23:42 - Epoch: 131, Step: 20/38, Avg Loss: 1.0174, Avg Regression Loss 0.1683, Avg Classification Loss: 0.8492\n",
            "2023-03-07 03:23:53 - Epoch: 131, Step: 30/38, Avg Loss: 0.9753, Avg Regression Loss 0.1976, Avg Classification Loss: 0.7777\n",
            "2023-03-07 03:23:59 - Epoch: 131, Training Loss: 1.0494, Training Regression Loss 0.2037, Training Classification Loss: 0.8457\n",
            "2023-03-07 03:24:00 - Epoch: 131, Validation Loss: 0.8356, Validation Regression Loss 0.1808, Validation Classification Loss: 0.6549\n",
            "2023-03-07 03:24:00 - Saved model models/model0110/mb1-ssd-Epoch-131-Loss-0.8356436640024185.pth\n",
            "2023-03-07 03:24:13 - Epoch: 132, Step: 10/38, Avg Loss: 1.4783, Avg Regression Loss 0.2967, Avg Classification Loss: 1.1816\n",
            "2023-03-07 03:24:25 - Epoch: 132, Step: 20/38, Avg Loss: 1.2101, Avg Regression Loss 0.2167, Avg Classification Loss: 0.9934\n",
            "2023-03-07 03:24:36 - Epoch: 132, Step: 30/38, Avg Loss: 1.2307, Avg Regression Loss 0.2655, Avg Classification Loss: 0.9652\n",
            "2023-03-07 03:24:42 - Epoch: 132, Training Loss: 1.2725, Training Regression Loss 0.2562, Training Classification Loss: 1.0164\n",
            "2023-03-07 03:24:45 - Epoch: 132, Validation Loss: 0.8945, Validation Regression Loss 0.1744, Validation Classification Loss: 0.7201\n",
            "2023-03-07 03:24:45 - Saved model models/model0110/mb1-ssd-Epoch-132-Loss-0.8945416510105133.pth\n",
            "2023-03-07 03:24:58 - Epoch: 133, Step: 10/38, Avg Loss: 1.2060, Avg Regression Loss 0.2237, Avg Classification Loss: 0.9824\n",
            "2023-03-07 03:25:09 - Epoch: 133, Step: 20/38, Avg Loss: 1.1455, Avg Regression Loss 0.2786, Avg Classification Loss: 0.8669\n",
            "2023-03-07 03:25:21 - Epoch: 133, Step: 30/38, Avg Loss: 1.0709, Avg Regression Loss 0.2512, Avg Classification Loss: 0.8197\n",
            "2023-03-07 03:25:29 - Epoch: 133, Training Loss: 1.1022, Training Regression Loss 0.2313, Training Classification Loss: 0.8709\n",
            "2023-03-07 03:25:30 - Epoch: 133, Validation Loss: 0.8949, Validation Regression Loss 0.1708, Validation Classification Loss: 0.7241\n",
            "2023-03-07 03:25:30 - Saved model models/model0110/mb1-ssd-Epoch-133-Loss-0.8948541730642319.pth\n",
            "2023-03-07 03:25:46 - Epoch: 134, Step: 10/38, Avg Loss: 1.2353, Avg Regression Loss 0.2877, Avg Classification Loss: 0.9476\n",
            "2023-03-07 03:25:57 - Epoch: 134, Step: 20/38, Avg Loss: 0.9841, Avg Regression Loss 0.2267, Avg Classification Loss: 0.7574\n",
            "2023-03-07 03:26:07 - Epoch: 134, Step: 30/38, Avg Loss: 1.5153, Avg Regression Loss 0.2963, Avg Classification Loss: 1.2190\n",
            "2023-03-07 03:26:15 - Epoch: 134, Training Loss: 1.2199, Training Regression Loss 0.2567, Training Classification Loss: 0.9632\n",
            "2023-03-07 03:26:16 - Epoch: 134, Validation Loss: 0.9296, Validation Regression Loss 0.1681, Validation Classification Loss: 0.7616\n",
            "2023-03-07 03:26:16 - Saved model models/model0110/mb1-ssd-Epoch-134-Loss-0.9296417236328125.pth\n",
            "2023-03-07 03:26:30 - Epoch: 135, Step: 10/38, Avg Loss: 1.2136, Avg Regression Loss 0.2458, Avg Classification Loss: 0.9678\n",
            "2023-03-07 03:26:41 - Epoch: 135, Step: 20/38, Avg Loss: 1.0952, Avg Regression Loss 0.2001, Avg Classification Loss: 0.8951\n",
            "2023-03-07 03:26:50 - Epoch: 135, Step: 30/38, Avg Loss: 1.1113, Avg Regression Loss 0.1948, Avg Classification Loss: 0.9165\n",
            "2023-03-07 03:26:58 - Epoch: 135, Training Loss: 1.2057, Training Regression Loss 0.2514, Training Classification Loss: 0.9543\n",
            "2023-03-07 03:26:59 - Epoch: 135, Validation Loss: 0.8581, Validation Regression Loss 0.1750, Validation Classification Loss: 0.6831\n",
            "2023-03-07 03:26:59 - Saved model models/model0110/mb1-ssd-Epoch-135-Loss-0.8581472635269165.pth\n",
            "2023-03-07 03:27:13 - Epoch: 136, Step: 10/38, Avg Loss: 1.3338, Avg Regression Loss 0.2597, Avg Classification Loss: 1.0741\n",
            "2023-03-07 03:27:24 - Epoch: 136, Step: 20/38, Avg Loss: 0.9911, Avg Regression Loss 0.2450, Avg Classification Loss: 0.7460\n",
            "2023-03-07 03:27:34 - Epoch: 136, Step: 30/38, Avg Loss: 1.0733, Avg Regression Loss 0.2525, Avg Classification Loss: 0.8208\n",
            "2023-03-07 03:27:41 - Epoch: 136, Training Loss: 1.0636, Training Regression Loss 0.2404, Training Classification Loss: 0.8231\n",
            "2023-03-07 03:27:42 - Epoch: 136, Validation Loss: 0.9538, Validation Regression Loss 0.1867, Validation Classification Loss: 0.7671\n",
            "2023-03-07 03:27:42 - Saved model models/model0110/mb1-ssd-Epoch-136-Loss-0.9537747502326965.pth\n",
            "2023-03-07 03:27:55 - Epoch: 137, Step: 10/38, Avg Loss: 1.0752, Avg Regression Loss 0.2194, Avg Classification Loss: 0.8558\n",
            "2023-03-07 03:28:06 - Epoch: 137, Step: 20/38, Avg Loss: 1.3274, Avg Regression Loss 0.2428, Avg Classification Loss: 1.0845\n",
            "2023-03-07 03:28:17 - Epoch: 137, Step: 30/38, Avg Loss: 1.0838, Avg Regression Loss 0.2220, Avg Classification Loss: 0.8619\n",
            "2023-03-07 03:28:23 - Epoch: 137, Training Loss: 1.1112, Training Regression Loss 0.2183, Training Classification Loss: 0.8929\n",
            "2023-03-07 03:28:25 - Epoch: 137, Validation Loss: 0.7909, Validation Regression Loss 0.1221, Validation Classification Loss: 0.6688\n",
            "2023-03-07 03:28:25 - Saved model models/model0110/mb1-ssd-Epoch-137-Loss-0.7909015119075775.pth\n",
            "2023-03-07 03:28:38 - Epoch: 138, Step: 10/38, Avg Loss: 1.1676, Avg Regression Loss 0.2618, Avg Classification Loss: 0.9058\n",
            "2023-03-07 03:28:49 - Epoch: 138, Step: 20/38, Avg Loss: 0.8508, Avg Regression Loss 0.1990, Avg Classification Loss: 0.6518\n",
            "2023-03-07 03:29:00 - Epoch: 138, Step: 30/38, Avg Loss: 1.4550, Avg Regression Loss 0.3524, Avg Classification Loss: 1.1026\n",
            "2023-03-07 03:29:08 - Epoch: 138, Training Loss: 1.1114, Training Regression Loss 0.2599, Training Classification Loss: 0.8516\n",
            "2023-03-07 03:29:10 - Epoch: 138, Validation Loss: 0.8276, Validation Regression Loss 0.1508, Validation Classification Loss: 0.6768\n",
            "2023-03-07 03:29:10 - Saved model models/model0110/mb1-ssd-Epoch-138-Loss-0.8276127129793167.pth\n",
            "2023-03-07 03:29:23 - Epoch: 139, Step: 10/38, Avg Loss: 1.6165, Avg Regression Loss 0.4585, Avg Classification Loss: 1.1580\n",
            "2023-03-07 03:29:33 - Epoch: 139, Step: 20/38, Avg Loss: 0.9614, Avg Regression Loss 0.2010, Avg Classification Loss: 0.7604\n",
            "2023-03-07 03:29:44 - Epoch: 139, Step: 30/38, Avg Loss: 1.0757, Avg Regression Loss 0.2232, Avg Classification Loss: 0.8525\n",
            "2023-03-07 03:29:51 - Epoch: 139, Training Loss: 1.1497, Training Regression Loss 0.2736, Training Classification Loss: 0.8761\n",
            "2023-03-07 03:29:53 - Epoch: 139, Validation Loss: 0.9103, Validation Regression Loss 0.1564, Validation Classification Loss: 0.7538\n",
            "2023-03-07 03:29:53 - Saved model models/model0110/mb1-ssd-Epoch-139-Loss-0.9102616757154465.pth\n",
            "2023-03-07 03:30:05 - Epoch: 140, Step: 10/38, Avg Loss: 1.2678, Avg Regression Loss 0.2318, Avg Classification Loss: 1.0360\n",
            "2023-03-07 03:30:15 - Epoch: 140, Step: 20/38, Avg Loss: 1.0414, Avg Regression Loss 0.2464, Avg Classification Loss: 0.7949\n",
            "2023-03-07 03:30:26 - Epoch: 140, Step: 30/38, Avg Loss: 1.2943, Avg Regression Loss 0.3126, Avg Classification Loss: 0.9817\n",
            "2023-03-07 03:30:34 - Epoch: 140, Training Loss: 1.1282, Training Regression Loss 0.2427, Training Classification Loss: 0.8855\n",
            "2023-03-07 03:30:35 - Epoch: 140, Validation Loss: 0.9538, Validation Regression Loss 0.1861, Validation Classification Loss: 0.7677\n",
            "2023-03-07 03:30:35 - Saved model models/model0110/mb1-ssd-Epoch-140-Loss-0.9538332670927048.pth\n",
            "2023-03-07 03:30:49 - Epoch: 141, Step: 10/38, Avg Loss: 1.4024, Avg Regression Loss 0.2152, Avg Classification Loss: 1.1872\n",
            "2023-03-07 03:30:59 - Epoch: 141, Step: 20/38, Avg Loss: 1.4419, Avg Regression Loss 0.3391, Avg Classification Loss: 1.1028\n",
            "2023-03-07 03:31:09 - Epoch: 141, Step: 30/38, Avg Loss: 1.1487, Avg Regression Loss 0.2001, Avg Classification Loss: 0.9486\n",
            "2023-03-07 03:31:17 - Epoch: 141, Training Loss: 1.3105, Training Regression Loss 0.2600, Training Classification Loss: 1.0505\n",
            "2023-03-07 03:31:18 - Epoch: 141, Validation Loss: 0.8582, Validation Regression Loss 0.1944, Validation Classification Loss: 0.6638\n",
            "2023-03-07 03:31:18 - Saved model models/model0110/mb1-ssd-Epoch-141-Loss-0.8582448065280914.pth\n",
            "2023-03-07 03:31:32 - Epoch: 142, Step: 10/38, Avg Loss: 1.8052, Avg Regression Loss 0.3982, Avg Classification Loss: 1.4070\n",
            "2023-03-07 03:31:43 - Epoch: 142, Step: 20/38, Avg Loss: 0.9926, Avg Regression Loss 0.2131, Avg Classification Loss: 0.7795\n",
            "2023-03-07 03:31:53 - Epoch: 142, Step: 30/38, Avg Loss: 1.4007, Avg Regression Loss 0.2126, Avg Classification Loss: 1.1881\n",
            "2023-03-07 03:32:00 - Epoch: 142, Training Loss: 1.3061, Training Regression Loss 0.2589, Training Classification Loss: 1.0471\n",
            "2023-03-07 03:32:02 - Epoch: 142, Validation Loss: 0.8626, Validation Regression Loss 0.1946, Validation Classification Loss: 0.6680\n",
            "2023-03-07 03:32:02 - Saved model models/model0110/mb1-ssd-Epoch-142-Loss-0.8625756651163101.pth\n",
            "2023-03-07 03:32:15 - Epoch: 143, Step: 10/38, Avg Loss: 1.4677, Avg Regression Loss 0.3882, Avg Classification Loss: 1.0795\n",
            "2023-03-07 03:32:26 - Epoch: 143, Step: 20/38, Avg Loss: 1.3861, Avg Regression Loss 0.2179, Avg Classification Loss: 1.1682\n",
            "2023-03-07 03:32:39 - Epoch: 143, Step: 30/38, Avg Loss: 1.2317, Avg Regression Loss 0.2570, Avg Classification Loss: 0.9747\n",
            "2023-03-07 03:32:45 - Epoch: 143, Training Loss: 1.2902, Training Regression Loss 0.2759, Training Classification Loss: 1.0143\n",
            "2023-03-07 03:32:46 - Epoch: 143, Validation Loss: 0.9906, Validation Regression Loss 0.2043, Validation Classification Loss: 0.7863\n",
            "2023-03-07 03:32:46 - Saved model models/model0110/mb1-ssd-Epoch-143-Loss-0.9905921667814255.pth\n",
            "2023-03-07 03:33:00 - Epoch: 144, Step: 10/38, Avg Loss: 1.0843, Avg Regression Loss 0.2334, Avg Classification Loss: 0.8509\n",
            "2023-03-07 03:33:11 - Epoch: 144, Step: 20/38, Avg Loss: 1.4171, Avg Regression Loss 0.2943, Avg Classification Loss: 1.1228\n",
            "2023-03-07 03:33:22 - Epoch: 144, Step: 30/38, Avg Loss: 1.3657, Avg Regression Loss 0.3050, Avg Classification Loss: 1.0607\n",
            "2023-03-07 03:33:28 - Epoch: 144, Training Loss: 1.2107, Training Regression Loss 0.2783, Training Classification Loss: 0.9324\n",
            "2023-03-07 03:33:30 - Epoch: 144, Validation Loss: 0.9895, Validation Regression Loss 0.2378, Validation Classification Loss: 0.7517\n",
            "2023-03-07 03:33:30 - Saved model models/model0110/mb1-ssd-Epoch-144-Loss-0.9895348846912384.pth\n",
            "2023-03-07 03:33:43 - Epoch: 145, Step: 10/38, Avg Loss: 1.4019, Avg Regression Loss 0.3421, Avg Classification Loss: 1.0598\n",
            "2023-03-07 03:33:54 - Epoch: 145, Step: 20/38, Avg Loss: 1.1704, Avg Regression Loss 0.2675, Avg Classification Loss: 0.9029\n",
            "2023-03-07 03:34:05 - Epoch: 145, Step: 30/38, Avg Loss: 1.2879, Avg Regression Loss 0.2792, Avg Classification Loss: 1.0087\n",
            "2023-03-07 03:34:12 - Epoch: 145, Training Loss: 1.2544, Training Regression Loss 0.2772, Training Classification Loss: 0.9771\n",
            "2023-03-07 03:34:14 - Epoch: 145, Validation Loss: 0.8249, Validation Regression Loss 0.1639, Validation Classification Loss: 0.6610\n",
            "2023-03-07 03:34:14 - Saved model models/model0110/mb1-ssd-Epoch-145-Loss-0.824852392077446.pth\n",
            "2023-03-07 03:34:27 - Epoch: 146, Step: 10/38, Avg Loss: 1.3559, Avg Regression Loss 0.3665, Avg Classification Loss: 0.9894\n",
            "2023-03-07 03:34:37 - Epoch: 146, Step: 20/38, Avg Loss: 1.6864, Avg Regression Loss 0.3823, Avg Classification Loss: 1.3042\n",
            "2023-03-07 03:34:48 - Epoch: 146, Step: 30/38, Avg Loss: 1.5617, Avg Regression Loss 0.4016, Avg Classification Loss: 1.1601\n",
            "2023-03-07 03:34:55 - Epoch: 146, Training Loss: 1.4053, Training Regression Loss 0.3557, Training Classification Loss: 1.0496\n",
            "2023-03-07 03:34:57 - Epoch: 146, Validation Loss: 0.9054, Validation Regression Loss 0.2093, Validation Classification Loss: 0.6962\n",
            "2023-03-07 03:34:57 - Saved model models/model0110/mb1-ssd-Epoch-146-Loss-0.905448704957962.pth\n",
            "2023-03-07 03:35:11 - Epoch: 147, Step: 10/38, Avg Loss: 1.5475, Avg Regression Loss 0.3174, Avg Classification Loss: 1.2301\n",
            "2023-03-07 03:35:26 - Epoch: 147, Step: 20/38, Avg Loss: 1.1131, Avg Regression Loss 0.2060, Avg Classification Loss: 0.9071\n",
            "2023-03-07 03:35:36 - Epoch: 147, Step: 30/38, Avg Loss: 1.5773, Avg Regression Loss 0.4129, Avg Classification Loss: 1.1644\n",
            "2023-03-07 03:35:43 - Epoch: 147, Training Loss: 1.3340, Training Regression Loss 0.3026, Training Classification Loss: 1.0315\n",
            "2023-03-07 03:35:45 - Epoch: 147, Validation Loss: 1.1062, Validation Regression Loss 0.2433, Validation Classification Loss: 0.8628\n",
            "2023-03-07 03:35:45 - Saved model models/model0110/mb1-ssd-Epoch-147-Loss-1.1061517894268036.pth\n",
            "2023-03-07 03:36:00 - Epoch: 148, Step: 10/38, Avg Loss: 1.0409, Avg Regression Loss 0.2789, Avg Classification Loss: 0.7621\n",
            "2023-03-07 03:36:10 - Epoch: 148, Step: 20/38, Avg Loss: 1.9979, Avg Regression Loss 0.2744, Avg Classification Loss: 1.7235\n",
            "2023-03-07 03:36:21 - Epoch: 148, Step: 30/38, Avg Loss: 1.2902, Avg Regression Loss 0.2974, Avg Classification Loss: 0.9928\n",
            "2023-03-07 03:36:27 - Epoch: 148, Training Loss: 1.3766, Training Regression Loss 0.2957, Training Classification Loss: 1.0809\n",
            "2023-03-07 03:36:29 - Epoch: 148, Validation Loss: 0.8916, Validation Regression Loss 0.2129, Validation Classification Loss: 0.6787\n",
            "2023-03-07 03:36:30 - Saved model models/model0110/mb1-ssd-Epoch-148-Loss-0.8916102945804596.pth\n",
            "2023-03-07 03:36:42 - Epoch: 149, Step: 10/38, Avg Loss: 1.3455, Avg Regression Loss 0.3367, Avg Classification Loss: 1.0088\n",
            "2023-03-07 03:36:53 - Epoch: 149, Step: 20/38, Avg Loss: 1.1519, Avg Regression Loss 0.2066, Avg Classification Loss: 0.9452\n",
            "2023-03-07 03:37:03 - Epoch: 149, Step: 30/38, Avg Loss: 1.1321, Avg Regression Loss 0.3089, Avg Classification Loss: 0.8232\n",
            "2023-03-07 03:37:11 - Epoch: 149, Training Loss: 1.2211, Training Regression Loss 0.2977, Training Classification Loss: 0.9234\n",
            "2023-03-07 03:37:12 - Epoch: 149, Validation Loss: 0.8647, Validation Regression Loss 0.1661, Validation Classification Loss: 0.6987\n",
            "2023-03-07 03:37:12 - Saved model models/model0110/mb1-ssd-Epoch-149-Loss-0.8647497296333313.pth\n",
            "2023-03-07 03:37:25 - Epoch: 150, Step: 10/38, Avg Loss: 1.1191, Avg Regression Loss 0.2504, Avg Classification Loss: 0.8687\n",
            "2023-03-07 03:37:35 - Epoch: 150, Step: 20/38, Avg Loss: 1.1639, Avg Regression Loss 0.2449, Avg Classification Loss: 0.9190\n",
            "2023-03-07 03:37:45 - Epoch: 150, Step: 30/38, Avg Loss: 1.0001, Avg Regression Loss 0.2093, Avg Classification Loss: 0.7907\n",
            "2023-03-07 03:37:53 - Epoch: 150, Training Loss: 1.0534, Training Regression Loss 0.2279, Training Classification Loss: 0.8255\n",
            "2023-03-07 03:37:54 - Epoch: 150, Validation Loss: 0.8980, Validation Regression Loss 0.1739, Validation Classification Loss: 0.7241\n",
            "2023-03-07 03:37:54 - Saved model models/model0110/mb1-ssd-Epoch-150-Loss-0.8979961276054382.pth\n",
            "2023-03-07 03:38:07 - Epoch: 151, Step: 10/38, Avg Loss: 1.1855, Avg Regression Loss 0.2586, Avg Classification Loss: 0.9269\n",
            "2023-03-07 03:38:17 - Epoch: 151, Step: 20/38, Avg Loss: 1.1782, Avg Regression Loss 0.2778, Avg Classification Loss: 0.9005\n",
            "2023-03-07 03:38:27 - Epoch: 151, Step: 30/38, Avg Loss: 1.7386, Avg Regression Loss 0.5139, Avg Classification Loss: 1.2247\n",
            "2023-03-07 03:38:34 - Epoch: 151, Training Loss: 1.3170, Training Regression Loss 0.3356, Training Classification Loss: 0.9814\n",
            "2023-03-07 03:38:36 - Epoch: 151, Validation Loss: 0.9246, Validation Regression Loss 0.1607, Validation Classification Loss: 0.7639\n",
            "2023-03-07 03:38:36 - Saved model models/model0110/mb1-ssd-Epoch-151-Loss-0.9246469885110855.pth\n",
            "2023-03-07 03:38:49 - Epoch: 152, Step: 10/38, Avg Loss: 1.4343, Avg Regression Loss 0.3268, Avg Classification Loss: 1.1076\n",
            "2023-03-07 03:38:59 - Epoch: 152, Step: 20/38, Avg Loss: 1.0573, Avg Regression Loss 0.2414, Avg Classification Loss: 0.8160\n",
            "2023-03-07 03:39:10 - Epoch: 152, Step: 30/38, Avg Loss: 1.2160, Avg Regression Loss 0.2849, Avg Classification Loss: 0.9311\n",
            "2023-03-07 03:39:16 - Epoch: 152, Training Loss: 1.3265, Training Regression Loss 0.3160, Training Classification Loss: 1.0105\n",
            "2023-03-07 03:39:18 - Epoch: 152, Validation Loss: 0.8052, Validation Regression Loss 0.1502, Validation Classification Loss: 0.6550\n",
            "2023-03-07 03:39:18 - Saved model models/model0110/mb1-ssd-Epoch-152-Loss-0.8051767647266388.pth\n",
            "2023-03-07 03:39:32 - Epoch: 153, Step: 10/38, Avg Loss: 1.4977, Avg Regression Loss 0.3254, Avg Classification Loss: 1.1723\n",
            "2023-03-07 03:39:43 - Epoch: 153, Step: 20/38, Avg Loss: 1.0604, Avg Regression Loss 0.2719, Avg Classification Loss: 0.7885\n",
            "2023-03-07 03:39:53 - Epoch: 153, Step: 30/38, Avg Loss: 1.4010, Avg Regression Loss 0.2990, Avg Classification Loss: 1.1020\n",
            "2023-03-07 03:40:00 - Epoch: 153, Training Loss: 1.2586, Training Regression Loss 0.2900, Training Classification Loss: 0.9686\n",
            "2023-03-07 03:40:01 - Epoch: 153, Validation Loss: 1.0017, Validation Regression Loss 0.2297, Validation Classification Loss: 0.7720\n",
            "2023-03-07 03:40:02 - Saved model models/model0110/mb1-ssd-Epoch-153-Loss-1.0017040073871613.pth\n",
            "2023-03-07 03:40:15 - Epoch: 154, Step: 10/38, Avg Loss: 1.8793, Avg Regression Loss 0.4289, Avg Classification Loss: 1.4503\n",
            "2023-03-07 03:40:25 - Epoch: 154, Step: 20/38, Avg Loss: 0.9994, Avg Regression Loss 0.2298, Avg Classification Loss: 0.7696\n",
            "2023-03-07 03:40:35 - Epoch: 154, Step: 30/38, Avg Loss: 1.5477, Avg Regression Loss 0.4348, Avg Classification Loss: 1.1129\n",
            "2023-03-07 03:40:42 - Epoch: 154, Training Loss: 1.4242, Training Regression Loss 0.3555, Training Classification Loss: 1.0688\n",
            "2023-03-07 03:40:44 - Epoch: 154, Validation Loss: 1.0021, Validation Regression Loss 0.2230, Validation Classification Loss: 0.7791\n",
            "2023-03-07 03:40:44 - Saved model models/model0110/mb1-ssd-Epoch-154-Loss-1.002091884613037.pth\n",
            "2023-03-07 03:40:57 - Epoch: 155, Step: 10/38, Avg Loss: 1.7568, Avg Regression Loss 0.3942, Avg Classification Loss: 1.3626\n",
            "2023-03-07 03:41:08 - Epoch: 155, Step: 20/38, Avg Loss: 1.4678, Avg Regression Loss 0.4175, Avg Classification Loss: 1.0503\n",
            "2023-03-07 03:41:17 - Epoch: 155, Step: 30/38, Avg Loss: 1.3457, Avg Regression Loss 0.3116, Avg Classification Loss: 1.0341\n",
            "2023-03-07 03:41:24 - Epoch: 155, Training Loss: 1.4393, Training Regression Loss 0.3611, Training Classification Loss: 1.0782\n",
            "2023-03-07 03:41:26 - Epoch: 155, Validation Loss: 1.0526, Validation Regression Loss 0.2103, Validation Classification Loss: 0.8423\n",
            "2023-03-07 03:41:26 - Saved model models/model0110/mb1-ssd-Epoch-155-Loss-1.052611529827118.pth\n",
            "2023-03-07 03:41:39 - Epoch: 156, Step: 10/38, Avg Loss: 1.2545, Avg Regression Loss 0.3100, Avg Classification Loss: 0.9444\n",
            "2023-03-07 03:41:50 - Epoch: 156, Step: 20/38, Avg Loss: 1.6617, Avg Regression Loss 0.3651, Avg Classification Loss: 1.2966\n",
            "2023-03-07 03:42:00 - Epoch: 156, Step: 30/38, Avg Loss: 1.1526, Avg Regression Loss 0.3354, Avg Classification Loss: 0.8171\n",
            "2023-03-07 03:42:06 - Epoch: 156, Training Loss: 1.3465, Training Regression Loss 0.3387, Training Classification Loss: 1.0078\n",
            "2023-03-07 03:42:08 - Epoch: 156, Validation Loss: 1.0755, Validation Regression Loss 0.2268, Validation Classification Loss: 0.8487\n",
            "2023-03-07 03:42:08 - Saved model models/model0110/mb1-ssd-Epoch-156-Loss-1.0754970014095306.pth\n",
            "2023-03-07 03:42:22 - Epoch: 157, Step: 10/38, Avg Loss: 2.0233, Avg Regression Loss 0.5190, Avg Classification Loss: 1.5043\n",
            "2023-03-07 03:42:32 - Epoch: 157, Step: 20/38, Avg Loss: 1.2488, Avg Regression Loss 0.2961, Avg Classification Loss: 0.9527\n",
            "2023-03-07 03:42:43 - Epoch: 157, Step: 30/38, Avg Loss: 1.3522, Avg Regression Loss 0.3213, Avg Classification Loss: 1.0309\n",
            "2023-03-07 03:42:51 - Epoch: 157, Training Loss: 1.5345, Training Regression Loss 0.3782, Training Classification Loss: 1.1564\n",
            "2023-03-07 03:42:53 - Epoch: 157, Validation Loss: 1.0019, Validation Regression Loss 0.2088, Validation Classification Loss: 0.7931\n",
            "2023-03-07 03:42:53 - Saved model models/model0110/mb1-ssd-Epoch-157-Loss-1.0018768608570099.pth\n",
            "2023-03-07 03:43:06 - Epoch: 158, Step: 10/38, Avg Loss: 1.4748, Avg Regression Loss 0.3479, Avg Classification Loss: 1.1269\n",
            "2023-03-07 03:43:16 - Epoch: 158, Step: 20/38, Avg Loss: 1.4958, Avg Regression Loss 0.4281, Avg Classification Loss: 1.0677\n",
            "2023-03-07 03:43:26 - Epoch: 158, Step: 30/38, Avg Loss: 1.2509, Avg Regression Loss 0.3192, Avg Classification Loss: 0.9318\n",
            "2023-03-07 03:43:33 - Epoch: 158, Training Loss: 1.2963, Training Regression Loss 0.3347, Training Classification Loss: 0.9616\n",
            "2023-03-07 03:43:35 - Epoch: 158, Validation Loss: 0.9741, Validation Regression Loss 0.1668, Validation Classification Loss: 0.8073\n",
            "2023-03-07 03:43:35 - Saved model models/model0110/mb1-ssd-Epoch-158-Loss-0.9740784168243408.pth\n",
            "2023-03-07 03:43:47 - Epoch: 159, Step: 10/38, Avg Loss: 1.4871, Avg Regression Loss 0.3827, Avg Classification Loss: 1.1044\n",
            "2023-03-07 03:43:58 - Epoch: 159, Step: 20/38, Avg Loss: 1.1379, Avg Regression Loss 0.2228, Avg Classification Loss: 0.9151\n",
            "2023-03-07 03:44:08 - Epoch: 159, Step: 30/38, Avg Loss: 1.5300, Avg Regression Loss 0.3312, Avg Classification Loss: 1.1988\n",
            "2023-03-07 03:44:15 - Epoch: 159, Training Loss: 1.3411, Training Regression Loss 0.2958, Training Classification Loss: 1.0453\n",
            "2023-03-07 03:44:16 - Epoch: 159, Validation Loss: 0.8927, Validation Regression Loss 0.2089, Validation Classification Loss: 0.6838\n",
            "2023-03-07 03:44:16 - Saved model models/model0110/mb1-ssd-Epoch-159-Loss-0.8927227556705475.pth\n",
            "2023-03-07 03:44:30 - Epoch: 160, Step: 10/38, Avg Loss: 1.6117, Avg Regression Loss 0.4889, Avg Classification Loss: 1.1228\n",
            "2023-03-07 03:44:41 - Epoch: 160, Step: 20/38, Avg Loss: 1.5329, Avg Regression Loss 0.3754, Avg Classification Loss: 1.1575\n",
            "2023-03-07 03:44:51 - Epoch: 160, Step: 30/38, Avg Loss: 1.7462, Avg Regression Loss 0.3869, Avg Classification Loss: 1.3593\n",
            "2023-03-07 03:44:57 - Epoch: 160, Training Loss: 1.4845, Training Regression Loss 0.3810, Training Classification Loss: 1.1034\n",
            "2023-03-07 03:44:58 - Epoch: 160, Validation Loss: 1.0881, Validation Regression Loss 0.2712, Validation Classification Loss: 0.8169\n",
            "2023-03-07 03:44:59 - Saved model models/model0110/mb1-ssd-Epoch-160-Loss-1.0881097614765167.pth\n",
            "2023-03-07 03:45:13 - Epoch: 161, Step: 10/38, Avg Loss: 1.8534, Avg Regression Loss 0.3826, Avg Classification Loss: 1.4708\n",
            "2023-03-07 03:45:23 - Epoch: 161, Step: 20/38, Avg Loss: 2.2949, Avg Regression Loss 0.5292, Avg Classification Loss: 1.7657\n",
            "2023-03-07 03:45:38 - Epoch: 161, Step: 30/38, Avg Loss: 1.4918, Avg Regression Loss 0.4259, Avg Classification Loss: 1.0658\n",
            "2023-03-07 03:45:46 - Epoch: 161, Training Loss: 1.7146, Training Regression Loss 0.4045, Training Classification Loss: 1.3102\n",
            "2023-03-07 03:45:47 - Epoch: 161, Validation Loss: 1.2453, Validation Regression Loss 0.3450, Validation Classification Loss: 0.9003\n",
            "2023-03-07 03:45:47 - Saved model models/model0110/mb1-ssd-Epoch-161-Loss-1.2452867329120636.pth\n",
            "2023-03-07 03:46:01 - Epoch: 162, Step: 10/38, Avg Loss: 1.7251, Avg Regression Loss 0.4940, Avg Classification Loss: 1.2311\n",
            "2023-03-07 03:46:13 - Epoch: 162, Step: 20/38, Avg Loss: 1.4778, Avg Regression Loss 0.4332, Avg Classification Loss: 1.0446\n",
            "2023-03-07 03:46:24 - Epoch: 162, Step: 30/38, Avg Loss: 1.3866, Avg Regression Loss 0.3717, Avg Classification Loss: 1.0149\n",
            "2023-03-07 03:46:30 - Epoch: 162, Training Loss: 1.4847, Training Regression Loss 0.4049, Training Classification Loss: 1.0798\n",
            "2023-03-07 03:46:31 - Epoch: 162, Validation Loss: 0.9621, Validation Regression Loss 0.1963, Validation Classification Loss: 0.7658\n",
            "2023-03-07 03:46:31 - Saved model models/model0110/mb1-ssd-Epoch-162-Loss-0.9620911926031113.pth\n",
            "2023-03-07 03:46:45 - Epoch: 163, Step: 10/38, Avg Loss: 1.6798, Avg Regression Loss 0.3693, Avg Classification Loss: 1.3105\n",
            "2023-03-07 03:46:56 - Epoch: 163, Step: 20/38, Avg Loss: 1.2597, Avg Regression Loss 0.2378, Avg Classification Loss: 1.0219\n",
            "2023-03-07 03:47:06 - Epoch: 163, Step: 30/38, Avg Loss: 1.5424, Avg Regression Loss 0.3866, Avg Classification Loss: 1.1558\n",
            "2023-03-07 03:47:13 - Epoch: 163, Training Loss: 1.4845, Training Regression Loss 0.3459, Training Classification Loss: 1.1386\n",
            "2023-03-07 03:47:15 - Epoch: 163, Validation Loss: 0.8963, Validation Regression Loss 0.2011, Validation Classification Loss: 0.6951\n",
            "2023-03-07 03:47:15 - Saved model models/model0110/mb1-ssd-Epoch-163-Loss-0.8962672352790833.pth\n",
            "2023-03-07 03:47:28 - Epoch: 164, Step: 10/38, Avg Loss: 1.7276, Avg Regression Loss 0.4928, Avg Classification Loss: 1.2348\n",
            "2023-03-07 03:47:37 - Epoch: 164, Step: 20/38, Avg Loss: 1.3579, Avg Regression Loss 0.3881, Avg Classification Loss: 0.9697\n",
            "2023-03-07 03:47:48 - Epoch: 164, Step: 30/38, Avg Loss: 1.7709, Avg Regression Loss 0.3302, Avg Classification Loss: 1.4407\n",
            "2023-03-07 03:47:55 - Epoch: 164, Training Loss: 1.5097, Training Regression Loss 0.3775, Training Classification Loss: 1.1323\n",
            "2023-03-07 03:47:56 - Epoch: 164, Validation Loss: 0.9955, Validation Regression Loss 0.1905, Validation Classification Loss: 0.8050\n",
            "2023-03-07 03:47:56 - Saved model models/model0110/mb1-ssd-Epoch-164-Loss-0.9955388009548187.pth\n",
            "2023-03-07 03:48:10 - Epoch: 165, Step: 10/38, Avg Loss: 1.6177, Avg Regression Loss 0.4194, Avg Classification Loss: 1.1983\n",
            "2023-03-07 03:48:21 - Epoch: 165, Step: 20/38, Avg Loss: 2.3551, Avg Regression Loss 0.5866, Avg Classification Loss: 1.7685\n",
            "2023-03-07 03:48:30 - Epoch: 165, Step: 30/38, Avg Loss: 1.5350, Avg Regression Loss 0.4303, Avg Classification Loss: 1.1047\n",
            "2023-03-07 03:48:37 - Epoch: 165, Training Loss: 1.6771, Training Regression Loss 0.4367, Training Classification Loss: 1.2404\n",
            "2023-03-07 03:48:39 - Epoch: 165, Validation Loss: 1.1507, Validation Regression Loss 0.2879, Validation Classification Loss: 0.8628\n",
            "2023-03-07 03:48:39 - Saved model models/model0110/mb1-ssd-Epoch-165-Loss-1.1506689637899399.pth\n",
            "2023-03-07 03:48:51 - Epoch: 166, Step: 10/38, Avg Loss: 1.3992, Avg Regression Loss 0.3314, Avg Classification Loss: 1.0678\n",
            "2023-03-07 03:49:02 - Epoch: 166, Step: 20/38, Avg Loss: 1.3380, Avg Regression Loss 0.3032, Avg Classification Loss: 1.0348\n",
            "2023-03-07 03:49:12 - Epoch: 166, Step: 30/38, Avg Loss: 1.2749, Avg Regression Loss 0.3096, Avg Classification Loss: 0.9653\n",
            "2023-03-07 03:49:19 - Epoch: 166, Training Loss: 1.2963, Training Regression Loss 0.3127, Training Classification Loss: 0.9836\n",
            "2023-03-07 03:49:20 - Epoch: 166, Validation Loss: 1.0533, Validation Regression Loss 0.2621, Validation Classification Loss: 0.7912\n",
            "2023-03-07 03:49:20 - Saved model models/model0110/mb1-ssd-Epoch-166-Loss-1.0532720983028412.pth\n",
            "2023-03-07 03:49:33 - Epoch: 167, Step: 10/38, Avg Loss: 1.6851, Avg Regression Loss 0.5104, Avg Classification Loss: 1.1748\n",
            "2023-03-07 03:49:45 - Epoch: 167, Step: 20/38, Avg Loss: 1.1831, Avg Regression Loss 0.4023, Avg Classification Loss: 0.7808\n",
            "2023-03-07 03:49:56 - Epoch: 167, Step: 30/38, Avg Loss: 1.1939, Avg Regression Loss 0.2605, Avg Classification Loss: 0.9334\n",
            "2023-03-07 03:50:02 - Epoch: 167, Training Loss: 1.3834, Training Regression Loss 0.3848, Training Classification Loss: 0.9986\n",
            "2023-03-07 03:50:04 - Epoch: 167, Validation Loss: 1.1644, Validation Regression Loss 0.2813, Validation Classification Loss: 0.8831\n",
            "2023-03-07 03:50:04 - Saved model models/model0110/mb1-ssd-Epoch-167-Loss-1.1644141972064972.pth\n",
            "2023-03-07 03:50:17 - Epoch: 168, Step: 10/38, Avg Loss: 1.9098, Avg Regression Loss 0.4752, Avg Classification Loss: 1.4345\n",
            "2023-03-07 03:50:28 - Epoch: 168, Step: 20/38, Avg Loss: 1.9936, Avg Regression Loss 0.6865, Avg Classification Loss: 1.3072\n",
            "2023-03-07 03:50:38 - Epoch: 168, Step: 30/38, Avg Loss: 1.5380, Avg Regression Loss 0.4672, Avg Classification Loss: 1.0708\n",
            "2023-03-07 03:50:46 - Epoch: 168, Training Loss: 1.7076, Training Regression Loss 0.4961, Training Classification Loss: 1.2115\n",
            "2023-03-07 03:50:47 - Epoch: 168, Validation Loss: 1.0028, Validation Regression Loss 0.2303, Validation Classification Loss: 0.7725\n",
            "2023-03-07 03:50:47 - Saved model models/model0110/mb1-ssd-Epoch-168-Loss-1.0028054863214493.pth\n",
            "2023-03-07 03:51:00 - Epoch: 169, Step: 10/38, Avg Loss: 1.5887, Avg Regression Loss 0.4513, Avg Classification Loss: 1.1374\n",
            "2023-03-07 03:51:11 - Epoch: 169, Step: 20/38, Avg Loss: 1.7733, Avg Regression Loss 0.4462, Avg Classification Loss: 1.3271\n",
            "2023-03-07 03:51:20 - Epoch: 169, Step: 30/38, Avg Loss: 1.4828, Avg Regression Loss 0.3286, Avg Classification Loss: 1.1541\n",
            "2023-03-07 03:51:28 - Epoch: 169, Training Loss: 1.4851, Training Regression Loss 0.3745, Training Classification Loss: 1.1106\n",
            "2023-03-07 03:51:29 - Epoch: 169, Validation Loss: 1.1531, Validation Regression Loss 0.2726, Validation Classification Loss: 0.8805\n",
            "2023-03-07 03:51:29 - Saved model models/model0110/mb1-ssd-Epoch-169-Loss-1.1530878841876984.pth\n",
            "2023-03-07 03:51:42 - Epoch: 170, Step: 10/38, Avg Loss: 1.8138, Avg Regression Loss 0.4606, Avg Classification Loss: 1.3532\n",
            "2023-03-07 03:51:53 - Epoch: 170, Step: 20/38, Avg Loss: 1.0894, Avg Regression Loss 0.2615, Avg Classification Loss: 0.8280\n",
            "2023-03-07 03:52:03 - Epoch: 170, Step: 30/38, Avg Loss: 1.5822, Avg Regression Loss 0.3946, Avg Classification Loss: 1.1876\n",
            "2023-03-07 03:52:09 - Epoch: 170, Training Loss: 1.3980, Training Regression Loss 0.3540, Training Classification Loss: 1.0440\n",
            "2023-03-07 03:52:11 - Epoch: 170, Validation Loss: 1.0436, Validation Regression Loss 0.2430, Validation Classification Loss: 0.8007\n",
            "2023-03-07 03:52:11 - Saved model models/model0110/mb1-ssd-Epoch-170-Loss-1.0436396598815918.pth\n",
            "2023-03-07 03:52:24 - Epoch: 171, Step: 10/38, Avg Loss: 1.7554, Avg Regression Loss 0.4540, Avg Classification Loss: 1.3013\n",
            "2023-03-07 03:52:35 - Epoch: 171, Step: 20/38, Avg Loss: 1.3995, Avg Regression Loss 0.3254, Avg Classification Loss: 1.0741\n",
            "2023-03-07 03:52:46 - Epoch: 171, Step: 30/38, Avg Loss: 1.3769, Avg Regression Loss 0.3468, Avg Classification Loss: 1.0301\n",
            "2023-03-07 03:52:52 - Epoch: 171, Training Loss: 1.5253, Training Regression Loss 0.3760, Training Classification Loss: 1.1493\n",
            "2023-03-07 03:52:53 - Epoch: 171, Validation Loss: 1.1862, Validation Regression Loss 0.3077, Validation Classification Loss: 0.8784\n",
            "2023-03-07 03:52:53 - Saved model models/model0110/mb1-ssd-Epoch-171-Loss-1.1861804276704788.pth\n",
            "2023-03-07 03:53:09 - Epoch: 172, Step: 10/38, Avg Loss: 1.5665, Avg Regression Loss 0.3569, Avg Classification Loss: 1.2096\n",
            "2023-03-07 03:53:19 - Epoch: 172, Step: 20/38, Avg Loss: 1.5654, Avg Regression Loss 0.3822, Avg Classification Loss: 1.1832\n",
            "2023-03-07 03:53:29 - Epoch: 172, Step: 30/38, Avg Loss: 1.6857, Avg Regression Loss 0.3673, Avg Classification Loss: 1.3184\n",
            "2023-03-07 03:53:37 - Epoch: 172, Training Loss: 1.5085, Training Regression Loss 0.3582, Training Classification Loss: 1.1503\n",
            "2023-03-07 03:53:38 - Epoch: 172, Validation Loss: 1.1295, Validation Regression Loss 0.2604, Validation Classification Loss: 0.8692\n",
            "2023-03-07 03:53:38 - Saved model models/model0110/mb1-ssd-Epoch-172-Loss-1.1295370310544968.pth\n",
            "2023-03-07 03:53:52 - Epoch: 173, Step: 10/38, Avg Loss: 1.8484, Avg Regression Loss 0.5261, Avg Classification Loss: 1.3222\n",
            "2023-03-07 03:54:03 - Epoch: 173, Step: 20/38, Avg Loss: 1.3992, Avg Regression Loss 0.3191, Avg Classification Loss: 1.0801\n",
            "2023-03-07 03:54:13 - Epoch: 173, Step: 30/38, Avg Loss: 1.3617, Avg Regression Loss 0.3416, Avg Classification Loss: 1.0201\n",
            "2023-03-07 03:54:20 - Epoch: 173, Training Loss: 1.5790, Training Regression Loss 0.4423, Training Classification Loss: 1.1367\n",
            "2023-03-07 03:54:21 - Epoch: 173, Validation Loss: 1.3047, Validation Regression Loss 0.3249, Validation Classification Loss: 0.9798\n",
            "2023-03-07 03:54:21 - Saved model models/model0110/mb1-ssd-Epoch-173-Loss-1.3046731650829315.pth\n",
            "2023-03-07 03:54:34 - Epoch: 174, Step: 10/38, Avg Loss: 1.4318, Avg Regression Loss 0.3297, Avg Classification Loss: 1.1020\n",
            "2023-03-07 03:54:45 - Epoch: 174, Step: 20/38, Avg Loss: 1.7967, Avg Regression Loss 0.4792, Avg Classification Loss: 1.3175\n",
            "2023-03-07 03:54:55 - Epoch: 174, Step: 30/38, Avg Loss: 1.7427, Avg Regression Loss 0.4178, Avg Classification Loss: 1.3249\n",
            "2023-03-07 03:55:01 - Epoch: 174, Training Loss: 1.5327, Training Regression Loss 0.3778, Training Classification Loss: 1.1549\n",
            "2023-03-07 03:55:03 - Epoch: 174, Validation Loss: 0.9390, Validation Regression Loss 0.2462, Validation Classification Loss: 0.6928\n",
            "2023-03-07 03:55:03 - Saved model models/model0110/mb1-ssd-Epoch-174-Loss-0.9389514327049255.pth\n",
            "2023-03-07 03:55:16 - Epoch: 175, Step: 10/38, Avg Loss: 1.5144, Avg Regression Loss 0.3801, Avg Classification Loss: 1.1342\n",
            "2023-03-07 03:55:27 - Epoch: 175, Step: 20/38, Avg Loss: 1.7162, Avg Regression Loss 0.4577, Avg Classification Loss: 1.2585\n",
            "2023-03-07 03:55:37 - Epoch: 175, Step: 30/38, Avg Loss: 1.3716, Avg Regression Loss 0.4121, Avg Classification Loss: 0.9595\n",
            "2023-03-07 03:55:46 - Epoch: 175, Training Loss: 1.4631, Training Regression Loss 0.4020, Training Classification Loss: 1.0610\n",
            "2023-03-07 03:55:49 - Epoch: 175, Validation Loss: 0.9856, Validation Regression Loss 0.2469, Validation Classification Loss: 0.7387\n",
            "2023-03-07 03:55:49 - Saved model models/model0110/mb1-ssd-Epoch-175-Loss-0.985578253865242.pth\n",
            "2023-03-07 03:56:02 - Epoch: 176, Step: 10/38, Avg Loss: 1.5708, Avg Regression Loss 0.3807, Avg Classification Loss: 1.1901\n",
            "2023-03-07 03:56:13 - Epoch: 176, Step: 20/38, Avg Loss: 1.2941, Avg Regression Loss 0.2869, Avg Classification Loss: 1.0073\n",
            "2023-03-07 03:56:24 - Epoch: 176, Step: 30/38, Avg Loss: 1.5589, Avg Regression Loss 0.3723, Avg Classification Loss: 1.1866\n",
            "2023-03-07 03:56:31 - Epoch: 176, Training Loss: 1.4299, Training Regression Loss 0.3375, Training Classification Loss: 1.0923\n",
            "2023-03-07 03:56:33 - Epoch: 176, Validation Loss: 0.8869, Validation Regression Loss 0.1945, Validation Classification Loss: 0.6924\n",
            "2023-03-07 03:56:33 - Saved model models/model0110/mb1-ssd-Epoch-176-Loss-0.8869235664606094.pth\n",
            "2023-03-07 03:56:46 - Epoch: 177, Step: 10/38, Avg Loss: 1.2156, Avg Regression Loss 0.3167, Avg Classification Loss: 0.8989\n",
            "2023-03-07 03:56:56 - Epoch: 177, Step: 20/38, Avg Loss: 1.4075, Avg Regression Loss 0.3809, Avg Classification Loss: 1.0266\n",
            "2023-03-07 03:57:07 - Epoch: 177, Step: 30/38, Avg Loss: 1.1107, Avg Regression Loss 0.2671, Avg Classification Loss: 0.8436\n",
            "2023-03-07 03:57:13 - Epoch: 177, Training Loss: 1.2582, Training Regression Loss 0.3210, Training Classification Loss: 0.9372\n",
            "2023-03-07 03:57:15 - Epoch: 177, Validation Loss: 1.0773, Validation Regression Loss 0.2558, Validation Classification Loss: 0.8215\n",
            "2023-03-07 03:57:15 - Saved model models/model0110/mb1-ssd-Epoch-177-Loss-1.0772621631622314.pth\n",
            "2023-03-07 03:57:28 - Epoch: 178, Step: 10/38, Avg Loss: 1.7592, Avg Regression Loss 0.5001, Avg Classification Loss: 1.2591\n",
            "2023-03-07 03:57:39 - Epoch: 178, Step: 20/38, Avg Loss: 1.4913, Avg Regression Loss 0.3544, Avg Classification Loss: 1.1369\n",
            "2023-03-07 03:57:50 - Epoch: 178, Step: 30/38, Avg Loss: 1.7361, Avg Regression Loss 0.3702, Avg Classification Loss: 1.3659\n",
            "2023-03-07 03:57:56 - Epoch: 178, Training Loss: 1.6555, Training Regression Loss 0.4121, Training Classification Loss: 1.2434\n",
            "2023-03-07 03:57:58 - Epoch: 178, Validation Loss: 1.4206, Validation Regression Loss 0.3825, Validation Classification Loss: 1.0381\n",
            "2023-03-07 03:57:58 - Saved model models/model0110/mb1-ssd-Epoch-178-Loss-1.4205613732337952.pth\n",
            "2023-03-07 03:58:12 - Epoch: 179, Step: 10/38, Avg Loss: 1.9704, Avg Regression Loss 0.5005, Avg Classification Loss: 1.4699\n",
            "2023-03-07 03:58:21 - Epoch: 179, Step: 20/38, Avg Loss: 1.3102, Avg Regression Loss 0.3770, Avg Classification Loss: 0.9331\n",
            "2023-03-07 03:58:32 - Epoch: 179, Step: 30/38, Avg Loss: 1.5194, Avg Regression Loss 0.2905, Avg Classification Loss: 1.2289\n",
            "2023-03-07 03:58:39 - Epoch: 179, Training Loss: 1.5232, Training Regression Loss 0.3866, Training Classification Loss: 1.1366\n",
            "2023-03-07 03:58:40 - Epoch: 179, Validation Loss: 1.1515, Validation Regression Loss 0.3075, Validation Classification Loss: 0.8441\n",
            "2023-03-07 03:58:40 - Saved model models/model0110/mb1-ssd-Epoch-179-Loss-1.1515361666679382.pth\n",
            "2023-03-07 03:58:54 - Epoch: 180, Step: 10/38, Avg Loss: 1.6276, Avg Regression Loss 0.3433, Avg Classification Loss: 1.2843\n",
            "2023-03-07 03:59:04 - Epoch: 180, Step: 20/38, Avg Loss: 1.7281, Avg Regression Loss 0.4900, Avg Classification Loss: 1.2381\n",
            "2023-03-07 03:59:14 - Epoch: 180, Step: 30/38, Avg Loss: 1.6404, Avg Regression Loss 0.4410, Avg Classification Loss: 1.1994\n",
            "2023-03-07 03:59:21 - Epoch: 180, Training Loss: 1.5580, Training Regression Loss 0.3865, Training Classification Loss: 1.1716\n",
            "2023-03-07 03:59:22 - Epoch: 180, Validation Loss: 1.0852, Validation Regression Loss 0.2141, Validation Classification Loss: 0.8711\n",
            "2023-03-07 03:59:22 - Saved model models/model0110/mb1-ssd-Epoch-180-Loss-1.0852047204971313.pth\n",
            "2023-03-07 03:59:35 - Epoch: 181, Step: 10/38, Avg Loss: 1.8178, Avg Regression Loss 0.4303, Avg Classification Loss: 1.3875\n",
            "2023-03-07 03:59:47 - Epoch: 181, Step: 20/38, Avg Loss: 1.3218, Avg Regression Loss 0.3225, Avg Classification Loss: 0.9992\n",
            "2023-03-07 03:59:58 - Epoch: 181, Step: 30/38, Avg Loss: 1.9259, Avg Regression Loss 0.4714, Avg Classification Loss: 1.4545\n",
            "2023-03-07 04:00:04 - Epoch: 181, Training Loss: 1.5875, Training Regression Loss 0.3815, Training Classification Loss: 1.2060\n",
            "2023-03-07 04:00:05 - Epoch: 181, Validation Loss: 1.0699, Validation Regression Loss 0.2060, Validation Classification Loss: 0.8639\n",
            "2023-03-07 04:00:05 - Saved model models/model0110/mb1-ssd-Epoch-181-Loss-1.0698802322149277.pth\n",
            "2023-03-07 04:00:19 - Epoch: 182, Step: 10/38, Avg Loss: 1.6098, Avg Regression Loss 0.4339, Avg Classification Loss: 1.1759\n",
            "2023-03-07 04:00:29 - Epoch: 182, Step: 20/38, Avg Loss: 1.8801, Avg Regression Loss 0.6330, Avg Classification Loss: 1.2471\n",
            "2023-03-07 04:00:39 - Epoch: 182, Step: 30/38, Avg Loss: 1.6321, Avg Regression Loss 0.4268, Avg Classification Loss: 1.2053\n",
            "2023-03-07 04:00:46 - Epoch: 182, Training Loss: 1.5803, Training Regression Loss 0.4632, Training Classification Loss: 1.1171\n",
            "2023-03-07 04:00:47 - Epoch: 182, Validation Loss: 1.2573, Validation Regression Loss 0.2948, Validation Classification Loss: 0.9625\n",
            "2023-03-07 04:00:47 - Saved model models/model0110/mb1-ssd-Epoch-182-Loss-1.2572963237762451.pth\n",
            "2023-03-07 04:01:01 - Epoch: 183, Step: 10/38, Avg Loss: 1.6059, Avg Regression Loss 0.3606, Avg Classification Loss: 1.2452\n",
            "2023-03-07 04:01:11 - Epoch: 183, Step: 20/38, Avg Loss: 1.4165, Avg Regression Loss 0.3899, Avg Classification Loss: 1.0266\n",
            "2023-03-07 04:01:21 - Epoch: 183, Step: 30/38, Avg Loss: 1.5869, Avg Regression Loss 0.4121, Avg Classification Loss: 1.1747\n",
            "2023-03-07 04:01:29 - Epoch: 183, Training Loss: 1.4322, Training Regression Loss 0.3516, Training Classification Loss: 1.0806\n",
            "2023-03-07 04:01:30 - Epoch: 183, Validation Loss: 1.0486, Validation Regression Loss 0.2503, Validation Classification Loss: 0.7983\n",
            "2023-03-07 04:01:30 - Saved model models/model0110/mb1-ssd-Epoch-183-Loss-1.0486160218715668.pth\n",
            "2023-03-07 04:01:44 - Epoch: 184, Step: 10/38, Avg Loss: 1.5402, Avg Regression Loss 0.4413, Avg Classification Loss: 1.0990\n",
            "2023-03-07 04:01:54 - Epoch: 184, Step: 20/38, Avg Loss: 1.6876, Avg Regression Loss 0.3772, Avg Classification Loss: 1.3104\n",
            "2023-03-07 04:02:04 - Epoch: 184, Step: 30/38, Avg Loss: 1.4373, Avg Regression Loss 0.3476, Avg Classification Loss: 1.0897\n",
            "2023-03-07 04:02:11 - Epoch: 184, Training Loss: 1.5276, Training Regression Loss 0.3767, Training Classification Loss: 1.1509\n",
            "2023-03-07 04:02:13 - Epoch: 184, Validation Loss: 1.2857, Validation Regression Loss 0.3795, Validation Classification Loss: 0.9062\n",
            "2023-03-07 04:02:13 - Saved model models/model0110/mb1-ssd-Epoch-184-Loss-1.2856926620006561.pth\n",
            "2023-03-07 04:02:26 - Epoch: 185, Step: 10/38, Avg Loss: 1.5896, Avg Regression Loss 0.4619, Avg Classification Loss: 1.1276\n",
            "2023-03-07 04:02:37 - Epoch: 185, Step: 20/38, Avg Loss: 1.8342, Avg Regression Loss 0.3743, Avg Classification Loss: 1.4599\n",
            "2023-03-07 04:02:47 - Epoch: 185, Step: 30/38, Avg Loss: 1.5140, Avg Regression Loss 0.4099, Avg Classification Loss: 1.1040\n",
            "2023-03-07 04:02:53 - Epoch: 185, Training Loss: 1.5497, Training Regression Loss 0.4043, Training Classification Loss: 1.1454\n",
            "2023-03-07 04:02:54 - Epoch: 185, Validation Loss: 1.0519, Validation Regression Loss 0.2698, Validation Classification Loss: 0.7821\n",
            "2023-03-07 04:02:55 - Saved model models/model0110/mb1-ssd-Epoch-185-Loss-1.0518978834152222.pth\n",
            "2023-03-07 04:03:10 - Epoch: 186, Step: 10/38, Avg Loss: 1.9130, Avg Regression Loss 0.4107, Avg Classification Loss: 1.5024\n",
            "2023-03-07 04:03:20 - Epoch: 186, Step: 20/38, Avg Loss: 1.4935, Avg Regression Loss 0.3067, Avg Classification Loss: 1.1868\n",
            "2023-03-07 04:03:31 - Epoch: 186, Step: 30/38, Avg Loss: 1.4638, Avg Regression Loss 0.4386, Avg Classification Loss: 1.0252\n",
            "2023-03-07 04:03:37 - Epoch: 186, Training Loss: 1.6190, Training Regression Loss 0.3899, Training Classification Loss: 1.2291\n",
            "2023-03-07 04:03:39 - Epoch: 186, Validation Loss: 1.4946, Validation Regression Loss 0.3820, Validation Classification Loss: 1.1127\n",
            "2023-03-07 04:03:39 - Saved model models/model0110/mb1-ssd-Epoch-186-Loss-1.494607299566269.pth\n",
            "2023-03-07 04:03:52 - Epoch: 187, Step: 10/38, Avg Loss: 1.6608, Avg Regression Loss 0.4425, Avg Classification Loss: 1.2182\n",
            "2023-03-07 04:04:02 - Epoch: 187, Step: 20/38, Avg Loss: 1.1972, Avg Regression Loss 0.3436, Avg Classification Loss: 0.8537\n",
            "2023-03-07 04:04:13 - Epoch: 187, Step: 30/38, Avg Loss: 1.7579, Avg Regression Loss 0.4564, Avg Classification Loss: 1.3015\n",
            "2023-03-07 04:04:20 - Epoch: 187, Training Loss: 1.5263, Training Regression Loss 0.4252, Training Classification Loss: 1.1011\n",
            "2023-03-07 04:04:21 - Epoch: 187, Validation Loss: 1.3808, Validation Regression Loss 0.3664, Validation Classification Loss: 1.0145\n",
            "2023-03-07 04:04:21 - Saved model models/model0110/mb1-ssd-Epoch-187-Loss-1.38083416223526.pth\n",
            "2023-03-07 04:04:35 - Epoch: 188, Step: 10/38, Avg Loss: 1.9948, Avg Regression Loss 0.5728, Avg Classification Loss: 1.4220\n",
            "2023-03-07 04:04:45 - Epoch: 188, Step: 20/38, Avg Loss: 1.6406, Avg Regression Loss 0.3587, Avg Classification Loss: 1.2819\n",
            "2023-03-07 04:04:54 - Epoch: 188, Step: 30/38, Avg Loss: 1.1202, Avg Regression Loss 0.3238, Avg Classification Loss: 0.7964\n",
            "2023-03-07 04:05:02 - Epoch: 188, Training Loss: 1.5168, Training Regression Loss 0.4106, Training Classification Loss: 1.1061\n",
            "2023-03-07 04:05:03 - Epoch: 188, Validation Loss: 1.1854, Validation Regression Loss 0.2652, Validation Classification Loss: 0.9202\n",
            "2023-03-07 04:05:03 - Saved model models/model0110/mb1-ssd-Epoch-188-Loss-1.1853747516870499.pth\n",
            "2023-03-07 04:05:16 - Epoch: 189, Step: 10/38, Avg Loss: 1.7539, Avg Regression Loss 0.4456, Avg Classification Loss: 1.3083\n",
            "2023-03-07 04:05:27 - Epoch: 189, Step: 20/38, Avg Loss: 1.4684, Avg Regression Loss 0.3412, Avg Classification Loss: 1.1272\n",
            "2023-03-07 04:05:36 - Epoch: 189, Step: 30/38, Avg Loss: 1.3308, Avg Regression Loss 0.3194, Avg Classification Loss: 1.0114\n",
            "2023-03-07 04:05:44 - Epoch: 189, Training Loss: 1.4157, Training Regression Loss 0.3397, Training Classification Loss: 1.0761\n",
            "2023-03-07 04:05:45 - Epoch: 189, Validation Loss: 1.2590, Validation Regression Loss 0.3149, Validation Classification Loss: 0.9441\n",
            "2023-03-07 04:05:45 - Saved model models/model0110/mb1-ssd-Epoch-189-Loss-1.258984386920929.pth\n",
            "2023-03-07 04:06:03 - Epoch: 190, Step: 10/38, Avg Loss: 1.3686, Avg Regression Loss 0.3267, Avg Classification Loss: 1.0419\n",
            "2023-03-07 04:06:14 - Epoch: 190, Step: 20/38, Avg Loss: 1.6879, Avg Regression Loss 0.4674, Avg Classification Loss: 1.2205\n",
            "2023-03-07 04:06:26 - Epoch: 190, Step: 30/38, Avg Loss: 1.2551, Avg Regression Loss 0.3862, Avg Classification Loss: 0.8689\n",
            "2023-03-07 04:06:33 - Epoch: 190, Training Loss: 1.3664, Training Regression Loss 0.3659, Training Classification Loss: 1.0005\n",
            "2023-03-07 04:06:34 - Epoch: 190, Validation Loss: 1.0810, Validation Regression Loss 0.2313, Validation Classification Loss: 0.8497\n",
            "2023-03-07 04:06:34 - Saved model models/model0110/mb1-ssd-Epoch-190-Loss-1.0810321420431137.pth\n",
            "2023-03-07 04:06:48 - Epoch: 191, Step: 10/38, Avg Loss: 1.1811, Avg Regression Loss 0.2988, Avg Classification Loss: 0.8823\n",
            "2023-03-07 04:06:59 - Epoch: 191, Step: 20/38, Avg Loss: 1.4398, Avg Regression Loss 0.3614, Avg Classification Loss: 1.0784\n",
            "2023-03-07 04:07:08 - Epoch: 191, Step: 30/38, Avg Loss: 1.2978, Avg Regression Loss 0.2988, Avg Classification Loss: 0.9989\n",
            "2023-03-07 04:07:15 - Epoch: 191, Training Loss: 1.4209, Training Regression Loss 0.3373, Training Classification Loss: 1.0836\n",
            "2023-03-07 04:07:17 - Epoch: 191, Validation Loss: 1.2027, Validation Regression Loss 0.2723, Validation Classification Loss: 0.9304\n",
            "2023-03-07 04:07:17 - Saved model models/model0110/mb1-ssd-Epoch-191-Loss-1.2027158439159393.pth\n",
            "2023-03-07 04:07:30 - Epoch: 192, Step: 10/38, Avg Loss: 1.8469, Avg Regression Loss 0.3807, Avg Classification Loss: 1.4662\n",
            "2023-03-07 04:07:41 - Epoch: 192, Step: 20/38, Avg Loss: 1.5179, Avg Regression Loss 0.2849, Avg Classification Loss: 1.2330\n",
            "2023-03-07 04:07:51 - Epoch: 192, Step: 30/38, Avg Loss: 1.2371, Avg Regression Loss 0.3369, Avg Classification Loss: 0.9002\n",
            "2023-03-07 04:07:57 - Epoch: 192, Training Loss: 1.4673, Training Regression Loss 0.3309, Training Classification Loss: 1.1364\n",
            "2023-03-07 04:07:59 - Epoch: 192, Validation Loss: 1.1001, Validation Regression Loss 0.2406, Validation Classification Loss: 0.8595\n",
            "2023-03-07 04:07:59 - Saved model models/model0110/mb1-ssd-Epoch-192-Loss-1.1001256555318832.pth\n",
            "2023-03-07 04:08:12 - Epoch: 193, Step: 10/38, Avg Loss: 1.6812, Avg Regression Loss 0.3574, Avg Classification Loss: 1.3238\n",
            "2023-03-07 04:08:23 - Epoch: 193, Step: 20/38, Avg Loss: 1.4500, Avg Regression Loss 0.3262, Avg Classification Loss: 1.1239\n",
            "2023-03-07 04:08:33 - Epoch: 193, Step: 30/38, Avg Loss: 1.5844, Avg Regression Loss 0.3950, Avg Classification Loss: 1.1894\n",
            "2023-03-07 04:08:40 - Epoch: 193, Training Loss: 1.4971, Training Regression Loss 0.3641, Training Classification Loss: 1.1330\n",
            "2023-03-07 04:08:41 - Epoch: 193, Validation Loss: 1.2094, Validation Regression Loss 0.3562, Validation Classification Loss: 0.8532\n",
            "2023-03-07 04:08:42 - Saved model models/model0110/mb1-ssd-Epoch-193-Loss-1.2093814015388489.pth\n",
            "2023-03-07 04:08:55 - Epoch: 194, Step: 10/38, Avg Loss: 1.7279, Avg Regression Loss 0.5725, Avg Classification Loss: 1.1553\n",
            "2023-03-07 04:09:05 - Epoch: 194, Step: 20/38, Avg Loss: 1.2740, Avg Regression Loss 0.3316, Avg Classification Loss: 0.9425\n",
            "2023-03-07 04:09:16 - Epoch: 194, Step: 30/38, Avg Loss: 1.8555, Avg Regression Loss 0.5308, Avg Classification Loss: 1.3247\n",
            "2023-03-07 04:09:23 - Epoch: 194, Training Loss: 1.5135, Training Regression Loss 0.4478, Training Classification Loss: 1.0656\n",
            "2023-03-07 04:09:24 - Epoch: 194, Validation Loss: 1.5947, Validation Regression Loss 0.4514, Validation Classification Loss: 1.1433\n",
            "2023-03-07 04:09:24 - Saved model models/model0110/mb1-ssd-Epoch-194-Loss-1.5946605205535889.pth\n",
            "2023-03-07 04:09:37 - Epoch: 195, Step: 10/38, Avg Loss: 2.0850, Avg Regression Loss 0.6539, Avg Classification Loss: 1.4312\n",
            "2023-03-07 04:09:49 - Epoch: 195, Step: 20/38, Avg Loss: 1.3061, Avg Regression Loss 0.3849, Avg Classification Loss: 0.9212\n",
            "2023-03-07 04:09:58 - Epoch: 195, Step: 30/38, Avg Loss: 1.4336, Avg Regression Loss 0.3694, Avg Classification Loss: 1.0642\n",
            "2023-03-07 04:10:06 - Epoch: 195, Training Loss: 1.4957, Training Regression Loss 0.4215, Training Classification Loss: 1.0742\n",
            "2023-03-07 04:10:07 - Epoch: 195, Validation Loss: 0.9789, Validation Regression Loss 0.2316, Validation Classification Loss: 0.7473\n",
            "2023-03-07 04:10:07 - Saved model models/model0110/mb1-ssd-Epoch-195-Loss-0.9788515567779541.pth\n",
            "2023-03-07 04:10:20 - Epoch: 196, Step: 10/38, Avg Loss: 1.4584, Avg Regression Loss 0.4155, Avg Classification Loss: 1.0429\n",
            "2023-03-07 04:10:31 - Epoch: 196, Step: 20/38, Avg Loss: 1.1416, Avg Regression Loss 0.2742, Avg Classification Loss: 0.8674\n",
            "2023-03-07 04:10:41 - Epoch: 196, Step: 30/38, Avg Loss: 1.5405, Avg Regression Loss 0.3613, Avg Classification Loss: 1.1793\n",
            "2023-03-07 04:10:47 - Epoch: 196, Training Loss: 1.3545, Training Regression Loss 0.3319, Training Classification Loss: 1.0226\n",
            "2023-03-07 04:10:49 - Epoch: 196, Validation Loss: 1.0798, Validation Regression Loss 0.2464, Validation Classification Loss: 0.8335\n",
            "2023-03-07 04:10:49 - Saved model models/model0110/mb1-ssd-Epoch-196-Loss-1.0798354744911194.pth\n",
            "2023-03-07 04:11:02 - Epoch: 197, Step: 10/38, Avg Loss: 1.6724, Avg Regression Loss 0.4804, Avg Classification Loss: 1.1920\n",
            "2023-03-07 04:11:13 - Epoch: 197, Step: 20/38, Avg Loss: 1.3097, Avg Regression Loss 0.3044, Avg Classification Loss: 1.0054\n",
            "2023-03-07 04:11:23 - Epoch: 197, Step: 30/38, Avg Loss: 1.9613, Avg Regression Loss 0.4320, Avg Classification Loss: 1.5293\n",
            "2023-03-07 04:11:29 - Epoch: 197, Training Loss: 1.6046, Training Regression Loss 0.3931, Training Classification Loss: 1.2114\n",
            "2023-03-07 04:11:31 - Epoch: 197, Validation Loss: 1.1079, Validation Regression Loss 0.2541, Validation Classification Loss: 0.8537\n",
            "2023-03-07 04:11:31 - Saved model models/model0110/mb1-ssd-Epoch-197-Loss-1.107876181602478.pth\n",
            "2023-03-07 04:11:44 - Epoch: 198, Step: 10/38, Avg Loss: 1.3975, Avg Regression Loss 0.3755, Avg Classification Loss: 1.0221\n",
            "2023-03-07 04:11:55 - Epoch: 198, Step: 20/38, Avg Loss: 1.4077, Avg Regression Loss 0.3852, Avg Classification Loss: 1.0225\n",
            "2023-03-07 04:12:06 - Epoch: 198, Step: 30/38, Avg Loss: 1.2560, Avg Regression Loss 0.3486, Avg Classification Loss: 0.9074\n",
            "2023-03-07 04:12:12 - Epoch: 198, Training Loss: 1.3612, Training Regression Loss 0.3645, Training Classification Loss: 0.9967\n",
            "2023-03-07 04:12:14 - Epoch: 198, Validation Loss: 1.1560, Validation Regression Loss 0.2295, Validation Classification Loss: 0.9265\n",
            "2023-03-07 04:12:14 - Saved model models/model0110/mb1-ssd-Epoch-198-Loss-1.1559635996818542.pth\n",
            "2023-03-07 04:12:27 - Epoch: 199, Step: 10/38, Avg Loss: 1.6754, Avg Regression Loss 0.3054, Avg Classification Loss: 1.3700\n",
            "2023-03-07 04:12:37 - Epoch: 199, Step: 20/38, Avg Loss: 1.3436, Avg Regression Loss 0.3417, Avg Classification Loss: 1.0019\n",
            "2023-03-07 04:12:47 - Epoch: 199, Step: 30/38, Avg Loss: 1.6161, Avg Regression Loss 0.5524, Avg Classification Loss: 1.0638\n",
            "2023-03-07 04:12:55 - Epoch: 199, Training Loss: 1.5639, Training Regression Loss 0.4007, Training Classification Loss: 1.1632\n",
            "2023-03-07 04:12:56 - Epoch: 199, Validation Loss: 1.0834, Validation Regression Loss 0.2824, Validation Classification Loss: 0.8010\n",
            "2023-03-07 04:12:56 - Saved model models/model0110/mb1-ssd-Epoch-199-Loss-1.0833896696567535.pth\n",
            "2023-03-07 04:13:10 - Epoch: 200, Step: 10/38, Avg Loss: 1.5113, Avg Regression Loss 0.3461, Avg Classification Loss: 1.1652\n",
            "2023-03-07 04:13:21 - Epoch: 200, Step: 20/38, Avg Loss: 1.4080, Avg Regression Loss 0.2656, Avg Classification Loss: 1.1424\n",
            "2023-03-07 04:13:30 - Epoch: 200, Step: 30/38, Avg Loss: 1.4626, Avg Regression Loss 0.3854, Avg Classification Loss: 1.0772\n",
            "2023-03-07 04:13:37 - Epoch: 200, Training Loss: 1.3983, Training Regression Loss 0.3286, Training Classification Loss: 1.0696\n",
            "2023-03-07 04:13:39 - Epoch: 200, Validation Loss: 1.1348, Validation Regression Loss 0.2603, Validation Classification Loss: 0.8745\n",
            "2023-03-07 04:13:39 - Saved model models/model0110/mb1-ssd-Epoch-200-Loss-1.1347723007202148.pth\n",
            "2023-03-07 04:13:52 - Epoch: 201, Step: 10/38, Avg Loss: 1.5739, Avg Regression Loss 0.3830, Avg Classification Loss: 1.1908\n",
            "2023-03-07 04:14:03 - Epoch: 201, Step: 20/38, Avg Loss: 1.6913, Avg Regression Loss 0.4207, Avg Classification Loss: 1.2706\n",
            "2023-03-07 04:14:13 - Epoch: 201, Step: 30/38, Avg Loss: 1.1738, Avg Regression Loss 0.2921, Avg Classification Loss: 0.8817\n",
            "2023-03-07 04:14:19 - Epoch: 201, Training Loss: 1.3570, Training Regression Loss 0.3409, Training Classification Loss: 1.0160\n",
            "2023-03-07 04:14:21 - Epoch: 201, Validation Loss: 1.0453, Validation Regression Loss 0.2674, Validation Classification Loss: 0.7779\n",
            "2023-03-07 04:14:21 - Saved model models/model0110/mb1-ssd-Epoch-201-Loss-1.0452550947666168.pth\n",
            "2023-03-07 04:14:34 - Epoch: 202, Step: 10/38, Avg Loss: 2.0752, Avg Regression Loss 0.5336, Avg Classification Loss: 1.5416\n",
            "2023-03-07 04:14:45 - Epoch: 202, Step: 20/38, Avg Loss: 1.3335, Avg Regression Loss 0.2582, Avg Classification Loss: 1.0752\n",
            "2023-03-07 04:14:55 - Epoch: 202, Step: 30/38, Avg Loss: 1.1983, Avg Regression Loss 0.2791, Avg Classification Loss: 0.9192\n",
            "2023-03-07 04:15:02 - Epoch: 202, Training Loss: 1.5001, Training Regression Loss 0.3382, Training Classification Loss: 1.1619\n",
            "2023-03-07 04:15:04 - Epoch: 202, Validation Loss: 1.0581, Validation Regression Loss 0.2709, Validation Classification Loss: 0.7872\n",
            "2023-03-07 04:15:04 - Saved model models/model0110/mb1-ssd-Epoch-202-Loss-1.0581018775701523.pth\n",
            "2023-03-07 04:15:17 - Epoch: 203, Step: 10/38, Avg Loss: 1.6547, Avg Regression Loss 0.4044, Avg Classification Loss: 1.2503\n",
            "2023-03-07 04:15:27 - Epoch: 203, Step: 20/38, Avg Loss: 1.4630, Avg Regression Loss 0.3174, Avg Classification Loss: 1.1456\n",
            "2023-03-07 04:15:37 - Epoch: 203, Step: 30/38, Avg Loss: 1.0321, Avg Regression Loss 0.2540, Avg Classification Loss: 0.7781\n",
            "2023-03-07 04:15:44 - Epoch: 203, Training Loss: 1.2727, Training Regression Loss 0.3195, Training Classification Loss: 0.9533\n",
            "2023-03-07 04:15:46 - Epoch: 203, Validation Loss: 1.2780, Validation Regression Loss 0.3186, Validation Classification Loss: 0.9594\n",
            "2023-03-07 04:15:46 - Saved model models/model0110/mb1-ssd-Epoch-203-Loss-1.2780354619026184.pth\n",
            "2023-03-07 04:15:59 - Epoch: 204, Step: 10/38, Avg Loss: 1.4415, Avg Regression Loss 0.4467, Avg Classification Loss: 0.9948\n",
            "2023-03-07 04:16:12 - Epoch: 204, Step: 20/38, Avg Loss: 1.2442, Avg Regression Loss 0.3300, Avg Classification Loss: 0.9142\n",
            "2023-03-07 04:16:23 - Epoch: 204, Step: 30/38, Avg Loss: 1.2087, Avg Regression Loss 0.3227, Avg Classification Loss: 0.8859\n",
            "2023-03-07 04:16:30 - Epoch: 204, Training Loss: 1.2724, Training Regression Loss 0.3499, Training Classification Loss: 0.9225\n",
            "2023-03-07 04:16:31 - Epoch: 204, Validation Loss: 1.0326, Validation Regression Loss 0.2297, Validation Classification Loss: 0.8029\n",
            "2023-03-07 04:16:31 - Saved model models/model0110/mb1-ssd-Epoch-204-Loss-1.032604068517685.pth\n",
            "2023-03-07 04:16:46 - Epoch: 205, Step: 10/38, Avg Loss: 1.4625, Avg Regression Loss 0.3802, Avg Classification Loss: 1.0823\n",
            "2023-03-07 04:16:57 - Epoch: 205, Step: 20/38, Avg Loss: 1.3805, Avg Regression Loss 0.3067, Avg Classification Loss: 1.0738\n",
            "2023-03-07 04:17:07 - Epoch: 205, Step: 30/38, Avg Loss: 1.1219, Avg Regression Loss 0.2997, Avg Classification Loss: 0.8222\n",
            "2023-03-07 04:17:14 - Epoch: 205, Training Loss: 1.2735, Training Regression Loss 0.3183, Training Classification Loss: 0.9552\n",
            "2023-03-07 04:17:16 - Epoch: 205, Validation Loss: 1.0835, Validation Regression Loss 0.2212, Validation Classification Loss: 0.8623\n",
            "2023-03-07 04:17:16 - Saved model models/model0110/mb1-ssd-Epoch-205-Loss-1.083531677722931.pth\n",
            "2023-03-07 04:17:29 - Epoch: 206, Step: 10/38, Avg Loss: 1.2366, Avg Regression Loss 0.2665, Avg Classification Loss: 0.9701\n",
            "2023-03-07 04:17:39 - Epoch: 206, Step: 20/38, Avg Loss: 1.1366, Avg Regression Loss 0.3222, Avg Classification Loss: 0.8144\n",
            "2023-03-07 04:17:50 - Epoch: 206, Step: 30/38, Avg Loss: 1.8483, Avg Regression Loss 0.3419, Avg Classification Loss: 1.5064\n",
            "2023-03-07 04:17:57 - Epoch: 206, Training Loss: 1.3142, Training Regression Loss 0.2916, Training Classification Loss: 1.0227\n",
            "2023-03-07 04:17:58 - Epoch: 206, Validation Loss: 1.2567, Validation Regression Loss 0.3383, Validation Classification Loss: 0.9184\n",
            "2023-03-07 04:17:58 - Saved model models/model0110/mb1-ssd-Epoch-206-Loss-1.2567355334758759.pth\n",
            "2023-03-07 04:18:11 - Epoch: 207, Step: 10/38, Avg Loss: 1.5314, Avg Regression Loss 0.4063, Avg Classification Loss: 1.1250\n",
            "2023-03-07 04:18:22 - Epoch: 207, Step: 20/38, Avg Loss: 1.5588, Avg Regression Loss 0.3816, Avg Classification Loss: 1.1773\n",
            "2023-03-07 04:18:31 - Epoch: 207, Step: 30/38, Avg Loss: 1.4470, Avg Regression Loss 0.3941, Avg Classification Loss: 1.0528\n",
            "2023-03-07 04:18:38 - Epoch: 207, Training Loss: 1.3957, Training Regression Loss 0.3674, Training Classification Loss: 1.0283\n",
            "2023-03-07 04:18:40 - Epoch: 207, Validation Loss: 1.1265, Validation Regression Loss 0.2832, Validation Classification Loss: 0.8433\n",
            "2023-03-07 04:18:40 - Saved model models/model0110/mb1-ssd-Epoch-207-Loss-1.1265156865119934.pth\n",
            "2023-03-07 04:18:52 - Epoch: 208, Step: 10/38, Avg Loss: 1.5715, Avg Regression Loss 0.3830, Avg Classification Loss: 1.1885\n",
            "2023-03-07 04:19:03 - Epoch: 208, Step: 20/38, Avg Loss: 1.4494, Avg Regression Loss 0.3819, Avg Classification Loss: 1.0675\n",
            "2023-03-07 04:19:13 - Epoch: 208, Step: 30/38, Avg Loss: 1.4922, Avg Regression Loss 0.4430, Avg Classification Loss: 1.0491\n",
            "2023-03-07 04:19:20 - Epoch: 208, Training Loss: 1.4560, Training Regression Loss 0.3828, Training Classification Loss: 1.0733\n",
            "2023-03-07 04:19:21 - Epoch: 208, Validation Loss: 1.1021, Validation Regression Loss 0.2129, Validation Classification Loss: 0.8892\n",
            "2023-03-07 04:19:22 - Saved model models/model0110/mb1-ssd-Epoch-208-Loss-1.1020947098731995.pth\n",
            "2023-03-07 04:19:35 - Epoch: 209, Step: 10/38, Avg Loss: 1.2392, Avg Regression Loss 0.2943, Avg Classification Loss: 0.9449\n",
            "2023-03-07 04:19:46 - Epoch: 209, Step: 20/38, Avg Loss: 1.5000, Avg Regression Loss 0.3381, Avg Classification Loss: 1.1619\n",
            "2023-03-07 04:19:57 - Epoch: 209, Step: 30/38, Avg Loss: 1.4986, Avg Regression Loss 0.3799, Avg Classification Loss: 1.1186\n",
            "2023-03-07 04:20:03 - Epoch: 209, Training Loss: 1.4228, Training Regression Loss 0.3396, Training Classification Loss: 1.0832\n",
            "2023-03-07 04:20:05 - Epoch: 209, Validation Loss: 1.2064, Validation Regression Loss 0.3050, Validation Classification Loss: 0.9014\n",
            "2023-03-07 04:20:05 - Saved model models/model0110/mb1-ssd-Epoch-209-Loss-1.2064327895641327.pth\n",
            "2023-03-07 04:20:18 - Epoch: 210, Step: 10/38, Avg Loss: 1.6080, Avg Regression Loss 0.3806, Avg Classification Loss: 1.2275\n",
            "2023-03-07 04:20:28 - Epoch: 210, Step: 20/38, Avg Loss: 1.4295, Avg Regression Loss 0.2849, Avg Classification Loss: 1.1446\n",
            "2023-03-07 04:20:39 - Epoch: 210, Step: 30/38, Avg Loss: 1.1844, Avg Regression Loss 0.3126, Avg Classification Loss: 0.8717\n",
            "2023-03-07 04:20:45 - Epoch: 210, Training Loss: 1.3380, Training Regression Loss 0.3086, Training Classification Loss: 1.0294\n",
            "2023-03-07 04:20:47 - Epoch: 210, Validation Loss: 0.8956, Validation Regression Loss 0.2141, Validation Classification Loss: 0.6815\n",
            "2023-03-07 04:20:47 - Saved model models/model0110/mb1-ssd-Epoch-210-Loss-0.8955942094326019.pth\n",
            "2023-03-07 04:21:00 - Epoch: 211, Step: 10/38, Avg Loss: 1.1607, Avg Regression Loss 0.2673, Avg Classification Loss: 0.8934\n",
            "2023-03-07 04:21:09 - Epoch: 211, Step: 20/38, Avg Loss: 1.7482, Avg Regression Loss 0.5352, Avg Classification Loss: 1.2130\n",
            "2023-03-07 04:21:20 - Epoch: 211, Step: 30/38, Avg Loss: 1.3584, Avg Regression Loss 0.3950, Avg Classification Loss: 0.9635\n",
            "2023-03-07 04:21:27 - Epoch: 211, Training Loss: 1.3073, Training Regression Loss 0.3642, Training Classification Loss: 0.9431\n",
            "2023-03-07 04:21:28 - Epoch: 211, Validation Loss: 1.0910, Validation Regression Loss 0.2671, Validation Classification Loss: 0.8240\n",
            "2023-03-07 04:21:28 - Saved model models/model0110/mb1-ssd-Epoch-211-Loss-1.09103561937809.pth\n",
            "2023-03-07 04:21:42 - Epoch: 212, Step: 10/38, Avg Loss: 2.1935, Avg Regression Loss 0.4237, Avg Classification Loss: 1.7698\n",
            "2023-03-07 04:21:52 - Epoch: 212, Step: 20/38, Avg Loss: 1.8493, Avg Regression Loss 0.5925, Avg Classification Loss: 1.2568\n",
            "2023-03-07 04:22:02 - Epoch: 212, Step: 30/38, Avg Loss: 1.2988, Avg Regression Loss 0.3677, Avg Classification Loss: 0.9311\n",
            "2023-03-07 04:22:09 - Epoch: 212, Training Loss: 1.6896, Training Regression Loss 0.4516, Training Classification Loss: 1.2380\n",
            "2023-03-07 04:22:10 - Epoch: 212, Validation Loss: 1.0433, Validation Regression Loss 0.2634, Validation Classification Loss: 0.7799\n",
            "2023-03-07 04:22:10 - Saved model models/model0110/mb1-ssd-Epoch-212-Loss-1.043299376964569.pth\n",
            "2023-03-07 04:22:23 - Epoch: 213, Step: 10/38, Avg Loss: 1.7541, Avg Regression Loss 0.4897, Avg Classification Loss: 1.2645\n",
            "2023-03-07 04:22:34 - Epoch: 213, Step: 20/38, Avg Loss: 1.8468, Avg Regression Loss 0.4757, Avg Classification Loss: 1.3711\n",
            "2023-03-07 04:22:44 - Epoch: 213, Step: 30/38, Avg Loss: 1.5417, Avg Regression Loss 0.3191, Avg Classification Loss: 1.2226\n",
            "2023-03-07 04:22:51 - Epoch: 213, Training Loss: 1.6032, Training Regression Loss 0.4036, Training Classification Loss: 1.1996\n",
            "2023-03-07 04:22:52 - Epoch: 213, Validation Loss: 0.9943, Validation Regression Loss 0.2401, Validation Classification Loss: 0.7542\n",
            "2023-03-07 04:22:52 - Saved model models/model0110/mb1-ssd-Epoch-213-Loss-0.9943250268697739.pth\n",
            "2023-03-07 04:23:05 - Epoch: 214, Step: 10/38, Avg Loss: 1.7294, Avg Regression Loss 0.3356, Avg Classification Loss: 1.3938\n",
            "2023-03-07 04:23:16 - Epoch: 214, Step: 20/38, Avg Loss: 1.7274, Avg Regression Loss 0.4533, Avg Classification Loss: 1.2742\n",
            "2023-03-07 04:23:28 - Epoch: 214, Step: 30/38, Avg Loss: 1.4775, Avg Regression Loss 0.3499, Avg Classification Loss: 1.1277\n",
            "2023-03-07 04:23:34 - Epoch: 214, Training Loss: 1.5780, Training Regression Loss 0.3631, Training Classification Loss: 1.2149\n",
            "2023-03-07 04:23:36 - Epoch: 214, Validation Loss: 1.0511, Validation Regression Loss 0.2406, Validation Classification Loss: 0.8105\n",
            "2023-03-07 04:23:36 - Saved model models/model0110/mb1-ssd-Epoch-214-Loss-1.0510753393173218.pth\n",
            "2023-03-07 04:23:49 - Epoch: 215, Step: 10/38, Avg Loss: 1.7590, Avg Regression Loss 0.3869, Avg Classification Loss: 1.3721\n",
            "2023-03-07 04:23:59 - Epoch: 215, Step: 20/38, Avg Loss: 2.1730, Avg Regression Loss 0.3875, Avg Classification Loss: 1.7854\n",
            "2023-03-07 04:24:09 - Epoch: 215, Step: 30/38, Avg Loss: 1.2703, Avg Regression Loss 0.3037, Avg Classification Loss: 0.9666\n",
            "2023-03-07 04:24:16 - Epoch: 215, Training Loss: 1.6198, Training Regression Loss 0.3283, Training Classification Loss: 1.2914\n",
            "2023-03-07 04:24:18 - Epoch: 215, Validation Loss: 0.9371, Validation Regression Loss 0.1975, Validation Classification Loss: 0.7396\n",
            "2023-03-07 04:24:18 - Saved model models/model0110/mb1-ssd-Epoch-215-Loss-0.9370971471071243.pth\n",
            "2023-03-07 04:24:31 - Epoch: 216, Step: 10/38, Avg Loss: 1.8603, Avg Regression Loss 0.4027, Avg Classification Loss: 1.4576\n",
            "2023-03-07 04:24:42 - Epoch: 216, Step: 20/38, Avg Loss: 2.1115, Avg Regression Loss 0.4706, Avg Classification Loss: 1.6408\n",
            "2023-03-07 04:24:51 - Epoch: 216, Step: 30/38, Avg Loss: 1.3933, Avg Regression Loss 0.3246, Avg Classification Loss: 1.0687\n",
            "2023-03-07 04:24:59 - Epoch: 216, Training Loss: 1.6125, Training Regression Loss 0.3672, Training Classification Loss: 1.2453\n",
            "2023-03-07 04:25:00 - Epoch: 216, Validation Loss: 1.0004, Validation Regression Loss 0.2415, Validation Classification Loss: 0.7588\n",
            "2023-03-07 04:25:00 - Saved model models/model0110/mb1-ssd-Epoch-216-Loss-1.0003585815429688.pth\n",
            "2023-03-07 04:25:13 - Epoch: 217, Step: 10/38, Avg Loss: 1.1792, Avg Regression Loss 0.2646, Avg Classification Loss: 0.9146\n",
            "2023-03-07 04:25:24 - Epoch: 217, Step: 20/38, Avg Loss: 1.1673, Avg Regression Loss 0.2509, Avg Classification Loss: 0.9163\n",
            "2023-03-07 04:25:34 - Epoch: 217, Step: 30/38, Avg Loss: 1.6078, Avg Regression Loss 0.4376, Avg Classification Loss: 1.1702\n",
            "2023-03-07 04:25:41 - Epoch: 217, Training Loss: 1.3235, Training Regression Loss 0.3179, Training Classification Loss: 1.0056\n",
            "2023-03-07 04:25:42 - Epoch: 217, Validation Loss: 1.0530, Validation Regression Loss 0.2540, Validation Classification Loss: 0.7991\n",
            "2023-03-07 04:25:42 - Saved model models/model0110/mb1-ssd-Epoch-217-Loss-1.0530260503292084.pth\n",
            "2023-03-07 04:25:56 - Epoch: 218, Step: 10/38, Avg Loss: 1.4873, Avg Regression Loss 0.3390, Avg Classification Loss: 1.1483\n",
            "2023-03-07 04:26:08 - Epoch: 218, Step: 20/38, Avg Loss: 2.1308, Avg Regression Loss 0.4357, Avg Classification Loss: 1.6951\n",
            "2023-03-07 04:26:20 - Epoch: 218, Step: 30/38, Avg Loss: 1.3586, Avg Regression Loss 0.3074, Avg Classification Loss: 1.0512\n",
            "2023-03-07 04:26:29 - Epoch: 218, Training Loss: 1.5229, Training Regression Loss 0.3247, Training Classification Loss: 1.1983\n",
            "2023-03-07 04:26:30 - Epoch: 218, Validation Loss: 1.0118, Validation Regression Loss 0.2328, Validation Classification Loss: 0.7790\n",
            "2023-03-07 04:26:30 - Saved model models/model0110/mb1-ssd-Epoch-218-Loss-1.0117993503808975.pth\n",
            "2023-03-07 04:26:45 - Epoch: 219, Step: 10/38, Avg Loss: 1.7549, Avg Regression Loss 0.4276, Avg Classification Loss: 1.3273\n",
            "2023-03-07 04:26:55 - Epoch: 219, Step: 20/38, Avg Loss: 1.3247, Avg Regression Loss 0.2596, Avg Classification Loss: 1.0651\n",
            "2023-03-07 04:27:05 - Epoch: 219, Step: 30/38, Avg Loss: 1.1799, Avg Regression Loss 0.3064, Avg Classification Loss: 0.8734\n",
            "2023-03-07 04:27:13 - Epoch: 219, Training Loss: 1.3900, Training Regression Loss 0.3233, Training Classification Loss: 1.0667\n",
            "2023-03-07 04:27:14 - Epoch: 219, Validation Loss: 1.2974, Validation Regression Loss 0.3308, Validation Classification Loss: 0.9666\n",
            "2023-03-07 04:27:14 - Saved model models/model0110/mb1-ssd-Epoch-219-Loss-1.2973535507917404.pth\n",
            "2023-03-07 04:27:27 - Epoch: 220, Step: 10/38, Avg Loss: 1.6301, Avg Regression Loss 0.3537, Avg Classification Loss: 1.2764\n",
            "2023-03-07 04:27:38 - Epoch: 220, Step: 20/38, Avg Loss: 1.7106, Avg Regression Loss 0.5220, Avg Classification Loss: 1.1885\n",
            "2023-03-07 04:27:48 - Epoch: 220, Step: 30/38, Avg Loss: 1.1475, Avg Regression Loss 0.2849, Avg Classification Loss: 0.8627\n",
            "2023-03-07 04:27:55 - Epoch: 220, Training Loss: 1.4363, Training Regression Loss 0.3643, Training Classification Loss: 1.0720\n",
            "2023-03-07 04:27:56 - Epoch: 220, Validation Loss: 1.1758, Validation Regression Loss 0.3084, Validation Classification Loss: 0.8674\n",
            "2023-03-07 04:27:56 - Saved model models/model0110/mb1-ssd-Epoch-220-Loss-1.1757768392562866.pth\n",
            "2023-03-07 04:28:09 - Epoch: 221, Step: 10/38, Avg Loss: 1.8044, Avg Regression Loss 0.3541, Avg Classification Loss: 1.4503\n",
            "2023-03-07 04:28:20 - Epoch: 221, Step: 20/38, Avg Loss: 1.5759, Avg Regression Loss 0.3686, Avg Classification Loss: 1.2073\n",
            "2023-03-07 04:28:30 - Epoch: 221, Step: 30/38, Avg Loss: 1.6520, Avg Regression Loss 0.3581, Avg Classification Loss: 1.2938\n",
            "2023-03-07 04:28:36 - Epoch: 221, Training Loss: 1.5041, Training Regression Loss 0.3309, Training Classification Loss: 1.1732\n",
            "2023-03-07 04:28:38 - Epoch: 221, Validation Loss: 1.1800, Validation Regression Loss 0.3158, Validation Classification Loss: 0.8642\n",
            "2023-03-07 04:28:38 - Saved model models/model0110/mb1-ssd-Epoch-221-Loss-1.180033102631569.pth\n",
            "2023-03-07 04:28:51 - Epoch: 222, Step: 10/38, Avg Loss: 1.6857, Avg Regression Loss 0.4247, Avg Classification Loss: 1.2611\n",
            "2023-03-07 04:29:01 - Epoch: 222, Step: 20/38, Avg Loss: 1.4444, Avg Regression Loss 0.3231, Avg Classification Loss: 1.1212\n",
            "2023-03-07 04:29:12 - Epoch: 222, Step: 30/38, Avg Loss: 1.4882, Avg Regression Loss 0.4291, Avg Classification Loss: 1.0591\n",
            "2023-03-07 04:29:18 - Epoch: 222, Training Loss: 1.5590, Training Regression Loss 0.4164, Training Classification Loss: 1.1426\n",
            "2023-03-07 04:29:20 - Epoch: 222, Validation Loss: 1.3419, Validation Regression Loss 0.2730, Validation Classification Loss: 1.0689\n",
            "2023-03-07 04:29:20 - Saved model models/model0110/mb1-ssd-Epoch-222-Loss-1.341916561126709.pth\n",
            "2023-03-07 04:29:32 - Epoch: 223, Step: 10/38, Avg Loss: 1.3546, Avg Regression Loss 0.3261, Avg Classification Loss: 1.0285\n",
            "2023-03-07 04:29:42 - Epoch: 223, Step: 20/38, Avg Loss: 1.2059, Avg Regression Loss 0.3398, Avg Classification Loss: 0.8661\n",
            "2023-03-07 04:29:53 - Epoch: 223, Step: 30/38, Avg Loss: 1.2153, Avg Regression Loss 0.3448, Avg Classification Loss: 0.8706\n",
            "2023-03-07 04:30:00 - Epoch: 223, Training Loss: 1.2560, Training Regression Loss 0.3248, Training Classification Loss: 0.9312\n",
            "2023-03-07 04:30:02 - Epoch: 223, Validation Loss: 1.0239, Validation Regression Loss 0.2442, Validation Classification Loss: 0.7797\n",
            "2023-03-07 04:30:02 - Saved model models/model0110/mb1-ssd-Epoch-223-Loss-1.0238938331604004.pth\n",
            "2023-03-07 04:30:16 - Epoch: 224, Step: 10/38, Avg Loss: 1.4558, Avg Regression Loss 0.2923, Avg Classification Loss: 1.1635\n",
            "2023-03-07 04:30:27 - Epoch: 224, Step: 20/38, Avg Loss: 1.8170, Avg Regression Loss 0.3696, Avg Classification Loss: 1.4475\n",
            "2023-03-07 04:30:36 - Epoch: 224, Step: 30/38, Avg Loss: 1.0127, Avg Regression Loss 0.2443, Avg Classification Loss: 0.7684\n",
            "2023-03-07 04:30:43 - Epoch: 224, Training Loss: 1.3645, Training Regression Loss 0.2929, Training Classification Loss: 1.0715\n",
            "2023-03-07 04:30:45 - Epoch: 224, Validation Loss: 1.2720, Validation Regression Loss 0.3359, Validation Classification Loss: 0.9361\n",
            "2023-03-07 04:30:45 - Saved model models/model0110/mb1-ssd-Epoch-224-Loss-1.2719655483961105.pth\n",
            "2023-03-07 04:30:58 - Epoch: 225, Step: 10/38, Avg Loss: 1.4733, Avg Regression Loss 0.4201, Avg Classification Loss: 1.0532\n",
            "2023-03-07 04:31:09 - Epoch: 225, Step: 20/38, Avg Loss: 1.5607, Avg Regression Loss 0.3451, Avg Classification Loss: 1.2156\n",
            "2023-03-07 04:31:20 - Epoch: 225, Step: 30/38, Avg Loss: 1.4266, Avg Regression Loss 0.3218, Avg Classification Loss: 1.1048\n",
            "2023-03-07 04:31:26 - Epoch: 225, Training Loss: 1.4629, Training Regression Loss 0.3533, Training Classification Loss: 1.1096\n",
            "2023-03-07 04:31:27 - Epoch: 225, Validation Loss: 1.2282, Validation Regression Loss 0.2761, Validation Classification Loss: 0.9520\n",
            "2023-03-07 04:31:27 - Saved model models/model0110/mb1-ssd-Epoch-225-Loss-1.22819122672081.pth\n",
            "2023-03-07 04:31:40 - Epoch: 226, Step: 10/38, Avg Loss: 1.4061, Avg Regression Loss 0.3731, Avg Classification Loss: 1.0330\n",
            "2023-03-07 04:31:51 - Epoch: 226, Step: 20/38, Avg Loss: 2.1235, Avg Regression Loss 0.5636, Avg Classification Loss: 1.5599\n",
            "2023-03-07 04:32:02 - Epoch: 226, Step: 30/38, Avg Loss: 1.8108, Avg Regression Loss 0.3169, Avg Classification Loss: 1.4939\n",
            "2023-03-07 04:32:08 - Epoch: 226, Training Loss: 1.7288, Training Regression Loss 0.4126, Training Classification Loss: 1.3162\n",
            "2023-03-07 04:32:10 - Epoch: 226, Validation Loss: 1.1674, Validation Regression Loss 0.2224, Validation Classification Loss: 0.9449\n",
            "2023-03-07 04:32:10 - Saved model models/model0110/mb1-ssd-Epoch-226-Loss-1.1673516184091568.pth\n",
            "2023-03-07 04:32:23 - Epoch: 227, Step: 10/38, Avg Loss: 2.4957, Avg Regression Loss 0.6047, Avg Classification Loss: 1.8910\n",
            "2023-03-07 04:32:34 - Epoch: 227, Step: 20/38, Avg Loss: 1.7522, Avg Regression Loss 0.4407, Avg Classification Loss: 1.3115\n",
            "2023-03-07 04:32:44 - Epoch: 227, Step: 30/38, Avg Loss: 1.4244, Avg Regression Loss 0.3630, Avg Classification Loss: 1.0614\n",
            "2023-03-07 04:32:51 - Epoch: 227, Training Loss: 1.7398, Training Regression Loss 0.4262, Training Classification Loss: 1.3137\n",
            "2023-03-07 04:32:53 - Epoch: 227, Validation Loss: 1.2994, Validation Regression Loss 0.2515, Validation Classification Loss: 1.0479\n",
            "2023-03-07 04:32:53 - Saved model models/model0110/mb1-ssd-Epoch-227-Loss-1.2994037568569183.pth\n",
            "2023-03-07 04:33:06 - Epoch: 228, Step: 10/38, Avg Loss: 1.4941, Avg Regression Loss 0.3691, Avg Classification Loss: 1.1251\n",
            "2023-03-07 04:33:16 - Epoch: 228, Step: 20/38, Avg Loss: 1.4362, Avg Regression Loss 0.4146, Avg Classification Loss: 1.0216\n",
            "2023-03-07 04:33:26 - Epoch: 228, Step: 30/38, Avg Loss: 1.3290, Avg Regression Loss 0.3188, Avg Classification Loss: 1.0102\n",
            "2023-03-07 04:33:34 - Epoch: 228, Training Loss: 1.4453, Training Regression Loss 0.3893, Training Classification Loss: 1.0560\n",
            "2023-03-07 04:33:36 - Epoch: 228, Validation Loss: 1.0783, Validation Regression Loss 0.2648, Validation Classification Loss: 0.8134\n",
            "2023-03-07 04:33:36 - Saved model models/model0110/mb1-ssd-Epoch-228-Loss-1.0782631933689117.pth\n",
            "2023-03-07 04:33:49 - Epoch: 229, Step: 10/38, Avg Loss: 1.4571, Avg Regression Loss 0.2991, Avg Classification Loss: 1.1580\n",
            "2023-03-07 04:33:59 - Epoch: 229, Step: 20/38, Avg Loss: 1.1519, Avg Regression Loss 0.2901, Avg Classification Loss: 0.8618\n",
            "2023-03-07 04:34:08 - Epoch: 229, Step: 30/38, Avg Loss: 1.1163, Avg Regression Loss 0.3041, Avg Classification Loss: 0.8123\n",
            "2023-03-07 04:34:16 - Epoch: 229, Training Loss: 1.2329, Training Regression Loss 0.3133, Training Classification Loss: 0.9197\n",
            "2023-03-07 04:34:17 - Epoch: 229, Validation Loss: 1.2225, Validation Regression Loss 0.3068, Validation Classification Loss: 0.9157\n",
            "2023-03-07 04:34:17 - Saved model models/model0110/mb1-ssd-Epoch-229-Loss-1.2224945425987244.pth\n",
            "2023-03-07 04:34:31 - Epoch: 230, Step: 10/38, Avg Loss: 1.2720, Avg Regression Loss 0.3279, Avg Classification Loss: 0.9442\n",
            "2023-03-07 04:34:42 - Epoch: 230, Step: 20/38, Avg Loss: 1.6927, Avg Regression Loss 0.3005, Avg Classification Loss: 1.3922\n",
            "2023-03-07 04:34:52 - Epoch: 230, Step: 30/38, Avg Loss: 1.5098, Avg Regression Loss 0.3781, Avg Classification Loss: 1.1317\n",
            "2023-03-07 04:34:58 - Epoch: 230, Training Loss: 1.3965, Training Regression Loss 0.3195, Training Classification Loss: 1.0770\n",
            "2023-03-07 04:34:59 - Epoch: 230, Validation Loss: 1.1468, Validation Regression Loss 0.2608, Validation Classification Loss: 0.8861\n",
            "2023-03-07 04:34:59 - Saved model models/model0110/mb1-ssd-Epoch-230-Loss-1.1468489170074463.pth\n",
            "2023-03-07 04:35:12 - Epoch: 231, Step: 10/38, Avg Loss: 1.4982, Avg Regression Loss 0.3538, Avg Classification Loss: 1.1445\n",
            "2023-03-07 04:35:23 - Epoch: 231, Step: 20/38, Avg Loss: 1.6470, Avg Regression Loss 0.3920, Avg Classification Loss: 1.2550\n",
            "2023-03-07 04:35:34 - Epoch: 231, Step: 30/38, Avg Loss: 1.5142, Avg Regression Loss 0.3138, Avg Classification Loss: 1.2004\n",
            "2023-03-07 04:35:40 - Epoch: 231, Training Loss: 1.4278, Training Regression Loss 0.3282, Training Classification Loss: 1.0995\n",
            "2023-03-07 04:35:42 - Epoch: 231, Validation Loss: 1.0457, Validation Regression Loss 0.2022, Validation Classification Loss: 0.8435\n",
            "2023-03-07 04:35:42 - Saved model models/model0110/mb1-ssd-Epoch-231-Loss-1.0456833839416504.pth\n",
            "2023-03-07 04:35:55 - Epoch: 232, Step: 10/38, Avg Loss: 1.3825, Avg Regression Loss 0.3195, Avg Classification Loss: 1.0630\n",
            "2023-03-07 04:36:05 - Epoch: 232, Step: 20/38, Avg Loss: 1.4711, Avg Regression Loss 0.3860, Avg Classification Loss: 1.0851\n",
            "2023-03-07 04:36:15 - Epoch: 232, Step: 30/38, Avg Loss: 1.1180, Avg Regression Loss 0.2561, Avg Classification Loss: 0.8619\n",
            "2023-03-07 04:36:23 - Epoch: 232, Training Loss: 1.2586, Training Regression Loss 0.3033, Training Classification Loss: 0.9553\n",
            "2023-03-07 04:36:24 - Epoch: 232, Validation Loss: 1.1571, Validation Regression Loss 0.2735, Validation Classification Loss: 0.8836\n",
            "2023-03-07 04:36:24 - Saved model models/model0110/mb1-ssd-Epoch-232-Loss-1.1571221947669983.pth\n",
            "2023-03-07 04:36:42 - Epoch: 233, Step: 10/38, Avg Loss: 1.7024, Avg Regression Loss 0.3218, Avg Classification Loss: 1.3806\n",
            "2023-03-07 04:36:54 - Epoch: 233, Step: 20/38, Avg Loss: 1.2492, Avg Regression Loss 0.2729, Avg Classification Loss: 0.9764\n",
            "2023-03-07 04:37:05 - Epoch: 233, Step: 30/38, Avg Loss: 1.4375, Avg Regression Loss 0.3075, Avg Classification Loss: 1.1300\n",
            "2023-03-07 04:37:11 - Epoch: 233, Training Loss: 1.3972, Training Regression Loss 0.2935, Training Classification Loss: 1.1037\n",
            "2023-03-07 04:37:12 - Epoch: 233, Validation Loss: 1.0643, Validation Regression Loss 0.2185, Validation Classification Loss: 0.8458\n",
            "2023-03-07 04:37:12 - Saved model models/model0110/mb1-ssd-Epoch-233-Loss-1.0642929375171661.pth\n",
            "2023-03-07 04:37:26 - Epoch: 234, Step: 10/38, Avg Loss: 1.9578, Avg Regression Loss 0.5419, Avg Classification Loss: 1.4159\n",
            "2023-03-07 04:37:37 - Epoch: 234, Step: 20/38, Avg Loss: 1.1630, Avg Regression Loss 0.2473, Avg Classification Loss: 0.9157\n",
            "2023-03-07 04:37:47 - Epoch: 234, Step: 30/38, Avg Loss: 1.2382, Avg Regression Loss 0.2461, Avg Classification Loss: 0.9921\n",
            "2023-03-07 04:37:53 - Epoch: 234, Training Loss: 1.3330, Training Regression Loss 0.3009, Training Classification Loss: 1.0322\n",
            "2023-03-07 04:37:56 - Epoch: 234, Validation Loss: 1.0602, Validation Regression Loss 0.1838, Validation Classification Loss: 0.8764\n",
            "2023-03-07 04:37:56 - Saved model models/model0110/mb1-ssd-Epoch-234-Loss-1.0601544231176376.pth\n",
            "2023-03-07 04:38:09 - Epoch: 235, Step: 10/38, Avg Loss: 1.1664, Avg Regression Loss 0.2521, Avg Classification Loss: 0.9143\n",
            "2023-03-07 04:38:19 - Epoch: 235, Step: 20/38, Avg Loss: 1.5935, Avg Regression Loss 0.3817, Avg Classification Loss: 1.2118\n",
            "2023-03-07 04:38:29 - Epoch: 235, Step: 30/38, Avg Loss: 1.1444, Avg Regression Loss 0.2607, Avg Classification Loss: 0.8837\n",
            "2023-03-07 04:38:37 - Epoch: 235, Training Loss: 1.2957, Training Regression Loss 0.3011, Training Classification Loss: 0.9946\n",
            "2023-03-07 04:38:38 - Epoch: 235, Validation Loss: 1.0487, Validation Regression Loss 0.2441, Validation Classification Loss: 0.8047\n",
            "2023-03-07 04:38:38 - Saved model models/model0110/mb1-ssd-Epoch-235-Loss-1.0487332046031952.pth\n",
            "2023-03-07 04:38:52 - Epoch: 236, Step: 10/38, Avg Loss: 1.4214, Avg Regression Loss 0.3382, Avg Classification Loss: 1.0832\n",
            "2023-03-07 04:39:02 - Epoch: 236, Step: 20/38, Avg Loss: 1.0925, Avg Regression Loss 0.2497, Avg Classification Loss: 0.8428\n",
            "2023-03-07 04:39:11 - Epoch: 236, Step: 30/38, Avg Loss: 1.4232, Avg Regression Loss 0.2791, Avg Classification Loss: 1.1441\n",
            "2023-03-07 04:39:19 - Epoch: 236, Training Loss: 1.2439, Training Regression Loss 0.2946, Training Classification Loss: 0.9494\n",
            "2023-03-07 04:39:20 - Epoch: 236, Validation Loss: 0.9591, Validation Regression Loss 0.1999, Validation Classification Loss: 0.7592\n",
            "2023-03-07 04:39:20 - Saved model models/model0110/mb1-ssd-Epoch-236-Loss-0.9590581208467484.pth\n",
            "2023-03-07 04:39:33 - Epoch: 237, Step: 10/38, Avg Loss: 1.2721, Avg Regression Loss 0.2929, Avg Classification Loss: 0.9792\n",
            "2023-03-07 04:39:44 - Epoch: 237, Step: 20/38, Avg Loss: 1.2269, Avg Regression Loss 0.2458, Avg Classification Loss: 0.9811\n",
            "2023-03-07 04:39:54 - Epoch: 237, Step: 30/38, Avg Loss: 1.3703, Avg Regression Loss 0.3234, Avg Classification Loss: 1.0469\n",
            "2023-03-07 04:40:01 - Epoch: 237, Training Loss: 1.2513, Training Regression Loss 0.2789, Training Classification Loss: 0.9724\n",
            "2023-03-07 04:40:02 - Epoch: 237, Validation Loss: 1.1611, Validation Regression Loss 0.2171, Validation Classification Loss: 0.9441\n",
            "2023-03-07 04:40:02 - Saved model models/model0110/mb1-ssd-Epoch-237-Loss-1.1611414104700089.pth\n",
            "2023-03-07 04:40:15 - Epoch: 238, Step: 10/38, Avg Loss: 1.2776, Avg Regression Loss 0.2604, Avg Classification Loss: 1.0172\n",
            "2023-03-07 04:40:28 - Epoch: 238, Step: 20/38, Avg Loss: 1.6131, Avg Regression Loss 0.3273, Avg Classification Loss: 1.2858\n",
            "2023-03-07 04:40:39 - Epoch: 238, Step: 30/38, Avg Loss: 1.5223, Avg Regression Loss 0.2607, Avg Classification Loss: 1.2616\n",
            "2023-03-07 04:40:45 - Epoch: 238, Training Loss: 1.3876, Training Regression Loss 0.2721, Training Classification Loss: 1.1155\n",
            "2023-03-07 04:40:47 - Epoch: 238, Validation Loss: 0.9204, Validation Regression Loss 0.1838, Validation Classification Loss: 0.7366\n",
            "2023-03-07 04:40:47 - Saved model models/model0110/mb1-ssd-Epoch-238-Loss-0.9203938245773315.pth\n",
            "2023-03-07 04:41:00 - Epoch: 239, Step: 10/38, Avg Loss: 1.6020, Avg Regression Loss 0.4519, Avg Classification Loss: 1.1501\n",
            "2023-03-07 04:41:10 - Epoch: 239, Step: 20/38, Avg Loss: 1.2619, Avg Regression Loss 0.2606, Avg Classification Loss: 1.0013\n",
            "2023-03-07 04:41:21 - Epoch: 239, Step: 30/38, Avg Loss: 1.4553, Avg Regression Loss 0.3787, Avg Classification Loss: 1.0766\n",
            "2023-03-07 04:41:28 - Epoch: 239, Training Loss: 1.3317, Training Regression Loss 0.3336, Training Classification Loss: 0.9981\n",
            "2023-03-07 04:41:29 - Epoch: 239, Validation Loss: 0.9787, Validation Regression Loss 0.2113, Validation Classification Loss: 0.7675\n",
            "2023-03-07 04:41:29 - Saved model models/model0110/mb1-ssd-Epoch-239-Loss-0.9787223637104034.pth\n",
            "2023-03-07 04:41:43 - Epoch: 240, Step: 10/38, Avg Loss: 1.6941, Avg Regression Loss 0.3757, Avg Classification Loss: 1.3184\n",
            "2023-03-07 04:41:53 - Epoch: 240, Step: 20/38, Avg Loss: 1.4081, Avg Regression Loss 0.2750, Avg Classification Loss: 1.1331\n",
            "2023-03-07 04:42:03 - Epoch: 240, Step: 30/38, Avg Loss: 1.2344, Avg Regression Loss 0.3445, Avg Classification Loss: 0.8899\n",
            "2023-03-07 04:42:10 - Epoch: 240, Training Loss: 1.4203, Training Regression Loss 0.3187, Training Classification Loss: 1.1016\n",
            "2023-03-07 04:42:11 - Epoch: 240, Validation Loss: 1.0591, Validation Regression Loss 0.1778, Validation Classification Loss: 0.8813\n",
            "2023-03-07 04:42:11 - Saved model models/model0110/mb1-ssd-Epoch-240-Loss-1.0590824782848358.pth\n",
            "2023-03-07 04:42:24 - Epoch: 241, Step: 10/38, Avg Loss: 1.4911, Avg Regression Loss 0.2904, Avg Classification Loss: 1.2006\n",
            "2023-03-07 04:42:35 - Epoch: 241, Step: 20/38, Avg Loss: 1.5891, Avg Regression Loss 0.3853, Avg Classification Loss: 1.2039\n",
            "2023-03-07 04:42:47 - Epoch: 241, Step: 30/38, Avg Loss: 1.2152, Avg Regression Loss 0.2753, Avg Classification Loss: 0.9400\n",
            "2023-03-07 04:42:53 - Epoch: 241, Training Loss: 1.3604, Training Regression Loss 0.3081, Training Classification Loss: 1.0524\n",
            "2023-03-07 04:42:55 - Epoch: 241, Validation Loss: 0.8052, Validation Regression Loss 0.1826, Validation Classification Loss: 0.6226\n",
            "2023-03-07 04:42:55 - Saved model models/model0110/mb1-ssd-Epoch-241-Loss-0.8051925152540207.pth\n",
            "2023-03-07 04:43:08 - Epoch: 242, Step: 10/38, Avg Loss: 1.0123, Avg Regression Loss 0.2315, Avg Classification Loss: 0.7808\n",
            "2023-03-07 04:43:19 - Epoch: 242, Step: 20/38, Avg Loss: 1.2770, Avg Regression Loss 0.3526, Avg Classification Loss: 0.9244\n",
            "2023-03-07 04:43:29 - Epoch: 242, Step: 30/38, Avg Loss: 1.4124, Avg Regression Loss 0.2648, Avg Classification Loss: 1.1476\n",
            "2023-03-07 04:43:35 - Epoch: 242, Training Loss: 1.2428, Training Regression Loss 0.3022, Training Classification Loss: 0.9406\n",
            "2023-03-07 04:43:37 - Epoch: 242, Validation Loss: 0.8398, Validation Regression Loss 0.1616, Validation Classification Loss: 0.6783\n",
            "2023-03-07 04:43:37 - Saved model models/model0110/mb1-ssd-Epoch-242-Loss-0.8398096859455109.pth\n",
            "2023-03-07 04:43:53 - Epoch: 243, Step: 10/38, Avg Loss: 1.6249, Avg Regression Loss 0.4446, Avg Classification Loss: 1.1803\n",
            "2023-03-07 04:44:02 - Epoch: 243, Step: 20/38, Avg Loss: 1.5050, Avg Regression Loss 0.4023, Avg Classification Loss: 1.1027\n",
            "2023-03-07 04:44:12 - Epoch: 243, Step: 30/38, Avg Loss: 1.3200, Avg Regression Loss 0.2202, Avg Classification Loss: 1.0998\n",
            "2023-03-07 04:44:20 - Epoch: 243, Training Loss: 1.3705, Training Regression Loss 0.3232, Training Classification Loss: 1.0472\n",
            "2023-03-07 04:44:21 - Epoch: 243, Validation Loss: 0.9237, Validation Regression Loss 0.2097, Validation Classification Loss: 0.7140\n",
            "2023-03-07 04:44:21 - Saved model models/model0110/mb1-ssd-Epoch-243-Loss-0.9236903488636017.pth\n",
            "2023-03-07 04:44:35 - Epoch: 244, Step: 10/38, Avg Loss: 1.4844, Avg Regression Loss 0.3682, Avg Classification Loss: 1.1162\n",
            "2023-03-07 04:44:45 - Epoch: 244, Step: 20/38, Avg Loss: 1.2544, Avg Regression Loss 0.2922, Avg Classification Loss: 0.9622\n",
            "2023-03-07 04:44:54 - Epoch: 244, Step: 30/38, Avg Loss: 1.5390, Avg Regression Loss 0.3768, Avg Classification Loss: 1.1621\n",
            "2023-03-07 04:45:02 - Epoch: 244, Training Loss: 1.3884, Training Regression Loss 0.3271, Training Classification Loss: 1.0613\n",
            "2023-03-07 04:45:03 - Epoch: 244, Validation Loss: 0.9361, Validation Regression Loss 0.2022, Validation Classification Loss: 0.7339\n",
            "2023-03-07 04:45:03 - Saved model models/model0110/mb1-ssd-Epoch-244-Loss-0.936149075627327.pth\n",
            "2023-03-07 04:45:16 - Epoch: 245, Step: 10/38, Avg Loss: 1.3786, Avg Regression Loss 0.2779, Avg Classification Loss: 1.1007\n",
            "2023-03-07 04:45:27 - Epoch: 245, Step: 20/38, Avg Loss: 0.9587, Avg Regression Loss 0.2079, Avg Classification Loss: 0.7508\n",
            "2023-03-07 04:45:37 - Epoch: 245, Step: 30/38, Avg Loss: 1.2672, Avg Regression Loss 0.3637, Avg Classification Loss: 0.9036\n",
            "2023-03-07 04:45:43 - Epoch: 245, Training Loss: 1.1983, Training Regression Loss 0.2699, Training Classification Loss: 0.9284\n",
            "2023-03-07 04:45:45 - Epoch: 245, Validation Loss: 0.9144, Validation Regression Loss 0.1790, Validation Classification Loss: 0.7354\n",
            "2023-03-07 04:45:45 - Saved model models/model0110/mb1-ssd-Epoch-245-Loss-0.9144188910722733.pth\n",
            "2023-03-07 04:45:58 - Epoch: 246, Step: 10/38, Avg Loss: 1.2987, Avg Regression Loss 0.2792, Avg Classification Loss: 1.0195\n",
            "2023-03-07 04:46:09 - Epoch: 246, Step: 20/38, Avg Loss: 0.9593, Avg Regression Loss 0.2067, Avg Classification Loss: 0.7526\n",
            "2023-03-07 04:46:19 - Epoch: 246, Step: 30/38, Avg Loss: 1.3571, Avg Regression Loss 0.2748, Avg Classification Loss: 1.0823\n",
            "2023-03-07 04:46:25 - Epoch: 246, Training Loss: 1.1105, Training Regression Loss 0.2459, Training Classification Loss: 0.8645\n",
            "2023-03-07 04:46:27 - Epoch: 246, Validation Loss: 0.8945, Validation Regression Loss 0.1457, Validation Classification Loss: 0.7488\n",
            "2023-03-07 04:46:27 - Saved model models/model0110/mb1-ssd-Epoch-246-Loss-0.8944806903600693.pth\n",
            "2023-03-07 04:46:44 - Epoch: 247, Step: 10/38, Avg Loss: 1.1405, Avg Regression Loss 0.2289, Avg Classification Loss: 0.9116\n",
            "2023-03-07 04:46:54 - Epoch: 247, Step: 20/38, Avg Loss: 1.4398, Avg Regression Loss 0.3036, Avg Classification Loss: 1.1362\n",
            "2023-03-07 04:47:04 - Epoch: 247, Step: 30/38, Avg Loss: 1.2476, Avg Regression Loss 0.3027, Avg Classification Loss: 0.9448\n",
            "2023-03-07 04:47:12 - Epoch: 247, Training Loss: 1.2559, Training Regression Loss 0.2655, Training Classification Loss: 0.9905\n",
            "2023-03-07 04:47:14 - Epoch: 247, Validation Loss: 0.9383, Validation Regression Loss 0.1769, Validation Classification Loss: 0.7614\n",
            "2023-03-07 04:47:14 - Saved model models/model0110/mb1-ssd-Epoch-247-Loss-0.9382868409156799.pth\n",
            "2023-03-07 04:47:27 - Epoch: 248, Step: 10/38, Avg Loss: 1.3045, Avg Regression Loss 0.3385, Avg Classification Loss: 0.9659\n",
            "2023-03-07 04:47:38 - Epoch: 248, Step: 20/38, Avg Loss: 0.9220, Avg Regression Loss 0.1863, Avg Classification Loss: 0.7358\n",
            "2023-03-07 04:47:48 - Epoch: 248, Step: 30/38, Avg Loss: 0.8475, Avg Regression Loss 0.1900, Avg Classification Loss: 0.6575\n",
            "2023-03-07 04:47:55 - Epoch: 248, Training Loss: 1.0123, Training Regression Loss 0.2418, Training Classification Loss: 0.7704\n",
            "2023-03-07 04:47:56 - Epoch: 248, Validation Loss: 1.0528, Validation Regression Loss 0.2223, Validation Classification Loss: 0.8305\n",
            "2023-03-07 04:47:56 - Saved model models/model0110/mb1-ssd-Epoch-248-Loss-1.0527767688035965.pth\n",
            "2023-03-07 04:48:09 - Epoch: 249, Step: 10/38, Avg Loss: 1.2122, Avg Regression Loss 0.2331, Avg Classification Loss: 0.9791\n",
            "2023-03-07 04:48:20 - Epoch: 249, Step: 20/38, Avg Loss: 1.4134, Avg Regression Loss 0.3137, Avg Classification Loss: 1.0997\n",
            "2023-03-07 04:48:30 - Epoch: 249, Step: 30/38, Avg Loss: 1.2172, Avg Regression Loss 0.3146, Avg Classification Loss: 0.9026\n",
            "2023-03-07 04:48:36 - Epoch: 249, Training Loss: 1.3162, Training Regression Loss 0.2949, Training Classification Loss: 1.0213\n",
            "2023-03-07 04:48:38 - Epoch: 249, Validation Loss: 0.9365, Validation Regression Loss 0.2001, Validation Classification Loss: 0.7364\n",
            "2023-03-07 04:48:38 - Saved model models/model0110/mb1-ssd-Epoch-249-Loss-0.9364961534738541.pth\n",
            "2023-03-07 04:48:51 - Epoch: 250, Step: 10/38, Avg Loss: 1.0810, Avg Regression Loss 0.2513, Avg Classification Loss: 0.8297\n",
            "2023-03-07 04:49:02 - Epoch: 250, Step: 20/38, Avg Loss: 1.1197, Avg Regression Loss 0.2296, Avg Classification Loss: 0.8901\n",
            "2023-03-07 04:49:13 - Epoch: 250, Step: 30/38, Avg Loss: 1.6862, Avg Regression Loss 0.3714, Avg Classification Loss: 1.3148\n",
            "2023-03-07 04:49:20 - Epoch: 250, Training Loss: 1.2539, Training Regression Loss 0.2793, Training Classification Loss: 0.9747\n",
            "2023-03-07 04:49:21 - Epoch: 250, Validation Loss: 1.1628, Validation Regression Loss 0.2560, Validation Classification Loss: 0.9068\n",
            "2023-03-07 04:49:21 - Saved model models/model0110/mb1-ssd-Epoch-250-Loss-1.1627921909093857.pth\n",
            "2023-03-07 04:49:34 - Epoch: 251, Step: 10/38, Avg Loss: 1.6289, Avg Regression Loss 0.3291, Avg Classification Loss: 1.2999\n",
            "2023-03-07 04:49:44 - Epoch: 251, Step: 20/38, Avg Loss: 1.0536, Avg Regression Loss 0.1799, Avg Classification Loss: 0.8736\n",
            "2023-03-07 04:49:55 - Epoch: 251, Step: 30/38, Avg Loss: 1.5329, Avg Regression Loss 0.3808, Avg Classification Loss: 1.1521\n",
            "2023-03-07 04:50:02 - Epoch: 251, Training Loss: 1.3076, Training Regression Loss 0.2771, Training Classification Loss: 1.0304\n",
            "2023-03-07 04:50:03 - Epoch: 251, Validation Loss: 1.0013, Validation Regression Loss 0.1952, Validation Classification Loss: 0.8061\n",
            "2023-03-07 04:50:04 - Saved model models/model0110/mb1-ssd-Epoch-251-Loss-1.0012847185134888.pth\n",
            "2023-03-07 04:50:17 - Epoch: 252, Step: 10/38, Avg Loss: 1.2125, Avg Regression Loss 0.1825, Avg Classification Loss: 1.0300\n",
            "2023-03-07 04:50:28 - Epoch: 252, Step: 20/38, Avg Loss: 0.9506, Avg Regression Loss 0.1767, Avg Classification Loss: 0.7739\n",
            "2023-03-07 04:50:38 - Epoch: 252, Step: 30/38, Avg Loss: 1.2550, Avg Regression Loss 0.2179, Avg Classification Loss: 1.0371\n",
            "2023-03-07 04:50:46 - Epoch: 252, Training Loss: 1.1158, Training Regression Loss 0.2038, Training Classification Loss: 0.9120\n",
            "2023-03-07 04:50:47 - Epoch: 252, Validation Loss: 0.9875, Validation Regression Loss 0.2003, Validation Classification Loss: 0.7872\n",
            "2023-03-07 04:50:47 - Saved model models/model0110/mb1-ssd-Epoch-252-Loss-0.9874734282493591.pth\n",
            "2023-03-07 04:51:00 - Epoch: 253, Step: 10/38, Avg Loss: 1.1558, Avg Regression Loss 0.2747, Avg Classification Loss: 0.8811\n",
            "2023-03-07 04:51:11 - Epoch: 253, Step: 20/38, Avg Loss: 1.0428, Avg Regression Loss 0.2524, Avg Classification Loss: 0.7904\n",
            "2023-03-07 04:51:21 - Epoch: 253, Step: 30/38, Avg Loss: 0.9344, Avg Regression Loss 0.1878, Avg Classification Loss: 0.7467\n",
            "2023-03-07 04:51:27 - Epoch: 253, Training Loss: 0.9983, Training Regression Loss 0.2210, Training Classification Loss: 0.7773\n",
            "2023-03-07 04:51:29 - Epoch: 253, Validation Loss: 1.0193, Validation Regression Loss 0.2167, Validation Classification Loss: 0.8026\n",
            "2023-03-07 04:51:29 - Saved model models/model0110/mb1-ssd-Epoch-253-Loss-1.0193183422088623.pth\n",
            "2023-03-07 04:51:42 - Epoch: 254, Step: 10/38, Avg Loss: 0.9537, Avg Regression Loss 0.2163, Avg Classification Loss: 0.7374\n",
            "2023-03-07 04:51:53 - Epoch: 254, Step: 20/38, Avg Loss: 1.6636, Avg Regression Loss 0.3335, Avg Classification Loss: 1.3301\n",
            "2023-03-07 04:52:03 - Epoch: 254, Step: 30/38, Avg Loss: 0.9621, Avg Regression Loss 0.2326, Avg Classification Loss: 0.7295\n",
            "2023-03-07 04:52:11 - Epoch: 254, Training Loss: 1.1127, Training Regression Loss 0.2409, Training Classification Loss: 0.8718\n",
            "2023-03-07 04:52:12 - Epoch: 254, Validation Loss: 0.9949, Validation Regression Loss 0.2141, Validation Classification Loss: 0.7808\n",
            "2023-03-07 04:52:12 - Saved model models/model0110/mb1-ssd-Epoch-254-Loss-0.9948689192533493.pth\n",
            "2023-03-07 04:52:25 - Epoch: 255, Step: 10/38, Avg Loss: 1.1554, Avg Regression Loss 0.2876, Avg Classification Loss: 0.8678\n",
            "2023-03-07 04:52:36 - Epoch: 255, Step: 20/38, Avg Loss: 1.0071, Avg Regression Loss 0.1902, Avg Classification Loss: 0.8169\n",
            "2023-03-07 04:52:46 - Epoch: 255, Step: 30/38, Avg Loss: 1.3069, Avg Regression Loss 0.2724, Avg Classification Loss: 1.0345\n",
            "2023-03-07 04:52:53 - Epoch: 255, Training Loss: 1.1033, Training Regression Loss 0.2409, Training Classification Loss: 0.8624\n",
            "2023-03-07 04:52:54 - Epoch: 255, Validation Loss: 1.0175, Validation Regression Loss 0.2292, Validation Classification Loss: 0.7882\n",
            "2023-03-07 04:52:54 - Saved model models/model0110/mb1-ssd-Epoch-255-Loss-1.0174644887447357.pth\n",
            "2023-03-07 04:53:08 - Epoch: 256, Step: 10/38, Avg Loss: 1.1558, Avg Regression Loss 0.2203, Avg Classification Loss: 0.9355\n",
            "2023-03-07 04:53:19 - Epoch: 256, Step: 20/38, Avg Loss: 1.3847, Avg Regression Loss 0.2225, Avg Classification Loss: 1.1622\n",
            "2023-03-07 04:53:29 - Epoch: 256, Step: 30/38, Avg Loss: 0.8218, Avg Regression Loss 0.1496, Avg Classification Loss: 0.6722\n",
            "2023-03-07 04:53:35 - Epoch: 256, Training Loss: 1.0708, Training Regression Loss 0.1922, Training Classification Loss: 0.8785\n",
            "2023-03-07 04:53:37 - Epoch: 256, Validation Loss: 1.0114, Validation Regression Loss 0.2082, Validation Classification Loss: 0.8033\n",
            "2023-03-07 04:53:37 - Saved model models/model0110/mb1-ssd-Epoch-256-Loss-1.011437103152275.pth\n",
            "2023-03-07 04:53:50 - Epoch: 257, Step: 10/38, Avg Loss: 1.4360, Avg Regression Loss 0.2841, Avg Classification Loss: 1.1519\n",
            "2023-03-07 04:54:01 - Epoch: 257, Step: 20/38, Avg Loss: 1.3612, Avg Regression Loss 0.3739, Avg Classification Loss: 0.9873\n",
            "2023-03-07 04:54:12 - Epoch: 257, Step: 30/38, Avg Loss: 0.9801, Avg Regression Loss 0.1940, Avg Classification Loss: 0.7861\n",
            "2023-03-07 04:54:19 - Epoch: 257, Training Loss: 1.2635, Training Regression Loss 0.2717, Training Classification Loss: 0.9918\n",
            "2023-03-07 04:54:21 - Epoch: 257, Validation Loss: 1.0042, Validation Regression Loss 0.2056, Validation Classification Loss: 0.7986\n",
            "2023-03-07 04:54:21 - Saved model models/model0110/mb1-ssd-Epoch-257-Loss-1.0042046755552292.pth\n",
            "2023-03-07 04:54:34 - Epoch: 258, Step: 10/38, Avg Loss: 1.3816, Avg Regression Loss 0.2747, Avg Classification Loss: 1.1069\n",
            "2023-03-07 04:54:43 - Epoch: 258, Step: 20/38, Avg Loss: 1.1648, Avg Regression Loss 0.2036, Avg Classification Loss: 0.9611\n",
            "2023-03-07 04:54:53 - Epoch: 258, Step: 30/38, Avg Loss: 1.0821, Avg Regression Loss 0.1813, Avg Classification Loss: 0.9008\n",
            "2023-03-07 04:55:01 - Epoch: 258, Training Loss: 1.1541, Training Regression Loss 0.2210, Training Classification Loss: 0.9331\n",
            "2023-03-07 04:55:02 - Epoch: 258, Validation Loss: 0.9195, Validation Regression Loss 0.1812, Validation Classification Loss: 0.7382\n",
            "2023-03-07 04:55:02 - Saved model models/model0110/mb1-ssd-Epoch-258-Loss-0.9194511920213699.pth\n",
            "2023-03-07 04:55:16 - Epoch: 259, Step: 10/38, Avg Loss: 0.9409, Avg Regression Loss 0.1745, Avg Classification Loss: 0.7664\n",
            "2023-03-07 04:55:26 - Epoch: 259, Step: 20/38, Avg Loss: 1.1316, Avg Regression Loss 0.2214, Avg Classification Loss: 0.9102\n",
            "2023-03-07 04:55:36 - Epoch: 259, Step: 30/38, Avg Loss: 1.1224, Avg Regression Loss 0.2296, Avg Classification Loss: 0.8928\n",
            "2023-03-07 04:55:43 - Epoch: 259, Training Loss: 0.9939, Training Regression Loss 0.1964, Training Classification Loss: 0.7975\n",
            "2023-03-07 04:55:44 - Epoch: 259, Validation Loss: 0.9384, Validation Regression Loss 0.1670, Validation Classification Loss: 0.7714\n",
            "2023-03-07 04:55:44 - Saved model models/model0110/mb1-ssd-Epoch-259-Loss-0.9383908212184906.pth\n",
            "2023-03-07 04:55:57 - Epoch: 260, Step: 10/38, Avg Loss: 1.1844, Avg Regression Loss 0.2705, Avg Classification Loss: 0.9140\n",
            "2023-03-07 04:56:08 - Epoch: 260, Step: 20/38, Avg Loss: 1.1177, Avg Regression Loss 0.2249, Avg Classification Loss: 0.8928\n",
            "2023-03-07 04:56:18 - Epoch: 260, Step: 30/38, Avg Loss: 1.2651, Avg Regression Loss 0.2808, Avg Classification Loss: 0.9843\n",
            "2023-03-07 04:56:24 - Epoch: 260, Training Loss: 1.1233, Training Regression Loss 0.2370, Training Classification Loss: 0.8863\n",
            "2023-03-07 04:56:26 - Epoch: 260, Validation Loss: 0.9237, Validation Regression Loss 0.1790, Validation Classification Loss: 0.7447\n",
            "2023-03-07 04:56:26 - Saved model models/model0110/mb1-ssd-Epoch-260-Loss-0.9237072318792343.pth\n",
            "2023-03-07 04:56:39 - Epoch: 261, Step: 10/38, Avg Loss: 1.0509, Avg Regression Loss 0.2023, Avg Classification Loss: 0.8486\n",
            "2023-03-07 04:56:51 - Epoch: 261, Step: 20/38, Avg Loss: 1.3057, Avg Regression Loss 0.2653, Avg Classification Loss: 1.0405\n",
            "2023-03-07 04:57:04 - Epoch: 261, Step: 30/38, Avg Loss: 1.0301, Avg Regression Loss 0.2366, Avg Classification Loss: 0.7935\n",
            "2023-03-07 04:57:11 - Epoch: 261, Training Loss: 1.1455, Training Regression Loss 0.2374, Training Classification Loss: 0.9082\n",
            "2023-03-07 04:57:12 - Epoch: 261, Validation Loss: 0.9222, Validation Regression Loss 0.1910, Validation Classification Loss: 0.7313\n",
            "2023-03-07 04:57:13 - Saved model models/model0110/mb1-ssd-Epoch-261-Loss-0.9222134202718735.pth\n",
            "2023-03-07 04:57:26 - Epoch: 262, Step: 10/38, Avg Loss: 1.4096, Avg Regression Loss 0.3030, Avg Classification Loss: 1.1065\n",
            "2023-03-07 04:57:36 - Epoch: 262, Step: 20/38, Avg Loss: 0.9248, Avg Regression Loss 0.2118, Avg Classification Loss: 0.7129\n",
            "2023-03-07 04:57:48 - Epoch: 262, Step: 30/38, Avg Loss: 1.2231, Avg Regression Loss 0.2339, Avg Classification Loss: 0.9892\n",
            "2023-03-07 04:57:55 - Epoch: 262, Training Loss: 1.0813, Training Regression Loss 0.2165, Training Classification Loss: 0.8647\n",
            "2023-03-07 04:57:56 - Epoch: 262, Validation Loss: 0.9752, Validation Regression Loss 0.1952, Validation Classification Loss: 0.7800\n",
            "2023-03-07 04:57:56 - Saved model models/model0110/mb1-ssd-Epoch-262-Loss-0.9751723259687424.pth\n",
            "2023-03-07 04:58:10 - Epoch: 263, Step: 10/38, Avg Loss: 1.6284, Avg Regression Loss 0.5169, Avg Classification Loss: 1.1115\n",
            "2023-03-07 04:58:21 - Epoch: 263, Step: 20/38, Avg Loss: 1.0290, Avg Regression Loss 0.2253, Avg Classification Loss: 0.8037\n",
            "2023-03-07 04:58:32 - Epoch: 263, Step: 30/38, Avg Loss: 1.0135, Avg Regression Loss 0.2018, Avg Classification Loss: 0.8117\n",
            "2023-03-07 04:58:38 - Epoch: 263, Training Loss: 1.1457, Training Regression Loss 0.2764, Training Classification Loss: 0.8693\n",
            "2023-03-07 04:58:39 - Epoch: 263, Validation Loss: 0.9309, Validation Regression Loss 0.1860, Validation Classification Loss: 0.7448\n",
            "2023-03-07 04:58:39 - Saved model models/model0110/mb1-ssd-Epoch-263-Loss-0.9308622926473618.pth\n",
            "2023-03-07 04:58:52 - Epoch: 264, Step: 10/38, Avg Loss: 1.3332, Avg Regression Loss 0.2643, Avg Classification Loss: 1.0689\n",
            "2023-03-07 04:59:03 - Epoch: 264, Step: 20/38, Avg Loss: 0.7514, Avg Regression Loss 0.1408, Avg Classification Loss: 0.6106\n",
            "2023-03-07 04:59:13 - Epoch: 264, Step: 30/38, Avg Loss: 1.4872, Avg Regression Loss 0.2641, Avg Classification Loss: 1.2232\n",
            "2023-03-07 04:59:20 - Epoch: 264, Training Loss: 1.0777, Training Regression Loss 0.2036, Training Classification Loss: 0.8741\n",
            "2023-03-07 04:59:22 - Epoch: 264, Validation Loss: 0.9793, Validation Regression Loss 0.1753, Validation Classification Loss: 0.8040\n",
            "2023-03-07 04:59:22 - Saved model models/model0110/mb1-ssd-Epoch-264-Loss-0.9793062210083008.pth\n",
            "2023-03-07 04:59:35 - Epoch: 265, Step: 10/38, Avg Loss: 1.1970, Avg Regression Loss 0.2021, Avg Classification Loss: 0.9949\n",
            "2023-03-07 04:59:45 - Epoch: 265, Step: 20/38, Avg Loss: 1.2260, Avg Regression Loss 0.2386, Avg Classification Loss: 0.9874\n",
            "2023-03-07 04:59:55 - Epoch: 265, Step: 30/38, Avg Loss: 1.0395, Avg Regression Loss 0.1975, Avg Classification Loss: 0.8420\n",
            "2023-03-07 05:00:02 - Epoch: 265, Training Loss: 1.1177, Training Regression Loss 0.2086, Training Classification Loss: 0.9092\n",
            "2023-03-07 05:00:04 - Epoch: 265, Validation Loss: 0.9431, Validation Regression Loss 0.1757, Validation Classification Loss: 0.7674\n",
            "2023-03-07 05:00:04 - Saved model models/model0110/mb1-ssd-Epoch-265-Loss-0.9430952221155167.pth\n",
            "2023-03-07 05:00:17 - Epoch: 266, Step: 10/38, Avg Loss: 1.2201, Avg Regression Loss 0.1846, Avg Classification Loss: 1.0355\n",
            "2023-03-07 05:00:27 - Epoch: 266, Step: 20/38, Avg Loss: 0.8013, Avg Regression Loss 0.1871, Avg Classification Loss: 0.6142\n",
            "2023-03-07 05:00:36 - Epoch: 266, Step: 30/38, Avg Loss: 1.3502, Avg Regression Loss 0.2926, Avg Classification Loss: 1.0576\n",
            "2023-03-07 05:00:44 - Epoch: 266, Training Loss: 1.0718, Training Regression Loss 0.2155, Training Classification Loss: 0.8563\n",
            "2023-03-07 05:00:45 - Epoch: 266, Validation Loss: 0.8773, Validation Regression Loss 0.1614, Validation Classification Loss: 0.7159\n",
            "2023-03-07 05:00:45 - Saved model models/model0110/mb1-ssd-Epoch-266-Loss-0.8772646188735962.pth\n",
            "2023-03-07 05:00:59 - Epoch: 267, Step: 10/38, Avg Loss: 1.1232, Avg Regression Loss 0.2795, Avg Classification Loss: 0.8437\n",
            "2023-03-07 05:01:11 - Epoch: 267, Step: 20/38, Avg Loss: 1.2698, Avg Regression Loss 0.2317, Avg Classification Loss: 1.0381\n",
            "2023-03-07 05:01:21 - Epoch: 267, Step: 30/38, Avg Loss: 1.2981, Avg Regression Loss 0.3225, Avg Classification Loss: 0.9755\n",
            "2023-03-07 05:01:27 - Epoch: 267, Training Loss: 1.1172, Training Regression Loss 0.2476, Training Classification Loss: 0.8695\n",
            "2023-03-07 05:01:28 - Epoch: 267, Validation Loss: 0.8938, Validation Regression Loss 0.1787, Validation Classification Loss: 0.7151\n",
            "2023-03-07 05:01:28 - Saved model models/model0110/mb1-ssd-Epoch-267-Loss-0.8938436359167099.pth\n",
            "2023-03-07 05:01:42 - Epoch: 268, Step: 10/38, Avg Loss: 0.9327, Avg Regression Loss 0.1606, Avg Classification Loss: 0.7721\n",
            "2023-03-07 05:01:53 - Epoch: 268, Step: 20/38, Avg Loss: 0.9811, Avg Regression Loss 0.1728, Avg Classification Loss: 0.8083\n",
            "2023-03-07 05:02:03 - Epoch: 268, Step: 30/38, Avg Loss: 1.5350, Avg Regression Loss 0.2834, Avg Classification Loss: 1.2516\n",
            "2023-03-07 05:02:10 - Epoch: 268, Training Loss: 1.1095, Training Regression Loss 0.2065, Training Classification Loss: 0.9030\n",
            "2023-03-07 05:02:12 - Epoch: 268, Validation Loss: 0.8062, Validation Regression Loss 0.1413, Validation Classification Loss: 0.6649\n",
            "2023-03-07 05:02:12 - Saved model models/model0110/mb1-ssd-Epoch-268-Loss-0.8061646968126297.pth\n",
            "2023-03-07 05:02:25 - Epoch: 269, Step: 10/38, Avg Loss: 1.1151, Avg Regression Loss 0.2560, Avg Classification Loss: 0.8591\n",
            "2023-03-07 05:02:34 - Epoch: 269, Step: 20/38, Avg Loss: 0.9902, Avg Regression Loss 0.1612, Avg Classification Loss: 0.8291\n",
            "2023-03-07 05:02:45 - Epoch: 269, Step: 30/38, Avg Loss: 0.7916, Avg Regression Loss 0.1447, Avg Classification Loss: 0.6469\n",
            "2023-03-07 05:02:52 - Epoch: 269, Training Loss: 0.9483, Training Regression Loss 0.1752, Training Classification Loss: 0.7731\n",
            "2023-03-07 05:02:53 - Epoch: 269, Validation Loss: 0.9273, Validation Regression Loss 0.1621, Validation Classification Loss: 0.7653\n",
            "2023-03-07 05:02:53 - Saved model models/model0110/mb1-ssd-Epoch-269-Loss-0.9273450076580048.pth\n",
            "2023-03-07 05:03:07 - Epoch: 270, Step: 10/38, Avg Loss: 1.1974, Avg Regression Loss 0.1938, Avg Classification Loss: 1.0036\n",
            "2023-03-07 05:03:18 - Epoch: 270, Step: 20/38, Avg Loss: 0.9880, Avg Regression Loss 0.1940, Avg Classification Loss: 0.7940\n",
            "2023-03-07 05:03:27 - Epoch: 270, Step: 30/38, Avg Loss: 0.8560, Avg Regression Loss 0.1776, Avg Classification Loss: 0.6785\n",
            "2023-03-07 05:03:34 - Epoch: 270, Training Loss: 0.9737, Training Regression Loss 0.1724, Training Classification Loss: 0.8013\n",
            "2023-03-07 05:03:35 - Epoch: 270, Validation Loss: 0.9355, Validation Regression Loss 0.1714, Validation Classification Loss: 0.7641\n",
            "2023-03-07 05:03:35 - Saved model models/model0110/mb1-ssd-Epoch-270-Loss-0.9355209916830063.pth\n",
            "2023-03-07 05:03:49 - Epoch: 271, Step: 10/38, Avg Loss: 1.0800, Avg Regression Loss 0.2195, Avg Classification Loss: 0.8605\n",
            "2023-03-07 05:03:59 - Epoch: 271, Step: 20/38, Avg Loss: 0.9266, Avg Regression Loss 0.1455, Avg Classification Loss: 0.7811\n",
            "2023-03-07 05:04:10 - Epoch: 271, Step: 30/38, Avg Loss: 0.8609, Avg Regression Loss 0.1494, Avg Classification Loss: 0.7116\n",
            "2023-03-07 05:04:16 - Epoch: 271, Training Loss: 0.9332, Training Regression Loss 0.1695, Training Classification Loss: 0.7637\n",
            "2023-03-07 05:04:17 - Epoch: 271, Validation Loss: 0.9648, Validation Regression Loss 0.1774, Validation Classification Loss: 0.7874\n",
            "2023-03-07 05:04:17 - Saved model models/model0110/mb1-ssd-Epoch-271-Loss-0.9647638946771622.pth\n",
            "2023-03-07 05:04:31 - Epoch: 272, Step: 10/38, Avg Loss: 1.1552, Avg Regression Loss 0.1828, Avg Classification Loss: 0.9723\n",
            "2023-03-07 05:04:43 - Epoch: 272, Step: 20/38, Avg Loss: 0.7417, Avg Regression Loss 0.1534, Avg Classification Loss: 0.5882\n",
            "2023-03-07 05:04:53 - Epoch: 272, Step: 30/38, Avg Loss: 1.3196, Avg Regression Loss 0.2892, Avg Classification Loss: 1.0305\n",
            "2023-03-07 05:04:59 - Epoch: 272, Training Loss: 1.0981, Training Regression Loss 0.2169, Training Classification Loss: 0.8812\n",
            "2023-03-07 05:05:01 - Epoch: 272, Validation Loss: 0.9408, Validation Regression Loss 0.1681, Validation Classification Loss: 0.7727\n",
            "2023-03-07 05:05:01 - Saved model models/model0110/mb1-ssd-Epoch-272-Loss-0.9408191740512848.pth\n",
            "2023-03-07 05:05:14 - Epoch: 273, Step: 10/38, Avg Loss: 1.8950, Avg Regression Loss 0.3982, Avg Classification Loss: 1.4968\n",
            "2023-03-07 05:05:24 - Epoch: 273, Step: 20/38, Avg Loss: 0.8338, Avg Regression Loss 0.1327, Avg Classification Loss: 0.7012\n",
            "2023-03-07 05:05:35 - Epoch: 273, Step: 30/38, Avg Loss: 0.8804, Avg Regression Loss 0.2277, Avg Classification Loss: 0.6526\n",
            "2023-03-07 05:05:41 - Epoch: 273, Training Loss: 1.1042, Training Regression Loss 0.2230, Training Classification Loss: 0.8811\n",
            "2023-03-07 05:05:43 - Epoch: 273, Validation Loss: 0.9007, Validation Regression Loss 0.1741, Validation Classification Loss: 0.7266\n",
            "2023-03-07 05:05:43 - Saved model models/model0110/mb1-ssd-Epoch-273-Loss-0.9006755948066711.pth\n",
            "2023-03-07 05:05:57 - Epoch: 274, Step: 10/38, Avg Loss: 1.4971, Avg Regression Loss 0.2420, Avg Classification Loss: 1.2551\n",
            "2023-03-07 05:06:06 - Epoch: 274, Step: 20/38, Avg Loss: 1.1067, Avg Regression Loss 0.2361, Avg Classification Loss: 0.8706\n",
            "2023-03-07 05:06:17 - Epoch: 274, Step: 30/38, Avg Loss: 0.9398, Avg Regression Loss 0.1368, Avg Classification Loss: 0.8030\n",
            "2023-03-07 05:06:24 - Epoch: 274, Training Loss: 1.1160, Training Regression Loss 0.1925, Training Classification Loss: 0.9235\n",
            "2023-03-07 05:06:26 - Epoch: 274, Validation Loss: 0.9537, Validation Regression Loss 0.1829, Validation Classification Loss: 0.7708\n",
            "2023-03-07 05:06:26 - Saved model models/model0110/mb1-ssd-Epoch-274-Loss-0.9536539912223816.pth\n",
            "2023-03-07 05:06:39 - Epoch: 275, Step: 10/38, Avg Loss: 1.2016, Avg Regression Loss 0.2279, Avg Classification Loss: 0.9737\n",
            "2023-03-07 05:06:49 - Epoch: 275, Step: 20/38, Avg Loss: 1.0761, Avg Regression Loss 0.2639, Avg Classification Loss: 0.8122\n",
            "2023-03-07 05:07:00 - Epoch: 275, Step: 30/38, Avg Loss: 0.9988, Avg Regression Loss 0.1338, Avg Classification Loss: 0.8650\n",
            "2023-03-07 05:07:09 - Epoch: 275, Training Loss: 1.0383, Training Regression Loss 0.1916, Training Classification Loss: 0.8467\n",
            "2023-03-07 05:07:11 - Epoch: 275, Validation Loss: 0.9316, Validation Regression Loss 0.1640, Validation Classification Loss: 0.7676\n",
            "2023-03-07 05:07:11 - Saved model models/model0110/mb1-ssd-Epoch-275-Loss-0.9316336661577225.pth\n",
            "2023-03-07 05:07:24 - Epoch: 276, Step: 10/38, Avg Loss: 0.9485, Avg Regression Loss 0.1883, Avg Classification Loss: 0.7602\n",
            "2023-03-07 05:07:35 - Epoch: 276, Step: 20/38, Avg Loss: 0.8989, Avg Regression Loss 0.1610, Avg Classification Loss: 0.7379\n",
            "2023-03-07 05:07:46 - Epoch: 276, Step: 30/38, Avg Loss: 1.1134, Avg Regression Loss 0.2233, Avg Classification Loss: 0.8901\n",
            "2023-03-07 05:07:52 - Epoch: 276, Training Loss: 0.9729, Training Regression Loss 0.1860, Training Classification Loss: 0.7869\n",
            "2023-03-07 05:07:54 - Epoch: 276, Validation Loss: 0.9516, Validation Regression Loss 0.1695, Validation Classification Loss: 0.7820\n",
            "2023-03-07 05:07:54 - Saved model models/model0110/mb1-ssd-Epoch-276-Loss-0.9515616744756699.pth\n",
            "2023-03-07 05:08:09 - Epoch: 277, Step: 10/38, Avg Loss: 1.0390, Avg Regression Loss 0.2178, Avg Classification Loss: 0.8212\n",
            "2023-03-07 05:08:18 - Epoch: 277, Step: 20/38, Avg Loss: 1.0343, Avg Regression Loss 0.1538, Avg Classification Loss: 0.8805\n",
            "2023-03-07 05:08:29 - Epoch: 277, Step: 30/38, Avg Loss: 1.2372, Avg Regression Loss 0.2915, Avg Classification Loss: 0.9457\n",
            "2023-03-07 05:08:36 - Epoch: 277, Training Loss: 1.0370, Training Regression Loss 0.2004, Training Classification Loss: 0.8366\n",
            "2023-03-07 05:08:37 - Epoch: 277, Validation Loss: 0.8811, Validation Regression Loss 0.1587, Validation Classification Loss: 0.7224\n",
            "2023-03-07 05:08:37 - Saved model models/model0110/mb1-ssd-Epoch-277-Loss-0.8811307847499847.pth\n",
            "2023-03-07 05:08:51 - Epoch: 278, Step: 10/38, Avg Loss: 1.2501, Avg Regression Loss 0.2733, Avg Classification Loss: 0.9767\n",
            "2023-03-07 05:09:01 - Epoch: 278, Step: 20/38, Avg Loss: 1.0473, Avg Regression Loss 0.1813, Avg Classification Loss: 0.8660\n",
            "2023-03-07 05:09:10 - Epoch: 278, Step: 30/38, Avg Loss: 0.9599, Avg Regression Loss 0.1657, Avg Classification Loss: 0.7941\n",
            "2023-03-07 05:09:17 - Epoch: 278, Training Loss: 1.0470, Training Regression Loss 0.1930, Training Classification Loss: 0.8540\n",
            "2023-03-07 05:09:19 - Epoch: 278, Validation Loss: 0.8805, Validation Regression Loss 0.1612, Validation Classification Loss: 0.7193\n",
            "2023-03-07 05:09:19 - Saved model models/model0110/mb1-ssd-Epoch-278-Loss-0.88046595454216.pth\n",
            "2023-03-07 05:09:31 - Epoch: 279, Step: 10/38, Avg Loss: 0.9475, Avg Regression Loss 0.1280, Avg Classification Loss: 0.8195\n",
            "2023-03-07 05:09:42 - Epoch: 279, Step: 20/38, Avg Loss: 1.1200, Avg Regression Loss 0.2413, Avg Classification Loss: 0.8787\n",
            "2023-03-07 05:09:52 - Epoch: 279, Step: 30/38, Avg Loss: 0.8212, Avg Regression Loss 0.1479, Avg Classification Loss: 0.6733\n",
            "2023-03-07 05:09:59 - Epoch: 279, Training Loss: 0.9213, Training Regression Loss 0.1638, Training Classification Loss: 0.7575\n",
            "2023-03-07 05:10:00 - Epoch: 279, Validation Loss: 0.8749, Validation Regression Loss 0.1547, Validation Classification Loss: 0.7201\n",
            "2023-03-07 05:10:00 - Saved model models/model0110/mb1-ssd-Epoch-279-Loss-0.8748567253351212.pth\n",
            "2023-03-07 05:10:13 - Epoch: 280, Step: 10/38, Avg Loss: 1.0130, Avg Regression Loss 0.1766, Avg Classification Loss: 0.8364\n",
            "2023-03-07 05:10:24 - Epoch: 280, Step: 20/38, Avg Loss: 0.9396, Avg Regression Loss 0.1533, Avg Classification Loss: 0.7863\n",
            "2023-03-07 05:10:34 - Epoch: 280, Step: 30/38, Avg Loss: 1.1699, Avg Regression Loss 0.2358, Avg Classification Loss: 0.9341\n",
            "2023-03-07 05:10:41 - Epoch: 280, Training Loss: 1.0233, Training Regression Loss 0.1766, Training Classification Loss: 0.8467\n",
            "2023-03-07 05:10:42 - Epoch: 280, Validation Loss: 0.8231, Validation Regression Loss 0.1424, Validation Classification Loss: 0.6807\n",
            "2023-03-07 05:10:42 - Saved model models/model0110/mb1-ssd-Epoch-280-Loss-0.8230618387460709.pth\n",
            "2023-03-07 05:10:55 - Epoch: 281, Step: 10/38, Avg Loss: 1.1935, Avg Regression Loss 0.2475, Avg Classification Loss: 0.9460\n",
            "2023-03-07 05:11:06 - Epoch: 281, Step: 20/38, Avg Loss: 0.9319, Avg Regression Loss 0.1793, Avg Classification Loss: 0.7526\n",
            "2023-03-07 05:11:18 - Epoch: 281, Step: 30/38, Avg Loss: 0.9893, Avg Regression Loss 0.1684, Avg Classification Loss: 0.8208\n",
            "2023-03-07 05:11:25 - Epoch: 281, Training Loss: 1.0733, Training Regression Loss 0.1827, Training Classification Loss: 0.8906\n",
            "2023-03-07 05:11:26 - Epoch: 281, Validation Loss: 0.8493, Validation Regression Loss 0.1462, Validation Classification Loss: 0.7031\n",
            "2023-03-07 05:11:27 - Saved model models/model0110/mb1-ssd-Epoch-281-Loss-0.8492972254753113.pth\n",
            "2023-03-07 05:11:42 - Epoch: 282, Step: 10/38, Avg Loss: 1.0217, Avg Regression Loss 0.1740, Avg Classification Loss: 0.8477\n",
            "2023-03-07 05:11:52 - Epoch: 282, Step: 20/38, Avg Loss: 0.8898, Avg Regression Loss 0.1642, Avg Classification Loss: 0.7256\n",
            "2023-03-07 05:12:01 - Epoch: 282, Step: 30/38, Avg Loss: 0.7242, Avg Regression Loss 0.0988, Avg Classification Loss: 0.6254\n",
            "2023-03-07 05:12:09 - Epoch: 282, Training Loss: 0.8812, Training Regression Loss 0.1643, Training Classification Loss: 0.7169\n",
            "2023-03-07 05:12:10 - Epoch: 282, Validation Loss: 0.9139, Validation Regression Loss 0.1763, Validation Classification Loss: 0.7376\n",
            "2023-03-07 05:12:10 - Saved model models/model0110/mb1-ssd-Epoch-282-Loss-0.9139027297496796.pth\n",
            "2023-03-07 05:12:24 - Epoch: 283, Step: 10/38, Avg Loss: 1.2691, Avg Regression Loss 0.2663, Avg Classification Loss: 1.0028\n",
            "2023-03-07 05:12:34 - Epoch: 283, Step: 20/38, Avg Loss: 1.0129, Avg Regression Loss 0.1448, Avg Classification Loss: 0.8681\n",
            "2023-03-07 05:12:45 - Epoch: 283, Step: 30/38, Avg Loss: 0.9712, Avg Regression Loss 0.1666, Avg Classification Loss: 0.8046\n",
            "2023-03-07 05:12:51 - Epoch: 283, Training Loss: 1.0137, Training Regression Loss 0.1767, Training Classification Loss: 0.8369\n",
            "2023-03-07 05:12:52 - Epoch: 283, Validation Loss: 0.8769, Validation Regression Loss 0.1633, Validation Classification Loss: 0.7135\n",
            "2023-03-07 05:12:52 - Saved model models/model0110/mb1-ssd-Epoch-283-Loss-0.8768809884786606.pth\n",
            "2023-03-07 05:13:05 - Epoch: 284, Step: 10/38, Avg Loss: 1.0812, Avg Regression Loss 0.1694, Avg Classification Loss: 0.9117\n",
            "2023-03-07 05:13:15 - Epoch: 284, Step: 20/38, Avg Loss: 0.9809, Avg Regression Loss 0.1244, Avg Classification Loss: 0.8564\n",
            "2023-03-07 05:13:26 - Epoch: 284, Step: 30/38, Avg Loss: 1.2377, Avg Regression Loss 0.2131, Avg Classification Loss: 1.0245\n",
            "2023-03-07 05:13:32 - Epoch: 284, Training Loss: 1.0278, Training Regression Loss 0.1604, Training Classification Loss: 0.8673\n",
            "2023-03-07 05:13:33 - Epoch: 284, Validation Loss: 0.8987, Validation Regression Loss 0.1679, Validation Classification Loss: 0.7308\n",
            "2023-03-07 05:13:33 - Saved model models/model0110/mb1-ssd-Epoch-284-Loss-0.8987020999193192.pth\n",
            "2023-03-07 05:13:47 - Epoch: 285, Step: 10/38, Avg Loss: 1.0717, Avg Regression Loss 0.1547, Avg Classification Loss: 0.9170\n",
            "2023-03-07 05:13:58 - Epoch: 285, Step: 20/38, Avg Loss: 1.1456, Avg Regression Loss 0.1763, Avg Classification Loss: 0.9693\n",
            "2023-03-07 05:14:08 - Epoch: 285, Step: 30/38, Avg Loss: 1.2763, Avg Regression Loss 0.2906, Avg Classification Loss: 0.9857\n",
            "2023-03-07 05:14:15 - Epoch: 285, Training Loss: 1.1006, Training Regression Loss 0.1879, Training Classification Loss: 0.9127\n",
            "2023-03-07 05:14:17 - Epoch: 285, Validation Loss: 0.9230, Validation Regression Loss 0.1763, Validation Classification Loss: 0.7468\n",
            "2023-03-07 05:14:17 - Saved model models/model0110/mb1-ssd-Epoch-285-Loss-0.9230208545923233.pth\n",
            "2023-03-07 05:14:31 - Epoch: 286, Step: 10/38, Avg Loss: 0.9153, Avg Regression Loss 0.1817, Avg Classification Loss: 0.7336\n",
            "2023-03-07 05:14:41 - Epoch: 286, Step: 20/38, Avg Loss: 0.9427, Avg Regression Loss 0.1542, Avg Classification Loss: 0.7885\n",
            "2023-03-07 05:14:50 - Epoch: 286, Step: 30/38, Avg Loss: 0.8722, Avg Regression Loss 0.1654, Avg Classification Loss: 0.7068\n",
            "2023-03-07 05:14:58 - Epoch: 286, Training Loss: 0.8590, Training Regression Loss 0.1540, Training Classification Loss: 0.7050\n",
            "2023-03-07 05:15:00 - Epoch: 286, Validation Loss: 0.9226, Validation Regression Loss 0.1715, Validation Classification Loss: 0.7511\n",
            "2023-03-07 05:15:00 - Saved model models/model0110/mb1-ssd-Epoch-286-Loss-0.9226025193929672.pth\n",
            "2023-03-07 05:15:14 - Epoch: 287, Step: 10/38, Avg Loss: 0.8731, Avg Regression Loss 0.1608, Avg Classification Loss: 0.7123\n",
            "2023-03-07 05:15:24 - Epoch: 287, Step: 20/38, Avg Loss: 0.9685, Avg Regression Loss 0.2150, Avg Classification Loss: 0.7535\n",
            "2023-03-07 05:15:35 - Epoch: 287, Step: 30/38, Avg Loss: 1.3074, Avg Regression Loss 0.2434, Avg Classification Loss: 1.0640\n",
            "2023-03-07 05:15:41 - Epoch: 287, Training Loss: 0.9915, Training Regression Loss 0.1973, Training Classification Loss: 0.7942\n",
            "2023-03-07 05:15:42 - Epoch: 287, Validation Loss: 0.8815, Validation Regression Loss 0.1711, Validation Classification Loss: 0.7105\n",
            "2023-03-07 05:15:42 - Saved model models/model0110/mb1-ssd-Epoch-287-Loss-0.8815446943044662.pth\n",
            "2023-03-07 05:15:56 - Epoch: 288, Step: 10/38, Avg Loss: 0.8591, Avg Regression Loss 0.1581, Avg Classification Loss: 0.7010\n",
            "2023-03-07 05:16:06 - Epoch: 288, Step: 20/38, Avg Loss: 0.8531, Avg Regression Loss 0.1305, Avg Classification Loss: 0.7226\n",
            "2023-03-07 05:16:17 - Epoch: 288, Step: 30/38, Avg Loss: 1.0253, Avg Regression Loss 0.1900, Avg Classification Loss: 0.8353\n",
            "2023-03-07 05:16:23 - Epoch: 288, Training Loss: 0.8837, Training Regression Loss 0.1580, Training Classification Loss: 0.7258\n",
            "2023-03-07 05:16:24 - Epoch: 288, Validation Loss: 0.8934, Validation Regression Loss 0.1624, Validation Classification Loss: 0.7310\n",
            "2023-03-07 05:16:24 - Saved model models/model0110/mb1-ssd-Epoch-288-Loss-0.8934019207954407.pth\n",
            "2023-03-07 05:16:37 - Epoch: 289, Step: 10/38, Avg Loss: 1.2232, Avg Regression Loss 0.2843, Avg Classification Loss: 0.9389\n",
            "2023-03-07 05:16:48 - Epoch: 289, Step: 20/38, Avg Loss: 0.7210, Avg Regression Loss 0.1081, Avg Classification Loss: 0.6129\n",
            "2023-03-07 05:16:59 - Epoch: 289, Step: 30/38, Avg Loss: 1.0757, Avg Regression Loss 0.1967, Avg Classification Loss: 0.8791\n",
            "2023-03-07 05:17:06 - Epoch: 289, Training Loss: 0.9318, Training Regression Loss 0.1725, Training Classification Loss: 0.7593\n",
            "2023-03-07 05:17:08 - Epoch: 289, Validation Loss: 0.9119, Validation Regression Loss 0.1680, Validation Classification Loss: 0.7439\n",
            "2023-03-07 05:17:08 - Saved model models/model0110/mb1-ssd-Epoch-289-Loss-0.911906898021698.pth\n",
            "2023-03-07 05:17:27 - Epoch: 290, Step: 10/38, Avg Loss: 0.9392, Avg Regression Loss 0.1337, Avg Classification Loss: 0.8055\n",
            "2023-03-07 05:17:37 - Epoch: 290, Step: 20/38, Avg Loss: 1.1455, Avg Regression Loss 0.1389, Avg Classification Loss: 1.0066\n",
            "2023-03-07 05:17:48 - Epoch: 290, Step: 30/38, Avg Loss: 1.7488, Avg Regression Loss 0.2925, Avg Classification Loss: 1.4563\n",
            "2023-03-07 05:17:54 - Epoch: 290, Training Loss: 1.1963, Training Regression Loss 0.1880, Training Classification Loss: 1.0084\n",
            "2023-03-07 05:17:55 - Epoch: 290, Validation Loss: 0.9193, Validation Regression Loss 0.1675, Validation Classification Loss: 0.7518\n",
            "2023-03-07 05:17:55 - Saved model models/model0110/mb1-ssd-Epoch-290-Loss-0.919284000992775.pth\n",
            "2023-03-07 05:18:09 - Epoch: 291, Step: 10/38, Avg Loss: 0.8376, Avg Regression Loss 0.1972, Avg Classification Loss: 0.6404\n",
            "2023-03-07 05:18:19 - Epoch: 291, Step: 20/38, Avg Loss: 1.2659, Avg Regression Loss 0.2433, Avg Classification Loss: 1.0226\n",
            "2023-03-07 05:18:31 - Epoch: 291, Step: 30/38, Avg Loss: 1.0051, Avg Regression Loss 0.1928, Avg Classification Loss: 0.8123\n",
            "2023-03-07 05:18:38 - Epoch: 291, Training Loss: 1.0165, Training Regression Loss 0.2028, Training Classification Loss: 0.8137\n",
            "2023-03-07 05:18:39 - Epoch: 291, Validation Loss: 0.9111, Validation Regression Loss 0.1583, Validation Classification Loss: 0.7527\n",
            "2023-03-07 05:18:40 - Saved model models/model0110/mb1-ssd-Epoch-291-Loss-0.9110854715108871.pth\n",
            "2023-03-07 05:18:53 - Epoch: 292, Step: 10/38, Avg Loss: 1.3379, Avg Regression Loss 0.2404, Avg Classification Loss: 1.0975\n",
            "2023-03-07 05:19:03 - Epoch: 292, Step: 20/38, Avg Loss: 0.8701, Avg Regression Loss 0.1577, Avg Classification Loss: 0.7124\n",
            "2023-03-07 05:19:14 - Epoch: 292, Step: 30/38, Avg Loss: 0.9102, Avg Regression Loss 0.1600, Avg Classification Loss: 0.7503\n",
            "2023-03-07 05:19:21 - Epoch: 292, Training Loss: 0.9353, Training Regression Loss 0.1660, Training Classification Loss: 0.7693\n",
            "2023-03-07 05:19:22 - Epoch: 292, Validation Loss: 0.8678, Validation Regression Loss 0.1531, Validation Classification Loss: 0.7147\n",
            "2023-03-07 05:19:22 - Saved model models/model0110/mb1-ssd-Epoch-292-Loss-0.8678090572357178.pth\n",
            "2023-03-07 05:19:36 - Epoch: 293, Step: 10/38, Avg Loss: 0.8962, Avg Regression Loss 0.1339, Avg Classification Loss: 0.7623\n",
            "2023-03-07 05:19:47 - Epoch: 293, Step: 20/38, Avg Loss: 1.3533, Avg Regression Loss 0.2050, Avg Classification Loss: 1.1483\n",
            "2023-03-07 05:19:56 - Epoch: 293, Step: 30/38, Avg Loss: 1.3619, Avg Regression Loss 0.2154, Avg Classification Loss: 1.1465\n",
            "2023-03-07 05:20:04 - Epoch: 293, Training Loss: 1.1251, Training Regression Loss 0.1758, Training Classification Loss: 0.9492\n",
            "2023-03-07 05:20:05 - Epoch: 293, Validation Loss: 0.8567, Validation Regression Loss 0.1494, Validation Classification Loss: 0.7073\n",
            "2023-03-07 05:20:05 - Saved model models/model0110/mb1-ssd-Epoch-293-Loss-0.8566500842571259.pth\n",
            "2023-03-07 05:20:18 - Epoch: 294, Step: 10/38, Avg Loss: 0.9060, Avg Regression Loss 0.1298, Avg Classification Loss: 0.7762\n",
            "2023-03-07 05:20:30 - Epoch: 294, Step: 20/38, Avg Loss: 0.9654, Avg Regression Loss 0.1553, Avg Classification Loss: 0.8101\n",
            "2023-03-07 05:20:40 - Epoch: 294, Step: 30/38, Avg Loss: 0.9508, Avg Regression Loss 0.1656, Avg Classification Loss: 0.7852\n",
            "2023-03-07 05:20:46 - Epoch: 294, Training Loss: 0.9198, Training Regression Loss 0.1585, Training Classification Loss: 0.7613\n",
            "2023-03-07 05:20:48 - Epoch: 294, Validation Loss: 0.8973, Validation Regression Loss 0.1554, Validation Classification Loss: 0.7419\n",
            "2023-03-07 05:20:48 - Saved model models/model0110/mb1-ssd-Epoch-294-Loss-0.8972753137350082.pth\n",
            "2023-03-07 05:21:00 - Epoch: 295, Step: 10/38, Avg Loss: 0.8535, Avg Regression Loss 0.1248, Avg Classification Loss: 0.7287\n",
            "2023-03-07 05:21:11 - Epoch: 295, Step: 20/38, Avg Loss: 0.9045, Avg Regression Loss 0.1547, Avg Classification Loss: 0.7498\n",
            "2023-03-07 05:21:21 - Epoch: 295, Step: 30/38, Avg Loss: 0.9248, Avg Regression Loss 0.1694, Avg Classification Loss: 0.7553\n",
            "2023-03-07 05:21:27 - Epoch: 295, Training Loss: 0.8932, Training Regression Loss 0.1514, Training Classification Loss: 0.7419\n",
            "2023-03-07 05:21:29 - Epoch: 295, Validation Loss: 0.8757, Validation Regression Loss 0.1529, Validation Classification Loss: 0.7228\n",
            "2023-03-07 05:21:29 - Saved model models/model0110/mb1-ssd-Epoch-295-Loss-0.8756557404994965.pth\n",
            "2023-03-07 05:21:42 - Epoch: 296, Step: 10/38, Avg Loss: 0.8218, Avg Regression Loss 0.1472, Avg Classification Loss: 0.6746\n",
            "2023-03-07 05:21:53 - Epoch: 296, Step: 20/38, Avg Loss: 1.3413, Avg Regression Loss 0.3013, Avg Classification Loss: 1.0400\n",
            "2023-03-07 05:22:04 - Epoch: 296, Step: 30/38, Avg Loss: 1.1593, Avg Regression Loss 0.1922, Avg Classification Loss: 0.9671\n",
            "2023-03-07 05:22:12 - Epoch: 296, Training Loss: 1.0033, Training Regression Loss 0.1873, Training Classification Loss: 0.8160\n",
            "2023-03-07 05:22:13 - Epoch: 296, Validation Loss: 0.8642, Validation Regression Loss 0.1513, Validation Classification Loss: 0.7130\n",
            "2023-03-07 05:22:13 - Saved model models/model0110/mb1-ssd-Epoch-296-Loss-0.8642451763153076.pth\n",
            "2023-03-07 05:22:27 - Epoch: 297, Step: 10/38, Avg Loss: 1.0876, Avg Regression Loss 0.1880, Avg Classification Loss: 0.8996\n",
            "2023-03-07 05:22:37 - Epoch: 297, Step: 20/38, Avg Loss: 1.0685, Avg Regression Loss 0.1565, Avg Classification Loss: 0.9120\n",
            "2023-03-07 05:22:47 - Epoch: 297, Step: 30/38, Avg Loss: 1.2250, Avg Regression Loss 0.3008, Avg Classification Loss: 0.9242\n",
            "2023-03-07 05:22:54 - Epoch: 297, Training Loss: 1.0282, Training Regression Loss 0.1933, Training Classification Loss: 0.8349\n",
            "2023-03-07 05:22:55 - Epoch: 297, Validation Loss: 0.8705, Validation Regression Loss 0.1541, Validation Classification Loss: 0.7163\n",
            "2023-03-07 05:22:55 - Saved model models/model0110/mb1-ssd-Epoch-297-Loss-0.8704636991024017.pth\n",
            "2023-03-07 05:23:08 - Epoch: 298, Step: 10/38, Avg Loss: 0.9168, Avg Regression Loss 0.1415, Avg Classification Loss: 0.7753\n",
            "2023-03-07 05:23:19 - Epoch: 298, Step: 20/38, Avg Loss: 0.9596, Avg Regression Loss 0.2169, Avg Classification Loss: 0.7427\n",
            "2023-03-07 05:23:29 - Epoch: 298, Step: 30/38, Avg Loss: 1.2512, Avg Regression Loss 0.2886, Avg Classification Loss: 0.9626\n",
            "2023-03-07 05:23:36 - Epoch: 298, Training Loss: 0.9484, Training Regression Loss 0.1845, Training Classification Loss: 0.7639\n",
            "2023-03-07 05:23:38 - Epoch: 298, Validation Loss: 0.9056, Validation Regression Loss 0.1605, Validation Classification Loss: 0.7451\n",
            "2023-03-07 05:23:38 - Saved model models/model0110/mb1-ssd-Epoch-298-Loss-0.9056162685155869.pth\n",
            "2023-03-07 05:23:51 - Epoch: 299, Step: 10/38, Avg Loss: 1.0072, Avg Regression Loss 0.2367, Avg Classification Loss: 0.7706\n",
            "2023-03-07 05:24:02 - Epoch: 299, Step: 20/38, Avg Loss: 1.1803, Avg Regression Loss 0.1750, Avg Classification Loss: 1.0054\n",
            "2023-03-07 05:24:13 - Epoch: 299, Step: 30/38, Avg Loss: 0.8922, Avg Regression Loss 0.1376, Avg Classification Loss: 0.7546\n",
            "2023-03-07 05:24:19 - Epoch: 299, Training Loss: 0.9185, Training Regression Loss 0.1651, Training Classification Loss: 0.7534\n",
            "2023-03-07 05:24:20 - Epoch: 299, Validation Loss: 0.8781, Validation Regression Loss 0.1555, Validation Classification Loss: 0.7226\n",
            "2023-03-07 05:24:20 - Saved model models/model0110/mb1-ssd-Epoch-299-Loss-0.8780922591686249.pth\n",
            "2023-03-07 05:24:20 - Task done, exiting program.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/jetson-train/result.py"
      ],
      "metadata": {
        "id": "beSgQ0E_LqPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df2ef1bf-f344-4d2b-e8d3-a4a0c31695bf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "Please enter model name: model0110\n",
            "Best Checkpoint: mb1-ssd-Epoch-105-Loss-0.774585634469986.pth\n",
            "Figure(640x480)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/jetson-train/vision/ssd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W21IgQ5aia-_",
        "outputId": "121780cd-e693-4f48-eb03-2bbcf7cc4ecf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/jetson-train/vision/ssd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python onnx_export.py --model-dir=models/model0110"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwqQ_GZQjHsc",
        "outputId": "f77f2cf8-7a34-432d-be5e-9e1416ff2f83"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file 'onnx_export.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip /content/jetson-train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Skhpu2ZOjLjl",
        "outputId": "18b9abcc-9307-48d6-e412-42099e764b23"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "zip error: Nothing to do! (/content/jetson-train.zip)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MVhm2Pq9kiFX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}